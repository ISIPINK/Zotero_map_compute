"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"78NY5WR8","report","2009","Settles, Burr","Active Learning Literature Survey","","","","","https://minds.wisconsin.edu/handle/1793/60660","The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer labeled training instances if it is allowed to choose the training data from which is learns. An active learner may ask queries in the form of unlabeled instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant but labels are difficult, time-consuming, or expensive to obtain.    This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for active learning, a summary of several problem setting variants, and a discussion of related topics in machine learning research are also presented.","2009","2022-09-17 13:55:35","2022-09-17 15:27:40","2022-09-17 13:55:35","","","","","","","","","","","","University of Wisconsin-Madison Department of Computer Sciences","","en","","Technical Report","","","minds.wisconsin.edu","","Accepted: 2012-03-15T17:23:56Z","","C:\Users\isido\Zotero\storage\XZAZ8M6G\Settles - 2009 - Active Learning Literature Survey.pdf; C:\Users\isido\Zotero\storage\A9QXPGLH\60660.html","","active learning; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5L3JNZM","preprint","2020","Baier, Lucas; Kellner, Vincent; Kühl, Niklas; Satzger, Gerhard","Switching Scheme: A Novel Approach for Handling Incremental Concept Drift in Real-World Data Sets","","","","","http://arxiv.org/abs/2011.02738","Machine learning models nowadays play a crucial role for many applications in business and industry. However, models only start adding value as soon as they are deployed into production. One challenge of deployed models is the effect of changing data over time, which is often described with the term concept drift. Due to their nature, concept drifts can severely affect the prediction performance of a machine learning system. In this work, we analyze the effects of concept drift in the context of a real-world data set. For efﬁcient concept drift handling, we introduce the switching scheme which combines the two principles of retraining and updating of a machine learning model. Furthermore, we systematically analyze existing regular adaptation as well as triggered adaptation strategies. The switching scheme is instantiated on New York City taxi data, which is heavily inﬂuenced by changing demand patterns over time. We can show that the switching scheme outperforms all other baselines and delivers promising prediction results.","2020-11-05","2022-09-17 15:26:45","2022-09-17 15:27:57","2022-09-17 15:26:45","","","","","","","Switching Scheme","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2011.02738 [cs]","","C:\Users\isido\Zotero\storage\4SZGPPN7\Baier e.a. - 2020 - Switching Scheme A Novel Approach for Handling In.pdf","","active learning","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2011.02738","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3AK4YYB","preprint","2022","Mayaki, Mansour Zoubeirou A.; Riveill, Michel","Autoregressive based Drift Detection Method","","","","","http://arxiv.org/abs/2203.04769","In the classic machine learning framework, models are trained on historical data and used to predict future values. It is assumed that the data distribution does not change over time (stationarity). However, in real-world scenarios, the data generation process changes over time and the model has to adapt to the new incoming data. This phenomenon is known as concept drift and leads to a decrease in the predictive model’s performance. In this study, we propose a new concept drift detection method based on autoregressive models called ADDM. This method can be integrated into any machine learning algorithm from deep neural networks to simple linear regression model. Our results show that this new concept drift detection method outperforms the state-of-the-art drift detection methods, both on synthetic data sets and real-world data sets. Our approach is theoretically guaranteed as well as empirical and effective for the detection of various concept drifts. In addition to the drift detector, we proposed a new method of concept drift adaptation based on the severity of the drift.","2022-03-09","2022-09-17 15:33:30","2022-09-17 15:33:30","2022-09-17 15:33:30","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2203.04769 [cs, stat]","","C:\Users\isido\Zotero\storage\54YTNIWQ\Mayaki en Riveill - 2022 - Autoregressive based Drift Detection Method.pdf","","","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2203.04769","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XL4WKTRT","journalArticle","2009","Sabelfeld, K.; Mozartova, N.","Sparsified Randomization Algorithms for large systems of linear equations and a new version of the Random Walk on Boundary method","Monte Carlo Methods and Applications","","0929-9629, 1569-3961","10.1515/MCMA.2009.015","https://www.degruyter.com/document/doi/10.1515/MCMA.2009.015/html","Sparsiﬁed Randomization Monte Carlo (SRMC) algorithms for solving large systems of linear algebraic equations are presented. We construct efﬁcient stochastic algorithms based on a probabilistic sampling of small size sub-matrices, or a randomized evaluation of a matrix-vector product and matrix iterations via a random sparsiﬁcation of the matrix. This approach is beyond the standard Markov chain based Neumann–Ulam method which has no universal instrument to decrease the variance. Instead, in the new method, ﬁrst, the variance can be decreased by increasing the number of the sampled columns of the matrix in play, and second, it is free of the restricted assumption of the Neumann–Ulam scheme that the Neumann series converges. We apply the developed methods to different stochastic iterative procedures. Application to boundary integral equation of the electrostatic potential theory is given where we develop a SRMC algorithm for solving the approximated system of linear algebraic equations, and compare it with the standard Random Walk on Boundary method.","2009-01","2022-09-17 17:35:35","2023-03-19 11:06:51","2022-09-17 17:35:35","","","3","15","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\YBMLVR26\Sabelfeld en Mozartova - 2009 - Sparsified Randomization Algorithms for large syst.pdf","","monte carlo; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMLGC6M2","journalArticle","2017","Benzi, Michele; Evans, Thomas M.; Hamilton, Steven P.; Lupo Pasini, Massimiliano; Slattery, Stuart R.","Analysis of Monte Carlo accelerated iterative methods for sparse linear systems","Numerical Linear Algebra with Applications","","1070-5325, 1099-1506","10.1002/nla.2088","https://onlinelibrary.wiley.com/doi/10.1002/nla.2088","We consider hybrid deterministic-stochastic iterative algorithms for the solution of large, sparse linear systems. Starting from a convergent splitting of the coeﬃcient matrix, we analyze various types of Monte Carlo acceleration schemes applied to the original preconditioned Richardson (stationary) iteration. These methods are expected to have considerable potential for resiliency to faults when implemented on massively parallel machines. We establish suﬃcient conditions for the convergence of the hybrid schemes, and we investigate diﬀerent types of preconditioners including sparse approximate inverses. Numerical experiments on linear systems arising from the discretization of partial diﬀerential equations are presented.","2017-05","2022-09-17 17:35:37","2023-03-19 11:06:56","2022-09-17 17:35:37","","","3","24","","Numer. Linear Algebra Appl.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\ZL2JBC57\Benzi e.a. - 2017 - Analysis of Monte Carlo accelerated iterative meth.pdf","","monte carlo; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMTYA6IM","journalArticle","2019","Wu, Tao; Gleich, David F.","Multiway Monte Carlo Method for Linear Systems","SIAM Journal on Scientific Computing","","1064-8275, 1095-7197","10.1137/18M121527X","https://epubs.siam.org/doi/10.1137/18M121527X","We study a novel variation on the Ulam–von Neumann Monte Carlo method for solving a linear system. This is an old randomized procedure that results from using a random walk to stochastically evaluate terms in the Neumann series. In order to apply this procedure, the variance of the stochastic estimator needs to be bounded. The best known suﬃcient condition for bounding the variance is that the inﬁnity norm of the matrix in the Neumann series is smaller than one, which greatly limits the usability of this method. We improve this condition by proposing a new stochastic estimator based on a diﬀerent type of random walk. Our multiway walk and estimator is based on a time-inhomogeneous Markov process that iterates through a sequence of transition matrices built from the original linear system. For our new method, we prove that a necessary and suﬃcient condition for convergence is that the spectral radius of the elementwise absolute value of the matrix underlying the Neumann series is smaller than one. This is a strictly weaker condition than currently exists. In addition, our new method is often faster than the standard algorithm. Through experiments, we demonstrate the potential for our method to reduce the time needed to solve linear equations by incorporating it into an outer iterative method.","2019-01","2022-09-17 17:35:39","2022-09-17 17:40:35","2022-09-17 17:35:39","A3449-A3475","","6","41","","SIAM J. Sci. Comput.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\UABEC4GQ\Wu en Gleich - 2019 - Multiway Monte Carlo Method for Linear Systems.pdf","","monte carlo; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPDWYCN5","journalArticle","2019","Dick, Josef; Gantner, Robert N.; Le Gia, Quoc T.; Schwab, Christoph","Higher order Quasi-Monte Carlo integration for Bayesian PDE Inversion","Computers & Mathematics with Applications","","08981221","10.1016/j.camwa.2018.09.019","https://linkinghub.elsevier.com/retrieve/pii/S0898122118305315","We analyze combined Quasi-Monte Carlo quadrature and Finite Element approximations in Bayesian estimation of solutions to countably-parametric operator equations with holomorphic dependence on the parameters as considered in Schillings and Schwab (2014). Such problems arise in numerical uncertainty quantification and in Bayesian inversion of operator equations with distributed uncertain inputs, such as uncertain coefficients, uncertain domains or uncertain source terms and boundary data. We show that the parametric Bayesian posterior densities belong to a class of weighted Bochner spaces of functions of countably many variables, with a particular structure of the QMC quadrature weights: up to a (problem-dependent, and possibly large) finite dimension S product weights can be used, and beyond this dimension, weighted spaces with so-called SPOD weights, recently introduced in Dick et al. (2014), are used to describe the solution regularity. We establish error bounds for higher order Quasi-Monte Carlo quadrature for the Bayesian estimation based on Dick et al. (2016). It implies, in particular, regularity of the parametric solution and of the countably-parametric Bayesian posterior density in SPOD (‘‘Smoothness driven, Product and Order Dependent’’) weighted spaces of integrand functions. This, in turn, implies that the Quasi-Monte Carlo quadrature methods in Dick et al. (2014) are applicable to these problem classes, with dimension-independent convergence rates O(N−1/p) of N-point HoQMC approximated Bayesian estimates, where 0 < p < 1 depends only on the sparsity class of the uncertain input in the Bayesian estimation. Fast componentby-component (CBC for short) construction Gantner and Schwab (2016) allow efficient deterministic Bayesian estimation with up to 104 parameters.","2019-01","2022-09-17 17:35:44","2022-09-17 17:40:21","2022-09-17 17:35:44","144-172","","1","77","","Computers & Mathematics with Applications","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\JNIFMW27\Dick e.a. - 2019 - Higher order Quasi-Monte Carlo integration for Bay.pdf","","monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S9MBRHQS","journalArticle","2012","Ji, Hao; Li, Yaohang","Reusing Random Walks in Monte Carlo Methods for Linear Systems","Procedia Computer Science","","18770509","10.1016/j.procs.2012.04.041","https://linkinghub.elsevier.com/retrieve/pii/S1877050912001627","In this paper, we present an approach of reusing random walks in Monte Carlo methods for linear systems. The fundamental idea is, during the Monte Carlo sampling process, the random walks generated to estimate one unknown element can also be effectively reused to estimate the other unknowns in the solution vector. As a result, when the random walks are reused, a single random walk can contribute samples for estimations of multiple unknowns in the solution simultaneously while ensuring that the samples for the same unknown element are statistically independent. Consequently, the total number of random walk transition steps needed for estimating the overall solution vector is reduced, which improves the performance of the Monte Carlo algorithm. We apply this approach to the Monte Carlo algorithm in two linear algebra applications, including solving a system of linear equations and approximating the inversion of a matrix. Our computational results show that compared to the conventional implementations of Monte Carlo algorithms for linear systems without random walk reusing, our approach can significantly improve the performance of Monte Carlo sampling process by reducing the overall number of transition steps in random walks to obtain the entire solution within desired precision.","2012","2022-09-17 17:35:48","2022-09-17 17:41:11","2022-09-17 17:35:48","383-392","","","9","","Procedia Computer Science","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\G5YWGZPN\Ji en Li - 2012 - Reusing Random Walks in Monte Carlo Methods for Li.pdf","","monte carlo; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QP5HLNL7","journalArticle","2016","Sabelfeld, Karl K.","Vector Monte Carlo stochastic matrix-based algorithms for large linear systems","Monte Carlo Methods and Applications","","0929-9629, 1569-3961","10.1515/mcma-2016-0112","https://www.degruyter.com/document/doi/10.1515/mcma-2016-0112/html","In this short article we suggest randomized scalable stochastic matrix-based algorithms for large linear systems. The idea behind these stochastic methods is a randomized vector representation of matrix iterations. In addition, to minimize the variance, it is suggested to use stochastic and double stochastic matrices for efficient randomized calculation of matrix iterations and a random gradient based search strategy. The iterations are performed by sampling random rows and columns only, thus avoiding not only matrix matrix but also matrix vector multiplications. Further improvements of the methods can be obtained through projections by a random gaussian matrix.","2016-01-01","2022-09-17 17:35:50","2022-09-17 17:42:06","2022-09-17 17:35:50","","","3","22","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\EX64VKZ2\Sabelfeld - 2016 - Vector Monte Carlo stochastic matrix-based algorit.pdf","","monte carlo; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7WBIRH9","bookSection","2012","Bender, Christian; Steiner, Jessica","Least-Squares Monte Carlo for Backward SDEs","Numerical Methods in Finance","978-3-642-25745-2 978-3-642-25746-9","","","http://link.springer.com/10.1007/978-3-642-25746-9_8","In this paper we ﬁrst give a review of the least-squares Monte Carlo approach for approximating the solution of backward stochastic diﬀerential equations (BSDEs) ﬁrst suggested by Gobet, Lemor, and Warin (Ann. Appl. Probab., 15, 2005, 2172–2202). We then propose the use of basis functions, which form a system of martingales, and explain how the least-squares Monte Carlo scheme can be simpliﬁed by exploiting the martingale property of the basis functions. We partially compare the convergence behavior of the original scheme and the scheme based on martingale basis functions, and provide several numerical examples related to option pricing problems under diﬀerent interest rates for borrowing and investing.","2012","2022-09-17 18:49:45","2022-09-26 12:59:18","2022-09-17 18:49:45","257-289","","","12","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Springer Proceedings in Mathematics DOI: 10.1007/978-3-642-25746-9_8","","C:\Users\isido\Zotero\storage\4LPW4G2Q\Bender en Steiner - 2012 - Least-Squares Monte Carlo for Backward SDEs.pdf","","monte carlo; SDE","","Carmona, René A.; Del Moral, Pierre; Hu, Peng; Oudjane, Nadia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3JZU8UXC","preprint","2015","Deaconu, Madalina; Herrmann, Samuel; Maire, Sylvain","The walk on moving spheres: a new tool for simulating Brownian motion's exit time from a domain","","","","","http://arxiv.org/abs/1401.3695","In this paper we introduce a new method for the simulation of the exit time and exit position of a δ-dimensional Brownian motion from a domain. The main interest of our method is that it avoids splitting time schemes as well as inversion of complicated series. The method, called walk on moving spheres algorithm, was ﬁrst introduced for hitting times of Bessel processes. In this study this method is adapted and developed for the ﬁrst time for the Brownian motion hitting times. The idea is to use the connexion between the δdimensional Bessel process and the δ-dimensional Brownian motion thanks to an explicit Bessel hitting time distribution associated with a particular curved boundary. This allows to build a fast and accurate numerical scheme for approximating the hitting time. We introduce also an overview of existing methods for the simulation of the Brownian hitting time and perform numerical comparisons with existing methods.","2015-10-16","2022-09-17 18:51:56","2023-03-19 11:06:29","2022-09-17 18:51:56","","","","","","","The walk on moving spheres","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1401.3695 [math]","","C:\Users\isido\Zotero\storage\EIYVRXS7\Deaconu e.a. - 2015 - The walk on moving spheres a new tool for simulat.pdf","","monte carlo; PDE; walk on spheres","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1401.3695","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C95PBMD4","journalArticle","2022","Sawhney, Rohan; Seyb, Dario; Jarosz, Wojciech; Crane, Keenan","Grid-free Monte Carlo for PDEs with spatially varying coefficients","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3528223.3530134","https://dl.acm.org/doi/10.1145/3528223.3530134","Partial differential equations (PDEs) with spatially varying coefficients arise throughout science and engineering, modeling rich heterogeneous material behavior. Yet conventional PDE solvers struggle with the immense complexity found in nature, since they must first discretize the problem---leading to spatial aliasing, and global meshing/sampling that is costly and error-prone. We describe a method that approximates neither the domain geometry, the problem data, nor the solution space, providing the exact solution (in expectation) even for problems with extremely detailed geometry and intricate coefficients. Our main contribution is to extend the               walk on spheres (WoS)               algorithm from constant- to variable-coefficient problems, by drawing on techniques from volumetric rendering. In particular, an approach inspired by               null-scattering               yields unbiased Monte Carlo estimators for a large class of 2nd order elliptic PDEs, which share many attractive features with Monte Carlo rendering: no meshing, trivial parallelism, and the ability to evaluate the solution at any point without solving a global system of equations.","2022-07","2022-09-17 18:52:00","2023-03-19 11:06:20","2022-09-17 18:52:00","1-17","","4","41","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\52QDH9YB\Sawhney e.a. - 2022 - Grid-free Monte Carlo for PDEs with spatially vary.pdf","","monte carlo; PDE; walk on spheres; rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WNZ92QXZ","journalArticle","","Sawhney, Rohan; Crane, Keenan","Monte Carlo Geometry Processing:A Grid-Free Approach to PDE-Based Methods on Volumetric Domains","","","","","","This paper explores how core problems in PDE-based geometry processing can be efficiently and reliably solved via grid-free Monte Carlo methods. Modern geometric algorithms often need to solve Poisson-like equations on geometrically intricate domains. Conventional methods most often mesh the domain, which is both challenging and expensive for geometry with fine details or imperfections (holes, self-intersections, etc.). In contrast, gridfree Monte Carlo methods avoid mesh generation entirely, and instead just evaluate closest point queries. They hence do not discretize space, time, nor even function spaces, and provide the exact solution (in expectation) even on extremely challenging models. More broadly, they share many benefits with Monte Carlo methods from photorealistic rendering: excellent scaling, trivial parallel implementation, view-dependent evaluation, and the ability to work with any kind of geometry (including implicit or procedural descriptions). We develop a complete “black box” solver that encompasses integration, variance reduction, and visualization, and explore how it can be used for various geometry processing tasks. In particular, we consider several fundamental linear elliptic PDEs with constant coefficients on solid regions of Rn . Overall we find that Monte Carlo methods significantly broaden the horizons of geometry processing, since they easily handle problems of size and complexity that are essentially hopeless for conventional methods.","","2022-09-17 18:54:45","2023-08-03 18:36:47","","18","","4","38","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\J5MXL5PE\Sawhney en Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf","","monte carlo; PDE; rendering; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TTZ3JB83","preprint","2018","Ferguson, Ryan; Green, Andrew","Deeply Learning Derivatives","","","","","http://arxiv.org/abs/1809.02233","This paper uses deep learning to value derivatives. The approach is broadly applicable, and we use a call option on a basket of stocks as an example. We show that the deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. We develop a methodology to randomly generate appropriate training data and explore the impact of several parameters including layer width and depth, training data quality and quantity on model speed and accuracy.","2018-10-17","2022-09-19 13:22:35","2023-03-19 11:06:00","2022-09-19 13:22:35","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1809.02233 [cs, q-fin]","","C:\Users\isido\Zotero\storage\5KLHN2WM\Ferguson en Green - 2018 - Deeply Learning Derivatives.pdf","","finance; machine learning","Computer Science - Machine Learning; Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:1809.02233","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y8CL8VZC","preprint","2018","Lehtinen, Jaakko; Munkberg, Jacob; Hasselgren, Jon; Laine, Samuli; Karras, Tero; Aittala, Miika; Aila, Timo","Noise2Noise: Learning Image Restoration without Clean Data","","","","","http://arxiv.org/abs/1803.04189","We apply basic statistical reasoning to signal reconstruction by machine learning – learning to map corrupted observations to clean signals – with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans – all corrupted by different processes – based on noisy data only.","2018-10-29","2022-09-19 14:04:13","2023-03-19 11:05:50","2022-09-19 14:04:13","","","","","","","Noise2Noise","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1803.04189 [cs, stat]","","C:\Users\isido\Zotero\storage\NAGQ9NY7\Lehtinen e.a. - 2018 - Noise2Noise Learning Image Restoration without Cl.pdf","","machine learning","Computer Science - Machine Learning; Statistics - Machine Learning; Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:1803.04189","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTGTF5I3","webpage","2020","","Accelerating Python for Exotic Option Pricing","NVIDIA Technical Blog","","","","https://developer.nvidia.com/blog/accelerating-python-for-exotic-option-pricing/","In finance, computation efficiency can be directly converted to trading profits sometimes. Quants are facing the challenges of trading off research efficiency with computation efficiency.","2020-03-19","2022-09-19 14:08:08","2022-09-19 14:08:40","2022-09-19 14:08:08","","","","","","","","","","","","","","en-US","","","","","","","","","C:\Users\isido\Zotero\storage\LNJMET6I\accelerating-python-for-exotic-option-pricing.html","","python; cupy; numba","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLFA8VRN","webpage","","","GitHub - NVIDIA/fsi-samples: A collection of open-source GPU accelerated Python tools and examples for quantitative analyst tasks and leverages RAPIDS AI project, Numba, cuDF, and Dask.","","","","","https://github.com/NVIDIA/fsi-samples","","","2022-09-19 14:17:17","2022-09-19 14:17:58","2022-09-19 14:17:17","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\FTUN9SNE\fsi-samples.html","","python; quant","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQLA8IME","encyclopediaArticle","2022","","Neville's algorithm","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Neville%27s_algorithm&oldid=1100728778","In mathematics, Neville's algorithm is an algorithm used for polynomial interpolation that was derived by the mathematician Eric Harold Neville in 1934. Given n + 1 points, there is a unique polynomial of degree ≤ n which goes through the given points. Neville's algorithm evaluates this polynomial. Neville's algorithm is based on the Newton form of the interpolating polynomial and the recursion relation for the divided differences. It is similar to Aitken's algorithm (named after Alexander Aitken), which is nowadays not used.","2022-07-27","2022-09-26 06:48:39","2022-09-26 06:49:18","2022-09-26 06:48:39","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1100728778","","C:\Users\isido\Zotero\storage\J69UYIG8\Neville's_algorithm.html","","finite differnces; interpolation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CT3DDRGG","preprint","2021","Vanroose, Wim; Cornelis, Jeffrey","Krylov-Simplex method that minimizes the residual in $\ell_1$-norm or $\ell_\infty$-norm","","","","","http://arxiv.org/abs/2101.11416","The paper presents two variants of a Krylov-Simplex iterative method that combines Krylov and simplex iterations to minimize the residual r = b−Ax. The ﬁrst method minimizes r ∞, i.e. maximum of the absolute residuals. The second minimizes r 1, and ﬁnds the solution with the least absolute residuals. Both methods search for an optimal solution xk in a Krylov subspace which results in a small linear programming problem. A specialized simplex algorithm solves this projected problem and ﬁnds the optimal linear combination of Krylov basis vectors to approximate the solution. The resulting simplex algorithm requires the solution of a series of small dense linear systems that only diﬀer by rank-one updates. The QR factorization of these matrices is updated each iteration. We demonstrate the eﬀectiveness of the methods with numerical experiments.","2021-01-27","2022-09-26 09:08:47","2023-03-19 11:04:36","2022-09-26 09:08:47","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2101.11416 [cs, math]","","C:\Users\isido\Zotero\storage\M2G9WBDA\Vanroose en Cornelis - 2021 - Krylov-Simplex method that minimizes the residual .pdf","","optimization-constrained; optimization","Mathematics - Numerical Analysis; Mathematics - Optimization and Control","","","","","","","","","","","","","","","","","","","arXiv:2101.11416","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A46LQ3HD","journalArticle","2007","Caglar, Hikmet; Caglar, Nazan","Solution of fifth order boundary value problems by using local polynomial regression","Applied Mathematics and Computation","","00963003","10.1016/j.amc.2006.08.046","https://linkinghub.elsevier.com/retrieve/pii/S0096300306010204","In this paper, we present a novel method based on the local polynomial regression for solving of ﬁfth order boundary value problems. The method is tested on numerical example to demonstrate its usefulness. The method presented in this paper is also compared with those developed by Siddiqi and Akram [Solution of ﬁfth order boundary value problems using nonpolynomial spline technique, Appl. Math. Comput. 175 (2006) 1575–1581], as well and is observed to be better.","2007-03","2022-09-26 12:57:28","2023-03-19 11:03:56","2022-09-26 12:57:28","952-956","","2","186","","Applied Mathematics and Computation","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\Z8EJ5CDR\Caglar en Caglar - 2007 - Solution of fifth order boundary value problems by.pdf","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZZXAYPQ","journalArticle","2012","Su, Liyun; Yan, Tianshun; Zhao, Yanyong; Li, Fenglan; Liu, Ruihua","Numerical Solution of Integro-Differential Equations with Local Polynomial Regression","Open Journal of Statistics","","2161-718X, 2161-7198","10.4236/ojs.2012.23043","http://www.scirp.org/journal/doi.aspx?DOI=10.4236/ojs.2012.23043","In recent years, there has been a growing interest in the Integro-Differential Equations (IDEs) which are a combination of differential and Fredholm-Volterra integral equations. IDEs play an important role in many branches of linear and nonlinear functional analysis and their applications in the theory of engineering, mechanics, physics, chemistry, astronomy, biology, economics, potential theory and electrostatics. The mentioned integro-differential equations are usually difficult to solve analytically, so a numerical method is required. Many different methods are used to obtain the solution of the linear and nonlinear IDEs such as the successive approximations, A domain decomposition, Homotopy perturbation method, Chebyshev and Taylor collocation, Haar Wavelet, Tau and Walsh series methods [1-8]. Recently, the authors [9], have used local polynomial regression (LPR) method for the numerical solution of linear and non-linear Fredholm and Volterra integral equations. In this paper, we consider the linear IDEs,     x a yx pxyx gx K     (1) where the upper limit of the integral is constant or variable,    are constants, g xpx  and the kernel     K xt y  are given functions, whereas x 0 needs to be determined. The subject of this paper is to try to find numerical solutions of integro-differential equations by means of local polynomial regression method which is presented firstly by Hikmat Caglar [9]. Finally, we show the method to achieve the desired accuracy. Details of the structure of the present method are explained in sections. We apply LPR method for IDEs. In Section 3, it’s proved the efficiency of numerical method. Finally, Section 4 contains some conclusions and directions for future expectations and researches.","2012","2022-09-26 13:07:47","2023-08-03 18:36:06","2022-09-26 13:07:47","352-355","","03","02","","OJS","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\MDM22BGE\Su e.a. - 2012 - Numerical Solution of Integro-Differential Equatio.pdf","","integral equations; ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QPP5ULJB","journalArticle","1966","Haji-Sheikh, A.; Sparrow, E. M.","The Floating Random Walk and Its Application to Monte Carlo Solutions of Heat Equations","SIAM Journal on Applied Mathematics","","","","http://www.jstor.org/stable/2946271","Introduction. As longago as the turnof thecentury, it hadbeen recognizedthatprobabilitysamplingtechniquescould,in principle, be employed in solvingpartialdifferential equationsarisingin physicsand engineering. In 1899,LordRayleigh[1]demonstratet dherelationshipbetweenstochastic processesand parabolicdifferential equations,whilea similarrelationship was establishedin 1928by Courantand hiscoworkers[2]forellipticdifferentialequations.The earliestknowncomputationalexperiments involving samplingtechniquesare due to Todd[3],whoworkedwithLaplace's equationin asquaregeometryhavingprescribedboundarytemperatures. Somewhat more recently,Ehrlich [4] used samplingtechniquesto solve the equation a2u +au kau _+ - + -- = 0 ax2 ay2 y ay in simplepolygonswithprescribedboundaryvalues ofu. In general,there have been relativelyfew suchcomputationalexperiments. The name ""Monte Carlo"" is characteristically used to describeprobabilitysamplingtechniquesthat approximatethe solutionofmathematical or physicalproblems. A valuable surveyofMonte Carlomethodsas applied to the solutionof differential and difference equationshas been provided by Curtiss[5]. A primereferencesourceforthe randomwalk technique, which is basic to Monte Carlo methods,is Feller's text on probability theory[6]","1966","2022-09-27 19:05:10","2023-08-03 18:35:44","","370-389","","2","14","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\M4YQIH62\Haji-Sheikh en Sparrow - 1966 - The Floating Random Walk and Its Application to Mo.pdf","","monte carlo; PDE; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYW4WWLU","book","2001","Hastie, Trevor; Friedman, Jerome; Tibshirani, Robert","The Elements of Statistical Learning  Data Mining, Inference, and Prediction","","","","","","The many topics include neural networks, support vector machines, classification trees and boosting - the first comprehensive treatment of this topic in any book","2001","2022-09-27 19:42:11","2023-03-19 11:03:35","","","","","","","","","","","","","Springer Berlin Heidelberg","","","","","","","","","","","C:\Users\isido\Zotero\storage\Q8DWLFW6\ESLII_print12_toc-compressed.pdf","","machine learning; statistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZWD66Q9A","journalArticle","2019","Cockayne, Jon; Oates, Chris; Sullivan, Tim; Girolami, Mark","Bayesian Probabilistic Numerical Methods","SIAM Review","","0036-1445, 1095-7200","10.1137/17M1139357","http://arxiv.org/abs/1702.03673","The emergent field of probabilistic numerics has thus far lacked clear statistical principals. This paper establishes Bayesian probabilistic numerical methods as those which can be cast as solutions to certain inverse problems within the Bayesian framework. This allows us to establish general conditions under which Bayesian probabilistic numerical methods are well-defined, encompassing both non-linear and non-Gaussian models. For general computation, a numerical approximation scheme is proposed and its asymptotic convergence established. The theoretical development is then extended to pipelines of computation, wherein probabilistic numerical methods are composed to solve more challenging numerical tasks. The contribution highlights an important research frontier at the interface of numerical analysis and uncertainty quantification, with a challenging industrial application presented.","2019-01","2022-09-30 13:49:16","2023-03-19 15:58:37","2022-09-30 13:49:16","756-789","","3","61","","SIAM Rev.","","","","","","","","en","","","","","arXiv.org","","arXiv:1702.03673 [cs, math, stat]","","C:\Users\isido\Zotero\storage\9ST6SIRW\Cockayne e.a. - 2019 - Bayesian Probabilistic Numerical Methods.pdf","","statistics","Mathematics - Numerical Analysis; Mathematics - Statistics Theory; Statistics - Computation; Statistics - Methodology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KUI5SU4X","journalArticle","2012","Gondzio, Jacek","Interior point methods 25 years later","European Journal of Operational Research","","03772217","10.1016/j.ejor.2011.09.017","https://linkinghub.elsevier.com/retrieve/pii/S0377221711008204","Interior point methods for optimization have been around for more than 25 years now. Their presence has shaken up the ﬁeld of optimization. Interior point methods for linear and (convex) quadratic programming display several features which make them particularly attractive for very large scale optimization. Among the most impressive of them are their low-degree polynomial worst-case complexity and an unrivalled ability to deliver optimal solutions in an almost constant number of iterations which depends very little, if at all, on the problem dimension. Interior point methods are competitive when dealing with small problems of dimensions below one million constraints and variables and are beyond competition when applied to large problems of dimensions going into millions of constraints and variables.","2012-05","2022-10-27 11:24:12","2022-10-27 11:25:27","2022-10-27 11:24:12","587-601","","3","218","","European Journal of Operational Research","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\NNLGF4AU\Gondzio - 2012 - Interior point methods 25 years later.pdf","","optimization-constrained; interior point methods; optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H4M3QKNQ","preprint","2021","Kitapbayev, Yerkin","Closed form optimal exercise boundary of the American put option","","","","","http://arxiv.org/abs/1912.05438","We present three models of stock price with time-dependent interest rate, dividend yield, and volatility, respectively, that allow for explicit forms of the optimal exercise boundary of the finite maturity American put option. The optimal exercise boundary satisfies the nonlinear integral equation of Volterra type. We choose time-dependent parameters of the model so that the integral equation for the exercise boundary can be solved in the closed form. We also define the contracts of put type with time-dependent strike price that support the explicit optimal exercise boundary.","2021-01-09","2022-12-03 08:44:33","2023-03-19 15:58:32","2022-12-03 08:44:33","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1912.05438 [q-fin]","","C:\Users\isido\Zotero\storage\99M3PKZV\Kitapbayev - 2021 - Closed form optimal exercise boundary of the Ameri.pdf","","finance","Primary Primary 91G20, 60G40. Secondary 60J60, 35R35, 45G10; Quantitative Finance - Mathematical Finance; Quantitative Finance - Pricing of Securities","","","","","","","","","","","","","","","","","","","arXiv:1912.05438","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52YIE38K","journalArticle","2021","Healy, Jherek","Pricing American options under negative rates","The Journal of Computational Finance","","14601559, 17552850","10.21314/JCF.2021.004","http://arxiv.org/abs/2109.15157","This paper starts by deﬁning the criteria where the early-exercise of an American option is never optimal, under positive, or negative rates. It follows with a short analysis of the various shapes of the exercise region under negative interest rates. It then presents a new integral equation, which establishes the option price, and the two early exercise boundaries, under negative rates. It shows how to solve this new equation, through modiﬁcations of the modern and efﬁcient algorithm of Andersen and Lake, from the initial guess of the two boundaries to more subtle changes required in their ﬁxed point method for stability. Finally, the performance and accuracy of the resulting algorithm is assessed against a cutting edge ﬁnite difference method implementation.","2021","2022-12-03 09:21:35","2023-03-19 11:02:32","2022-12-03 09:21:35","","","","","","JCF","","","","","","","","en","","","","","arXiv.org","","arXiv:2109.15157 [q-fin]","","C:\Users\isido\Zotero\storage\8RBI4CZR\Healy - 2021 - Pricing American options under negative rates.pdf","","finance","Quantitative Finance - Computational Finance; Quantitative Finance - Pricing of Securities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VT99V4NF","journalArticle","2010","Bossy, Mireille; Baude, Françoise; Doan, Viet Dung; Gaikwad, Abhijeet; Stokes-Rees, Ian","Parallel Pricing Algorithms for Multi--Dimensional Bermudan/American Options using Monte Carlo methods","Mathematics and Computers in Simulation","","03784754","10.1016/j.matcom.2010.08.005","http://arxiv.org/abs/0805.1827","In this paper we present two parallel Monte Carlo based algorithms for pricing multi–dimensional Bermudan/American options. First approach relies on computation of the optimal exercise boundary while the second relies on classiﬁcation of continuation and exercise values. We also evaluate the performance of both the algorithms in a desktop grid environment. We show the eﬀectiveness of the proposed approaches in a heterogeneous computing environment, and identify scalability constraints due to the algorithmic structure.","2010-11","2022-12-03 09:36:45","2023-03-19 11:02:07","2022-12-03 09:36:45","568-577","","3","81","","Mathematics and Computers in Simulation","","","","","","","","en","","","","","arXiv.org","","arXiv:0805.1827 [cs]","","C:\Users\isido\Zotero\storage\R7AAXVAF\Bossy e.a. - 2010 - Parallel Pricing Algorithms for Multi--Dimensional.pdf","","monte carlo; finance","Computer Science - Computational Engineering, Finance, and Science; Computer Science - Distributed, Parallel, and Cluster Computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EF9KMM7N","preprint","2007","Sevcovic, Daniel","An iterative algorithm for evaluating approximations to the optimal exercise boundary for a nonlinear Black-Scholes equation","","","","","http://arxiv.org/abs/0710.5301","The purpose of this paper is to analyze and compute the early exercise boundary for a class of nonlinear Black–Scholes equations with a nonlinear volatility which can be a function of the second derivative of the option price itself. A motivation for studying the nonlinear Black–Scholes equation with a nonlinear volatility arises from option pricing models taking into account e.g. nontrivial transaction costs, investor’s preferences, feedback and illiquid markets effects and risk from a volatile (unprotected) portfolio. We present a new method how to transform the free boundary problem for the early exercise boundary position into a solution of a time depending nonlinear parabolic equation deﬁned on a ﬁxed domain. We furthermore propose an iterative numerical scheme that can be used to ﬁnd an approximation of the free boundary. We present results of numerical approximation of the early exercise boundary for various types of nonlinear Black–Scholes equations and we discuss dependence of the free boundary on various model parameters.","2007-10-28","2022-12-03 09:39:03","2023-03-19 11:01:51","2022-12-03 09:39:03","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:0710.5301 [math, q-fin]","","C:\Users\isido\Zotero\storage\QEPCMV5C\Sevcovic - 2007 - An iterative algorithm for evaluating approximatio.pdf","","finance","Quantitative Finance - Computational Finance; Mathematics - Numerical Analysis; 35K15; 35K55; 90A09; 91B28","","","","","","","","","","","","","","","","","","","arXiv:0710.5301","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGBVP9JJ","preprint","1998","Sorge, H.","Valuation of path-dependent American options using a Monte Carlo approach","","","","","http://arxiv.org/abs/math/9801057","It is shown how to obtain accurate values for American options using Monte Carlo simulation. The main feature of the novel algorithm consists of tracking the boundary between exercise and hold regions via optimization of a certain payoﬀ function. We compare estimates from simulation for some types of claims with results from binomial tree calculations and ﬁnd very good agreement. The novel method allows to calculate so far untractable path-dependent option values.","1998-01-12","2022-12-03 09:44:48","2023-03-19 11:01:36","2022-12-03 09:44:48","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:math/9801057","","C:\Users\isido\Zotero\storage\TEBUQCAP\Sorge - 1998 - Valuation of path-dependent American options using.pdf","","finance","Quantitative Finance - Computational Finance; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:math/9801057","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VQR3WI22","preprint","2021","Hout, Karel in 't; Snoeijer, Jacob","Numerical valuation of American basket options via partial differential complementarity problems","","","","","http://arxiv.org/abs/2106.01200","We study the principal component analysis based approach introduced by Reisinger & Wittum [1] and the comonotonic approach considered by Hanbali & Linders [2] for the approximation of American basket option values via multidimensional partial diﬀerential complementarity problems (PDCPs). Both approximation approaches require the solution of just a limited number of low-dimensional PDCPs. It is demonstrated by ample numerical experiments that they deﬁne approximations that lie close to each other. Next, an eﬃcient discretisation of the pertinent PDCPs is presented that leads to a favourable convergence behaviour.","2021-06-02","2022-12-03 10:47:53","2023-03-19 11:01:04","2022-12-03 10:47:53","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2106.01200 [cs, math, q-fin]","","C:\Users\isido\Zotero\storage\VYEP4C9L\Hout en Snoeijer - 2021 - Numerical valuation of American basket options via.pdf","","finance","Quantitative Finance - Computational Finance; Mathematics - Numerical Analysis; Computer Science - Computational Engineering, Finance, and Science","","","","","","","","","","","","","","","","","","","arXiv:2106.01200","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LNZX599X","encyclopediaArticle","2022","","Free boundary problem","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Free_boundary_problem&oldid=1117659232","In mathematics, a free boundary problem (FB problem) is a partial differential equation to be solved for both an unknown function                         u                 {\displaystyle u}    and an unknown domain                         Ω                 {\displaystyle \Omega }   . The segment                         Γ                 {\displaystyle \Gamma }    of the boundary of                         Ω                 {\displaystyle \Omega }    which is not known at the outset of the problem is the free boundary. FBs arise in various mathematical models encompassing applications that ranges from physical to economical, financial and biological phenomena, where there is an extra effect of the medium. This effect is in general a qualitative change of the medium and hence an appearance of a phase transition: ice to water, liquid to crystal, buying to selling (assets), active to inactive (biology), blue to red (coloring games), disorganized to organized (self-organizing criticality). An interesting aspect of such a criticality is the so-called sandpile dynamic (or Internal DLA). The most classical example is the melting of ice: Given a block of ice, one can solve the heat equation given appropriate initial and boundary conditions to determine its temperature. But, if in any region the temperature is greater than the melting point of ice, this domain will be occupied by liquid water instead. The boundary formed from the ice/liquid interface is controlled dynamically by the solution of the PDE.","2022-10-22","2022-12-03 10:56:17","2023-03-19 11:00:56","2022-12-03 10:56:17","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1117659232","","C:\Users\isido\Zotero\storage\T8LYY8CI\Free_boundary_problem.html","","finance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6DRMT66","preprint","2014","Herrera, Calypso; Paulot, Louis","Parallel American Monte Carlo","","","","","http://arxiv.org/abs/1404.1180","In this paper we introduce a new algorithm for American Monte Carlo that can be used either for American-style options, callable structured products or for computing counterparty credit risk (e.g. CVA or PFE computation). Leveraging least squares regressions, the main novel feature of our algorithm is that it can be fully parallelized. Moreover, there is no need to store the paths and the payoﬀ computation can be done forwards: this allows to price structured products with complex path and exercise dependencies. The key idea of our algorithm is to split the set of paths in several subsets which are used iteratively. We give the convergence rate of the algorithm. We illustrate our method on an American put option and compare the results with the Longstaﬀ-Schwartz algorithm.","2014-04-04","2022-12-03 13:09:37","2023-03-19 11:00:51","2022-12-03 13:09:37","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1404.1180 [q-fin]","","C:\Users\isido\Zotero\storage\MKELBXNC\Herrera en Paulot - 2014 - Parallel American Monte Carlo.pdf","","monte carlo; finance","Quantitative Finance - Computational Finance; Quantitative Finance - Pricing of Securities","","","","","","","","","","","","","","","","","","","arXiv:1404.1180","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YD8USU5M","bookSection","2012","Garcke, Jochen","Sparse Grids in a Nutshell","Sparse Grids and Applications","978-3-642-31702-6 978-3-642-31703-3","","","http://link.springer.com/10.1007/978-3-642-31703-3_3","The technique of sparse grids allows to overcome the curse of dimensionality, which prevents the use of classical numerical discretization schemes in more than three or four dimensions, under suitable regularity assumptions. The approach is obtained from a multi-scale basis by a tensor product construction and subsequent truncation of the resulting multiresolution series expansion. This entry level article gives an introduction to sparse grids and the sparse grid combination technique.","2012","2022-12-04 10:38:58","2022-12-04 10:38:58","2022-12-04 10:38:57","57-80","","","88","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computational Science and Engineering DOI: 10.1007/978-3-642-31703-3_3","","C:\Users\isido\Zotero\storage\UN7T7FRH\Garcke - 2012 - Sparse Grids in a Nutshell.pdf","","","","Garcke, Jochen; Griebel, Michael","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W37U7KH8","encyclopediaArticle","2022","","Parareal","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Parareal&oldid=1117710630","Parareal is a parallel algorithm from numerical analysis and used for the solution of initial value problems. It was introduced in 2001 by Lions, Maday and Turinici. Since then, it has become one of the most widely studied parallel-in-time integration methods.","2022-10-23","2022-12-04 20:18:43","2023-03-19 11:00:21","2022-12-04 20:18:42","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1117710630","","C:\Users\isido\Zotero\storage\RCGZQ9J3\Parareal.html","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNL3J7SL","encyclopediaArticle","2022","","Multilevel Monte Carlo method (wikipedia)","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Multilevel_Monte_Carlo_method&oldid=1070124752","Multilevel Monte Carlo (MLMC) methods in numerical analysis are algorithms for computing expectations that arise in stochastic simulations. Just as Monte Carlo methods, they rely on repeated random sampling, but these samples are taken on different levels of accuracy. MLMC methods can greatly reduce the computational cost of standard Monte Carlo methods by taking most samples with a low accuracy and corresponding low cost, and only very few samples are taken at high accuracy and corresponding high cost.","2022-02-05","2022-12-04 20:33:45","2023-03-19 11:00:16","2022-12-04 20:33:45","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1070124752","","C:\Users\isido\Zotero\storage\NSTZZI8D\Multilevel_Monte_Carlo_method.html","","monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IAEDCF37","journalArticle","2011","Cliffe, K. A.; Giles, M. B.; Scheichl, R.; Teckentrup, A. L.","Multilevel Monte Carlo methods and applications to elliptic PDEs with random coefficients","Computing and Visualization in Science","","1432-9360, 1433-0369","10.1007/s00791-011-0160-x","http://link.springer.com/10.1007/s00791-011-0160-x","We consider the numerical solution of elliptic partial differential equations with random coefﬁcients. Such problems arise, for example, in uncertainty quantiﬁcation for groundwater ﬂow. We describe a novel variance reduction technique for the standard Monte Carlo method, called the multilevel Monte Carlo method, and demonstrate numerically its superiority. The asymptotic cost of solving the stochastic problem with the multilevel method is always significantly lower than that of the standard method and grows only proportionally to the cost of solving the deterministic problem in certain circumstances. Numerical calculations demonstrating the effectiveness of the method for one- and two-dimensional model problems arising in groundwater ﬂow are presented.","2011-01","2022-12-04 20:35:41","2023-03-19 11:00:10","2022-12-04 20:35:41","3-15","","1","14","","Comput. Visual Sci.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\EM2WHUW8\Cliffe e.a. - 2011 - Multilevel Monte Carlo methods and applications to.pdf","","monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"47E5JX3J","preprint","2013","Giles, Michael B.","Multilevel Monte Carlo methods","","","","","http://arxiv.org/abs/1304.5472","The author’s presentation of multilevel Monte Carlo path simulation at the MCQMC 2006 conference stimulated a lot of research into multilevel Monte Carlo methods. This paper reviews the progress since then, emphasising the simplicity, ﬂexibility and generality of the multilevel Monte Carlo approach. It also offers a few original ideas and suggests areas for future research.","2013-04-19","2022-12-04 20:40:38","2023-03-19 11:00:04","2022-12-04 20:40:38","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1304.5472 [math]","","C:\Users\isido\Zotero\storage\YRKQ5XCV\Giles - 2013 - Multilevel Monte Carlo methods.pdf","","monte carlo","Mathematics - Numerical Analysis; 60H10, 60H15, 60H35, 65C30","","","","","","","","","","","","","","","","","","","arXiv:1304.5472","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYXF7ZLI","book","1995","Øksendal, Bernt","Stochastic Differential Equations","","978-3-540-60243-9 978-3-662-03185-8","","","http://link.springer.com/10.1007/978-3-662-03185-8","","1995","2022-12-04 20:48:20","2022-12-04 20:48:21","2022-12-04 20:48:20","","","","","","","","Universitext","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-3-662-03185-8","","C:\Users\isido\Zotero\storage\NN2LBDZP\Øksendal - 1995 - Stochastic Differential Equations.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VJQ8UL4","journalArticle","2007","Zhu, Song-Ping; He, Zhi-Wei","CALCULATING THE EARLY EXERCISE BOUNDARY OF AMERICAN PUT OPTIONS WITH AN APPROXIMATION FORMULA","International Journal of Theoretical and Applied Finance","","0219-0249, 1793-6322","10.1142/S0219024907004615","https://www.worldscientific.com/doi/abs/10.1142/S0219024907004615","In this paper, an algorithm to improve the computational accuracy of the analytical approximation to the value of American put options and their optimal exercise boundary proposed by Zhu (2004) is presented. In the current approach, Zhu’s simple approximation formula is used as an initial guess for the optimal exercise boundary of American put options. The determination of an improved optimal exercise boundary is then achieved by setting a null value of the Theta of option value on the optimal exercise boundary. Test example results show that the improvement is indeed signiﬁcant.","2007-11","2022-12-04 20:49:18","2023-03-19 10:59:56","2022-12-04 20:49:18","1203-1227","","07","10","","Int. J. Theor. Appl. Finan.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\2ZSHAVUG\Zhu en He - 2007 - CALCULATING THE EARLY EXERCISE BOUNDARY OF AMERICA.pdf","","finance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SCG2GC94","journalArticle","2006","Bormetti, G.; Montagna, G.; Moreni, N.; Nicrosini, O.","Pricing exotic options in a path integral approach","Quantitative Finance","","1469-7688, 1469-7696","10.1080/14697680500510878","http://www.tandfonline.com/doi/abs/10.1080/14697680500510878","In the framework of Black-Scholes-Merton model of ﬁnancial derivatives, a path integral approach to option pricing is presented. A general formula to price European path dependent options on multidimensional assets is obtained and implemented by means of various ﬂexible and eﬃcient algorithms. As an example, we detail the cases of Asian, barrier knock out, reverse cliquet and basket call options, evaluating prices and Greeks. The numerical results are compared with those obtained with other procedures used in quantitative ﬁnance and found to be in good agreement. In particular, when pricing at-the-money and out-of-the-money options, the path integral approach exhibits competitive performances.","2006-02","2022-12-04 21:32:15","2023-03-19 10:59:42","2022-12-04 21:32:15","55-66","","1","6","","Quantitative Finance","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\5RXL3P32\Bormetti e.a. - 2006 - Pricing exotic options in a path integral approach.pdf","","finance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U55LBZVJ","journalArticle","2021","Capuozzo, Pietro; Panella, Emanuele; Schettini Gherardini, Tancredi; Vvedensky, Dimitri D.","Path integral Monte Carlo method for option pricing","Physica A: Statistical Mechanics and its Applications","","03784371","10.1016/j.physa.2021.126231","https://linkinghub.elsevier.com/retrieve/pii/S0378437121005045","The Markov chain Monte Carlo (MCMC) method, in conjunction with the Metropolis–Hastings algorithm, is used to simulate the path integral for the Black–Scholes–Merton model of option pricing. After a brief derivation of the path integral solution of this model, we develop the MCMC method by discretizing the path integral on a time lattice and evaluating this discretized form for various scenarios. Particular attention is paid to the existence of autocorrelations, their decay with the number of sweeps, and the resulting estimate of the corresponding errors. After testing our approach against closed-form solutions, we demonstrate the utility and flexibility of our method with applications to non-Gaussian models.","2021-11","2022-12-05 17:14:42","2023-03-19 10:58:51","2022-12-05 17:14:42","126231","","","581","","Physica A: Statistical Mechanics and its Applications","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\4543G9SW\Capuozzo e.a. - 2021 - Path integral Monte Carlo method for option pricin.pdf","","monte carlo; finance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SPI4W4S","journalArticle","2010","Devreese, Jeroen P. A.; Lemmens, Damiaan; Tempere, Jacques","Path integral approach to Asian options in the Black-Scholes model","Physica A: Statistical Mechanics and its Applications","","03784371","10.1016/j.physa.2009.10.020","http://arxiv.org/abs/0906.4456","We derive a closed-form solution for the price of an average price as well as an average strike geometric Asian option, by making use of the path integral formulation. Our results are compared to a numerical Monte Carlo simulation. We also develop a pricing formula for an Asian option with a barrier on a control process, combining the method of images with a partitioning of the set of paths according to the average along the path. This formula is exact when the correlation is zero, and is approximate when the correlation increases.","2010-02","2022-12-05 17:15:01","2023-03-19 10:58:08","2022-12-05 17:15:01","780-788","","4","389","","Physica A: Statistical Mechanics and its Applications","","","","","","","","en","","","","","arXiv.org","","arXiv:0906.4456 [q-fin]","","C:\Users\isido\Zotero\storage\TRU3Y9RR\Devreese e.a. - 2010 - Path integral approach to Asian options in the Bla.pdf","","finance","Quantitative Finance - Computational Finance; Quantitative Finance - Pricing of Securities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JR9ZTF7","preprint","2011","Xia, Yuan","Multilevel Monte Carlo method for jump-diffusion SDEs","","","","","http://arxiv.org/abs/1106.4730","We investigate the extension of the multilevel Monte Carlo path simulation method to jump-diﬀusion SDEs. We consider models with ﬁnite rate activity , using a jump-adapted discretisation in which the jump times are computed and added to the standard uniform discretisation times. The key component in multilevel analysis is the calculation of an expected payoﬀ diﬀerence between a coarse path simulation and a ﬁne path simulation with twice as many timesteps. If the Poisson jump rate is constant, the jump times are the same on both paths and the multilevel extension is relatively straightforward, but the implementation is more complex in the case of state-dependent jump rates for which the jump times naturally diﬀer.","2011-06-23","2022-12-05 17:41:12","2023-03-19 10:58:01","2022-12-05 17:41:12","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1106.4730 [q-fin]","","C:\Users\isido\Zotero\storage\YGXG767H\Xia - 2011 - Multilevel Monte Carlo method for jump-diffusion S.pdf","","monte carlo","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:1106.4730","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FV8BJ945","journalArticle","2011","Casella, Bruno; Roberts, Gareth O.","Exact Simulation of Jump-Diffusion Processes with Monte Carlo Applications","Methodology and Computing in Applied Probability","","1387-5841, 1573-7713","10.1007/s11009-009-9163-1","http://link.springer.com/10.1007/s11009-009-9163-1","We introduce a novel algorithm (JEA) to simulate exactly from a class of one-dimensional jump-diffusion processes with state-dependent intensity. The simulation of the continuous component builds on the recent Exact Algorithm ((1)). The simulation of the jump component instead employes a thinning algorithm with stochastic acceptance probabilities in the spirit of (14). In turn JEA allows unbiased Monte Carlo simulation of a wide class of functionals of the process’ trajectory, including discrete averages, max/min, crossing events, hitting times. Our numerical experiments show that the method outperforms Monte Carlo methods based on the Euler discretization.","2011-09","2022-12-05 17:46:55","2023-08-03 17:59:43","2022-12-05 17:46:55","449-473","","3","13","","Methodol Comput Appl Probab","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\6PDHDU6J\Casella en Roberts - 2011 - Exact Simulation of Jump-Diffusion Processes with .pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JUEPNLKV","conferencePaper","2009","Binder, Ilia; Braverman, Mark","The complexity of simulating Brownian Motion","Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms","978-0-89871-680-1 978-1-61197-306-8","","10.1137/1.9781611973068.7","https://epubs.siam.org/doi/10.1137/1.9781611973068.7","We analyze the complexity of the Walk on Spheres algorithm for simulating Brownian Motion in a domain Ω ⊂ Rd. The algorithm, which was ﬁrst proposed in the 1950s, produces samples from the hitting probability distribution of the Brownian Motion process on ∂Ω within an error of ε. The algorithm is used as a building block for solving a variety of diﬀerential equations, including the Dirichlet Problem.","2009-01-04","2022-12-07 07:37:52","2023-03-19 10:57:42","2022-12-07 07:37:52","58-67","","","","","","","","","","","Society for Industrial and Applied Mathematics","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\9LATAZYY\Binder en Braverman - 2009 - The complexity of simulating Brownian Motion.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms","","","","","","","","","","","","","","",""
"39YC8CRC","preprint","2022","Azzone, Michele; Baviera, Roberto","A fast Monte Carlo scheme for additive processes and option pricing","","","","","http://arxiv.org/abs/2112.08291","In this paper, we present a very fast Monte Carlo scheme for additive processes: the computational time is of the same order of magnitude of standard algorithms for Brownian motions. We analyze in detail numerical error sources and propose a technique that reduces the two major sources of error. We also compare our results with a benchmark method: the jump simulation with Gaussian approximation.","2022-11-18","2022-12-07 07:46:49","2022-12-07 07:46:49","2022-12-07 07:46:49","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2112.08291 [q-fin]","","C:\Users\isido\Zotero\storage\NKJIF6K7\Azzone en Baviera - 2022 - A fast Monte Carlo scheme for additive processes a.pdf","","","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:2112.08291","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94VFW5X6","preprint","2021","Herrmann, Samuel; Massin, Nicolas","Exact simulation of the first passage time through a given level for jump diffusions","","","","","http://arxiv.org/abs/2106.05560","Continuous-time stochastic processes play an important role in the description of random phenomena, it is therefore of prime interest to study particular variables depending on their paths, like stopping time for example. One approach consists in pointing out explicit expressions of the probability distributions, an other approach is rather based on the numerical generation of the random variables. We propose an algorithm in order to generate the ﬁrst passage time through a given level of a one-dimensional jump diﬀusion. This process satisﬁes a stochastic diﬀerential equation driven by a Brownian motion and subject to random shocks characterized by an independent Poisson process. Our algorithm belongs to the family of rejection sampling procedures, also called exact simulation in this context: the outcome of the algorithm and the stopping time under consideration are identically distributed. It is based on both the exact simulation of the diﬀusion at a given time and on the exact simulation of ﬁrst passage time for continuous diﬀusions. It is therefore based on an extension of the algorithm introduced by Herrmann and Zucca [16] in the continuous framework. The challenge here is to generate the exact position of a continuous diﬀusion conditionally to the fact that the given level has not been reached before. We present the construction of the algorithm and give numerical illustrations, conditions on the recurrence of jump diﬀusions are also discussed.","2021-06-10","2022-12-07 07:48:30","2023-03-19 10:56:47","2022-12-07 07:48:30","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2106.05560 [math]","","C:\Users\isido\Zotero\storage\DBB4B6I2\Herrmann en Massin - 2021 - Exact simulation of the first passage time through.pdf","","brownian motion","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:2106.05560","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NR6SIWF","preprint","2021","Llorente, F.; Martino, L.; Read, J.; Delgado, D.","A survey of Monte Carlo methods for noisy and costly densities with application to reinforcement learning","","","","","http://arxiv.org/abs/2108.00490","This survey gives an overview of Monte Carlo methodologies using surrogate models, for dealing with densities which are intractable, costly, and/or noisy. This type of problem can be found in numerous real-world scenarios, including stochastic optimization and reinforcement learning, where each evaluation of a density function may incur some computationally-expensive or even physical (real-world activity) cost, likely to give diﬀerent results each time. The surrogate model does not incur this cost, but there are important trade-oﬀs and considerations involved in the choice and design of such methodologies. We classify the diﬀerent methodologies into three main classes and describe speciﬁc instances of algorithms under a uniﬁed notation. A modular scheme which encompasses the considered methods is also presented. A range of application scenarios is discussed, with special attention to the likelihood-free setting and reinforcement learning. Several numerical comparisons are also provided.","2021-09-15","2022-12-07 08:38:22","2022-12-07 08:38:23","2022-12-07 08:38:22","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2108.00490 [cs, stat]","","C:\Users\isido\Zotero\storage\ZXRFKLSV\Llorente e.a. - 2021 - A survey of Monte Carlo methods for noisy and cost.pdf","","","Computer Science - Machine Learning; Statistics - Machine Learning; Statistics - Computation","","","","","","","","","","","","","","","","","","","arXiv:2108.00490","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ERJI879C","journalArticle","2012","Browne, Cameron B.; Powley, Edward; Whitehouse, Daniel; Lucas, Simon M.; Cowling, Peter I.; Rohlfshagen, Philipp; Tavener, Stephen; Perez, Diego; Samothrakis, Spyridon; Colton, Simon","A Survey of Monte Carlo Tree Search Methods","IEEE Transactions on Computational Intelligence and AI in Games","","1943-068X, 1943-0698","10.1109/TCIAIG.2012.2186810","http://ieeexplore.ieee.org/document/6145622/","Monte Carlo Tree Search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difﬁcult problem of computer Go, but has also proved beneﬁcial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the ﬁrst ﬁve years of MCTS research. We outline the core algorithm’s derivation, impart some structure on the many variations and enhancements that have been proposed, and summarise the results from the key game and non-game domains to which MCTS methods have been applied. A number of open research questions indicate that the ﬁeld is ripe for future work.","2012-03","2022-12-07 08:40:15","2022-12-07 08:40:15","2022-12-07 08:40:15","1-43","","1","4","","IEEE Trans. Comput. Intell. AI Games","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\E9YVZ4L9\Browne e.a. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRWQANKV","journalArticle","2020","Luengo, D.; Martino, L.; Bugallo, M.; Elvira, V.; S ärkkä, S.","A Survey of Monte Carlo Methods for Parameter Estimation","EURASIP Journal on Advances in Signal Processing","","1687-6180","10.1186/s13634-020-00675-6","http://arxiv.org/abs/2107.11820","Statistical signal processing applications usually require the estimation of some parameters of interest given a set of observed data. These estimates are typically obtained either by solving a multi-variate optimization problem, as in the maximum likelihood (ML) or maximum a posteriori (MAP) estimators, or by performing a multi-dimensional integration, as in the minimum mean squared error (MMSE) estimators. Unfortunately, analytical expressions for these estimators cannot be found in most real-world applications, and the Monte Carlo (MC) methodology is one feasible approach. MC methods proceed by drawing random samples, either from the desired distribution or from a simpler one, and using them to compute consistent estimators. The most important families of MC algorithms are Markov chain MC (MCMC) and importance sampling (IS). On the one hand, MCMC methods draw samples from a proposal density, building then an ergodic Markov chain whose stationary distribution is the desired distribution by accepting or rejecting those candidate samples as the new state of the chain. On the other hand, IS techniques draw samples from a simple proposal density, and then assign them suitable weights that measure their quality in some appropriate way. In this paper, we perform a thorough review of MC methods for the estimation of static parameters in signal processing applications. A historical note on the development of MC schemes is also provided, followed by the basic MC method and a brief description of the rejection sampling (RS) algorithm, as well as three sections describing many of the most relevant MCMC and IS algorithms, and their combined use. Finally, ﬁve numerical examples (including the estimation of the parameters of a chaotic system, a localization problem in wireless sensor networks and a spectral analysis application) are provided in order to demonstrate the performance of the described approaches.","2020-12","2022-12-07 08:42:00","2022-12-07 08:42:01","2022-12-07 08:42:00","25","","1","2020","","EURASIP J. Adv. Signal Process.","","","","","","","","en","","","","","arXiv.org","","arXiv:2107.11820 [cs, eess, math, stat]","","C:\Users\isido\Zotero\storage\AW7RXXX8\Luengo e.a. - 2020 - A Survey of Monte Carlo Methods for Parameter Esti.pdf","","","Mathematics - Numerical Analysis; Statistics - Computation; Computer Science - Artificial Intelligence; Electrical Engineering and Systems Science - Signal Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPTA6MLJ","bookSection","2010","Devroye, Luc","On Exact Simulation Algorithms for Some Distributions Related to Brownian Motion and Brownian Meanders","Recent Developments in Applied Probability and Statistics","978-3-7908-2597-8 978-3-7908-2598-5","","","http://link.springer.com/10.1007/978-3-7908-2598-5_1","We survey and develop exact random variate generators for several distributions related to Brownian motion, Brownian bridge, Brownian excursion, Brownian meander, and related restricted Brownian motion processes. Various parameters such as maxima and ﬁrst passage times are dealt with at length. We are particularly interested in simulating process variables in expected time uniformly bounded over all parameters.","2010","2022-12-08 15:17:42","2023-03-19 10:54:32","2022-12-08 15:17:42","1-35","","","","","","","","","","","Physica-Verlag HD","Heidelberg","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-3-7908-2598-5_1","","C:\Users\isido\Zotero\storage\IKVR3JRG\Devroye - 2010 - On Exact Simulation Algorithms for Some Distributi.pdf","","brownian motion","","Devroye, Luc; Karasözen, Bülent; Kohler, Michael; Korn, Ralf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YDUMFRIC","preprint","2017","Dieker, A. B.; Lagos, Guido","On the Euler discretization error of Brownian motion about random times","","","","","http://arxiv.org/abs/1708.04356","In this paper we derive weak limits for the discretization errors of sampling barrierhitting and extreme events of Brownian motion by using the Euler discretization simulation method. Speciﬁcally, we consider the Euler discretization approximation of Brownian motion to sample barrier-hitting events, i.e. hitting for the ﬁrst time a deterministic “barrier” function; and to sample extreme events, i.e. attaining a minimum on a given compact time interval or unbounded closed time interval. For each case we study the discretization error between the actual time the event occurs versus the time the event occurs for the discretized path, and also the discretization error on the position of the Brownian motion at these times. We show limits in distribution for the discretization errors normalized by their convergence rate, and give closed-form analytic expressions for the limiting random variables. Additionally, we use these limits to study the asymptotic behaviour of Gaussian random walks in the following situations: (1.) the overshoot of a Gaussian walk above a barrier that goes to inﬁnity; (2.) the minimum of a Gaussian walk compared to the minimum of the Brownian motion obtained when interpolating the Gaussian walk with Brownian bridges, both up to the same time horizon that goes to inﬁnity; and (3.) the global minimum of a Gaussian walk compared to the global minimum of the Brownian motion obtained when interpolating the Gaussian walk with Brownian bridges, when both have the same positive drift decreasing to zero. In deriving these limits in distribution we provide a uniﬁed framew√ork to understand the relation between several papers where the constant −ζ(1/2)/ 2π has appeared, where ζ is the Riemann zeta function. In particular, we show that this constant is the mean of some of the limiting distributions we derive.","2017-08-14","2022-12-08 15:19:28","2023-03-19 10:54:17","2022-12-08 15:19:28","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1708.04356 [math]","","C:\Users\isido\Zotero\storage\BPSGSE6D\Dieker en Lagos - 2017 - On the Euler discretization error of Brownian moti.pdf","","brownian motion","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1708.04356","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YI8CANNN","journalArticle","2013","Xu, Lin; Zhu, Dongjin","On the Distribution of First Exit Time for Brownian Motion with Double Linear Time-Dependent Barriers","ISRN Applied Mathematics","","2090-5572","10.1155/2013/865347","https://www.hindawi.com/journals/isrn/2013/865347/","This paper focuses on the first exit time for a Brownian motion with a double linear time-dependent barrier specified by                                                   y                   =                   a                   +                   b                   t                                               ,                                                   y                   =                   c                   t                                               , (                                a                 >                 0                              ,                                b                 <                 0                              ,                                c                 >                 0                              ). We are concerned in this paper with the distribution of the Brownian motion hitting the upper barrier before hitting the lower linear barrier. The main method we applied here is the Girsanov transform formula. As a result, we expressed the density of such exit time in terms of a finite series. This result principally provides us an analytical expression for the distribution of the aforementioned exit time and  an easy way to compute the distribution of first exit time numerically.","2013-09-26","2022-12-08 15:31:50","2023-03-19 10:54:01","2022-12-08 15:31:50","1-5","","","2013","","ISRN Applied Mathematics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\R3QCYSHV\Xu en Zhu - 2013 - On the Distribution of First Exit Time for Brownia.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PVWRGL2","journalArticle","2012","Beskos, Alexandros; Peluchetti, Stefano; Roberts, Gareth","$\varepsilon$-Strong simulation of the Brownian path","Bernoulli","","1350-7265","10.3150/11-BEJ383","https://projecteuclid.org/journals/bernoulli/volume-18/issue-4/varepsilon-Strong-simulation-of-the-Brownian-path/10.3150/11-BEJ383.full","We present an iterative sampling method which delivers upper and lower bounding processes for the Brownian path. We develop such processes with particular emphasis on being able to unbiasedly simulate them on a personal computer. The dominating processes converge almost surely in the supremum and L1 norms. In particular, the rate of converge in L1 is of the order O(K−1/2), K denoting the computing cost. The a.s. enfolding of the Brownian path can be exploited in Monte Carlo applications involving Brownian paths whence our algorithm (termed the ε-strong algorithm) can deliver unbiased Monte Carlo estimators over path expectations, overcoming discretisation errors characterising standard approaches. We will show analytical results from applications of the ε-strong algorithm for estimating expectations arising in option pricing. We will also illustrate that individual steps of the algorithm can be of separate interest, giving new simulation methods for interesting Brownian distributions.","2012-11-01","2022-12-08 15:51:49","2023-08-03 17:59:11","2022-12-08 15:51:49","","","4","18","","Bernoulli","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\G8BZTKXZ\Beskos e.a. - 2012 - $varepsilon$-Strong simulation of the Brownian pa.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPW2CNRW","journalArticle","2002","Metwally, Steve A.K.; Atiya, Amir F.","Using Brownian Bridge for Fast Simulation of Jump-Diffusion Processes and Barrier Options","The Journal of Derivatives","","1074-1240, 2168-8524","10.3905/jod.2002.319189","http://jod.pm-research.com/lookup/doi/10.3905/jod.2002.319189","Barrier options are one of the most popular derivatives in the financial markets. The authors present a fast and unbiased Monte Carlo approach to pricing barrier options when the underlying security follows a simple jump-diffusion process with constant parameters and a continuously monitored barrier. Two algorithms are based on the Brownian bridge concept. The first one is based on a sampling approach to evaluate an integral that results from application of the Brownian bridge. The second approach approximates that integral using a Taylor series expansion. Both methods significantly reduce bias and speed convergence compared to the standard Monte Carlo simulation approach. For example, the first method achieves zero bias. In addition, it is about 100 times faster than the conventional Monte Carlo method that achieves acceptable bias. In developing the second algorithm, the authors derive a novel approach for obtaining a first-passage time density integral using a Taylor series expansion. This approach is potentially useful in other applications, where the expectation of some function over the first-passage time distribution needs to be derived.","2002-08-31","2022-12-08 16:05:02","2023-08-03 17:58:51","2022-12-08 16:05:02","43-54","","1","10","","JOD","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\ABLIPAX8\Metwally en Atiya - 2002 - Using Brownian Bridge for Fast Simulation of Jump-.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E94MWYD7","encyclopediaArticle","2022","","Reflection principle (Wiener process)","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Reflection_principle_(Wiener_process)&oldid=1111342822","In the theory of probability for stochastic processes, the reflection principle for a Wiener process states that if the path of a Wiener process f(t)  reaches a value f(s) = a at time t = s,  then the subsequent path after time s has the same distribution as the reflection of the subsequent path about the value a. More formally, the reflection principle refers to a lemma concerning the distribution of the supremum of the Wiener process, or Brownian motion. The result relates the distribution of the supremum of Brownian motion up to time t to the distribution of the process at time t. It is a corollary of the strong Markov property of Brownian motion.","2022-09-20","2022-12-08 16:23:20","2023-03-19 10:51:37","2022-12-08 16:23:20","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1111342822","","C:\Users\isido\Zotero\storage\LHGS64H3\Reflection_principle_(Wiener_process).html","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQYEVNSX","journalArticle","2006","Deaconu, Madalina; Lejay, Antoine","A Random Walk on Rectangles Algorithm","Methodology and Computing in Applied Probability","","1387-5841, 1573-7713","10.1007/s11009-006-7292-3","http://link.springer.com/10.1007/s11009-006-7292-3","In this article, we introduce an algorithm that simulates eﬃciently the ﬁrst exit time and position from a rectangle (or a parallelepiped) for a Brownian motion that starts at any point inside. This method provides an exact way to simulate the ﬁrst exit time and position from any polygonal domain and then to solve some Dirichlet problems, whatever the dimension. This method can be used as a replacement or complement of the method of the random walk on spheres and can be easily adapted to deal with Neumann boundary conditions or Brownian motion with a constant drift.","2006-03","2022-12-13 07:57:59","2023-03-19 10:51:33","2022-12-13 07:57:59","135-151","","1","8","","Methodol Comput Appl Probab","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\LETY9EC9\Deaconu en Lejay - 2006 - A Random Walk on Rectangles Algorithm.pdf","","monte carlo; PDE; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4RKK8AUU","journalArticle","2015","Hwang, Chi-Ok; Hong, Sungpyo; Kim, Jinwoo","Off-centered “Walk-on-Spheres” (WOS) algorithm","Journal of Computational Physics","","00219991","10.1016/j.jcp.2015.10.002","https://linkinghub.elsevier.com/retrieve/pii/S0021999115006646","The “Walk-on-Spheres” (WOS) algorithm has played the central role in simulating the diffusion process in Diffusion Monte Carlo methods. In this paper, based on the isomorphism between the electrostatic Poisson problem and the corresponding diffusion motion expectation of the first-passage, we develop an off-centered WOS algorithm to replace the old WOS one. We find that the new off-centered WOS algorithm is much more efficient than the old one.","2015-12","2022-12-13 11:30:39","2023-08-03 17:58:24","2022-12-13 11:30:39","331-335","","","303","","Journal of Computational Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\3YHCI5ZF\Hwang e.a. - 2015 - Off-centered “Walk-on-Spheres” (WOS) algorithm.pdf","","monte carlo; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RK5YI5P9","preprint","2022","Yılmazer, Ekrem Fatih; Vicini, Delio; Jakob, Wenzel","Solving Inverse PDE Problems using Grid-Free Monte Carlo Estimators","","","","","http://arxiv.org/abs/2208.02114","Modeling physical phenomena like heat transport and diffusion is crucially dependent on the numerical solution of partial differential equations (PDEs). A PDE solver finds the solution given coefficients and a boundary condition, whereas an inverse PDE solver goes the opposite way and reconstructs these inputs from an existing solution. In this article, we investigate techniques for solving inverse PDE problems using a gradient-based methodology. Conventional PDE solvers based on the finite element method require a domain meshing step that can be fragile and costly. Grid-free Monte Carlo methods instead stochastically sample paths using variations of the walk on spheres algorithm to construct an unbiased estimator of the solution. The uncanny similarity of these methods to physically-based rendering algorithms has been observed by several recent works. In the area of rendering, recent progress has led to the development of efficient unbiased derivative estimators. They solve an adjoint form of the problem and exploit arithmetic invertibility to compute gradients using a constant amount of memory and linear time complexity. Could these two lines of work be combined to compute cheap parametric derivatives of a grid-free PDE solver? We investigate this question and present preliminary results. CCS Concepts: • Mathematics of computing → Partial differential equations; • Computing methodologies → Rendering.","2022-08-03","2022-12-13 11:39:58","2023-03-19 10:51:01","2022-12-13 11:39:58","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2208.02114 [cs, math]","","C:\Users\isido\Zotero\storage\RQAZ53HP\Yılmazer e.a. - 2022 - Solving Inverse PDE Problems using Grid-Free Monte.pdf","","monte carlo; walk on spheres; rendering; inverse problem","68U05; Computer Science - Graphics; Mathematics - Analysis of PDEs","","","","","","","","","","","","","","","","","","","arXiv:2208.02114","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7DZP3NLW","journalArticle","1996","Kosztin, Ioan; Faber, Byron; Schulten, Klaus","Introduction to the diffusion Monte Carlo method","American Journal of Physics","","0002-9505, 1943-2909","10.1119/1.18168","http://aapt.scitation.org/doi/10.1119/1.18168","A self–contained and tutorial presentation of the diffusion Monte Carlo method for determining the ground state energy and wave function of quantum systems is provided. First, the theoretical basis of the method is derived and then a numerical algorithm is formulated. The algorithm is applied to determine the ground state of the harmonic oscillator, the Morse oscillator, the hydrogen atom, and the electronic ground state of the H+ 2 ion and of the H2 molecule. A computer program on which the sample calculations are based is available upon request.","1996-05","2022-12-13 11:53:23","2023-08-03 17:58:07","2022-12-13 11:53:23","633-644","","5","64","","American Journal of Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\UJQSNZJ3\Kosztin e.a. - 1996 - Introduction to the diffusion Monte Carlo method.pdf","","walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FE7DSJT7","journalArticle","2003","Hwang, Chi-Ok; Mascagni, Michael","Analysis and comparison of Green’s function first-passage algorithms with “Walk on Spheres” algorithms","Mathematics and Computers in Simulation","","03784754","10.1016/S0378-4754(03)00091-0","https://linkinghub.elsevier.com/retrieve/pii/S0378475403000910","We analyze the optimization of the running times of Green’s function ﬁrst-passage (GFFP) algorithms. The running times for these new ﬁrst-passage (FP) algorithms [1–4], which use exact Green’s functions for the Laplacian to eliminate the absorption layer in the “walk on spheres” (WOS) method [5–9], are compared with those for WOS algorithms. It has been empirically observed that GFFP algorithms are more eﬃcient than WOS algorithms when high accuracy is required [2–4]. Additionally, it has been observed that there is always an optimal distance from the surface of the absorbing boundary, δI , for a GFFP algorithm within which a FP surface can be permitted to intersect the boundary [2–4]. In this paper, we will provide a rigorous complexity analysis consistent with these observations. This analysis is based on estimating the numbers of WOS and GFFP steps needed for absorption on the boundary, and the complexity and running times of each WOS and GFFP step. As an illustration, we analyze the running times for calculating the capacitance of the unit cube using both GFFP and WOS.","2003-11","2022-12-18 13:10:56","2023-03-19 10:49:57","2022-12-18 13:10:56","605-613","","6","63","","Mathematics and Computers in Simulation","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\HBPK37PS\Hwang en Mascagni - 2003 - Analysis and comparison of Green’s function first-.pdf","","walk on spheres; green function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JC22BPH9","journalArticle","2001","Hwang, Chi-Ok; Given, James A.; Mascagni, Michael","The Simulation–Tabulation Method for Classical Diffusion Monte Carlo","Journal of Computational Physics","","00219991","10.1006/jcph.2001.6947","https://linkinghub.elsevier.com/retrieve/pii/S0021999101969475","Many important classes of problems in materials science and biotechnology require the solution of the Laplace or Poisson equation in disordered two-phase domains in which the phase interface is extensive and convoluted. Green’s function first-passage (GFFP) methods solve such problems efficiently by generalizing the “walk on spheres” (WOS) method to allow first-passage (FP) domains to be not just spheres but a wide variety of geometrical shapes. (In particular, this solves the difficulty of slow convergence with WOS by allowing FP domains that contain patches of the phase interface.) Previous studies accomplished this by using geometries for which the Green’s function was available in quasi-analytic form. Here, we extend these studies by using the simulation–tabulation (ST) method. We simulate and then tabulate surface Green’s functions that cannot be obtained analytically. The ST method is applied to the Solc–Stockmayer model with zero potential, to the mean trapping rate of a diffusing particle in a domain of nonoverlapping spherical traps, and to the effective conductivity for perfectly insulating, nonoverlapping spherical inclusions in a matrix of finite conductivity. In all cases, this class of algorithms provides the most efficient methods known to solve these problems to high accuracy.","2001-12","2022-12-18 13:14:08","2023-08-03 17:57:51","2022-12-18 13:14:08","925-946","","2","174","","Journal of Computational Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\BTSXYC8S\Hwang e.a. - 2001 - The Simulation–Tabulation Method for Classical Dif.pdf","","brownian motion; green function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZKL4UBC","journalArticle","1999","Milstein, G. N.; Tretyakov, M. V.","Simulation of a space-time bounded diffusion","The Annals of Applied Probability","","1050-5164","10.1214/aoap/1029962812","https://projecteuclid.org/journals/annals-of-applied-probability/volume-9/issue-3/Simulation-of-a-space-time-bounded-diffusion/10.1214/aoap/1029962812.full","Mean-square approximations, which ensure boundedness of both time and space increments, are constructed for stochastic differential equations in a bounded domain. The proposed algorithms are based on a space–time discretization using a random walk over boundaries of small space–time parallelepipeds. To realize the algorithms, exact distributions for exit points of the space–time Brownian motion from a space–time parallelepiped are given. Convergence theorems are stated for the proposed algorithms. A method of approximate searching for exit points of the space–time diffusion from the bounded domain is constructed. Results of several numerical tests are presented.","1999-08-01","2022-12-20 11:10:43","2023-08-03 17:57:35","2022-12-20 11:10:43","","","3","9","","Ann. Appl. Probab.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\3A6SZGK6\Milstein en Tretyakov - 1999 - Simulation of a space-time bounded diffusion.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8S65NS4H","journalArticle","2016","Allab, Imene; Watier, Francois","First-passage Time Estimation of Diffusion Processes through Time-Varying Boundaries with an Application in Finance","International Journal of Statistics and Probability","","1927-7040, 1927-7032","10.5539/ijsp.v6n1p59","http://www.ccsenet.org/journal/index.php/ijsp/article/view/63088","In this paper, we develop a Monte Carlo based algorithm for estimating the FPT (ﬁrst passage time) density of the solution of a one-dimensional time-homogeneous SDE (stochastic diﬀerential equation) through a time-dependent frontier. We consider Brownian bridges as well as local Daniels curve approximations to obtain tractable estimations of the FPT probability between successive points of a simulated path of the process. Under mild assumptions, a (unique) Daniels curve local approximation can easily be obtained by explicitly solving a non-linear system of equations.","2016-12-20","2022-12-20 11:13:32","2023-03-19 10:49:12","2022-12-20 11:13:32","59","","1","6","","IJSP","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\8DTMPTXR\Allab en Watier - 2016 - First-passage Time Estimation of Diffusion Process.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQLG9NPZ","journalArticle","2016","Herrmann, Samuel; Tanré, Etienne","The first-passage time of the Brownian motion to a curved boundary: an algorithmic approach","SIAM Journal on Scientific Computing","","1064-8275, 1095-7197","10.1137/151006172","http://arxiv.org/abs/1501.07060","Under some weak conditions, the ﬁrst-passage time of the Brownian motion to a continuous curved boundary is an almost surely ﬁnite stopping time. Its probability density function (pdf) is explicitly known only in few particular cases. Several mathematical studies proposed to approximate the pdf in a quite general framework or even to simulate this hitting time using a discrete time approximation of the Brownian motion. The authors study a new algorithm which permits to simulate the ﬁrst-passage time using an iterating procedure. The convergence rate presented in this paper suggests that the method is very eﬃcient.","2016-01","2022-12-20 11:18:59","2023-03-19 10:49:08","2022-12-20 11:18:59","A196-A215","","1","38","","SIAM J. Sci. Comput.","The first-passage time of the Brownian motion to a curved boundary","","","","","","","en","","","","","arXiv.org","","arXiv:1501.07060 [math]","","C:\Users\isido\Zotero\storage\5NRAE68H\Herrmann en Tanré - 2016 - The first-passage time of the Brownian motion to a.pdf","","brownian motion","Mathematics - Probability; 65C05, 65N75, 60G40","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2VT9SM9","journalArticle","2013","Lejay, Antoine; Maire, Sylvain","New Monte Carlo schemes for simulating diffusions in discontinuous media","Journal of Computational and Applied Mathematics","","03770427","10.1016/j.cam.2012.12.013","https://linkinghub.elsevier.com/retrieve/pii/S0377042712005444","We introduce new Monte Carlo simulation schemes for diﬀusions in a discontinuous media divided in subdomains with piecewise constant diﬀusivity. These schemes are higher order extensions of the usual schemes and take into account the two dimensional aspects of the diﬀusion at the interface between subdomains. This is achieved using either stochastic processes techniques or an approach based on ﬁnite diﬀerences. Numerical tests on elliptic, parabolic and eigenvalue problems involving an operator in divergence form show the eﬃciency of these new schemes.","2013-06","2022-12-20 11:32:05","2023-03-19 10:48:59","2022-12-20 11:32:05","97-116","","","245","","Journal of Computational and Applied Mathematics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\U84MVIQQ\Lejay en Maire - 2013 - New Monte Carlo schemes for simulating diffusions .pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYVUVPLG","preprint","2015","Yang, Xuxin; Rasila, Antti; Sottinen, Tommi","Walk on Spheres Algorithm for Helmholtz and Yukawa Equations via Duffin Correspondence","","","","","http://arxiv.org/abs/1512.07725","We show that a constant-potential time-independent Schro¨dinger equation with Dirichlet boundary data can be reformulated as a Laplace equation with Dirichlet boundary data. With this reformulation, which we call the Duﬃn correspondence, we provide a classical Walk On Spheres (WOS) algorithm for Monte Carlo simulation of the solutions of the boundary value problem. We compare the obtained Duﬃn WOS algorithm with existing modiﬁed WOS algorithms.","2015-12-24","2022-12-20 11:34:46","2023-03-19 10:48:42","2022-12-20 11:34:46","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1512.07725 [math]","","C:\Users\isido\Zotero\storage\3XFZ3E64\Yang e.a. - 2015 - Walk on Spheres Algorithm for Helmholtz and Yukawa.pdf","","monte carlo; PDE; walk on spheres","Mathematics - Probability; Mathematics - Numerical Analysis; Mathematics - Analysis of PDEs; 65C05, 68U20, 35Q40","","","","","","","","","","","","","","","","","","","arXiv:1512.07725","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2ZFT9T2","encyclopediaArticle","2022","","Volterra integral equation","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Volterra_integral_equation&oldid=1125547908","In mathematics, the Volterra integral equations are a special type of integral equations. They are divided into two groups referred to as the first and the second kind. A linear Volterra equation of the first kind is                        f         (         t         )         =                    ∫                        a                                   t                             K         (         t         ,         s         )                  x         (         s         )                  d         s                 {\displaystyle f(t)=\int _{a}^{t}K(t,s)\,x(s)\,ds}   where f is a given function and x is an unknown function to be solved for.  A linear Volterra equation of the second kind is                        x         (         t         )         =         f         (         t         )         +                    ∫                        a                                   t                             K         (         t         ,         s         )         x         (         s         )                  d         s         .                 {\displaystyle x(t)=f(t)+\int _{a}^{t}K(t,s)x(s)\,ds.}   In operator theory, and in Fredholm theory, the corresponding operators are called Volterra operators.  A useful method to solve such equations, the Adomian decomposition method, is due to George Adomian. A linear Volterra integral equation is a convolution equation if                        x         (         t         )         =         f         (         t         )         +                    ∫                                       t                                0                                                               t                             K         (         t         −         s         )         x         (         s         )                  d         s         .                 {\displaystyle x(t)=f(t)+\int _{t_{0}}^{t}K(t-s)x(s)\,ds.}   The function                         K                 {\displaystyle K}    in the integral is called the kernel. Such equations can be analyzed and solved by means of Laplace transform techniques. For a weakly singular kernel of the form                         K         (         t         ,         s         )         =         (                    t                        2                             −                    s                        2                                        )                        −             α                                     {\displaystyle K(t,s)=(t^{2}-s^{2})^{-\alpha }}    with                         0         <         α         <         1                 {\displaystyle 0<\alpha <1}   , Volterra integral equation of the first kind can conveniently be transformed into a classical Abel integral equation.  The Volterra integral equations were introduced by Vito Volterra and then studied by Traian Lalescu in his 1908 thesis, Sur les équations de Volterra, written under the direction of Émile Picard.   In 1911, Lalescu wrote the first book ever on integral equations. Volterra integral equations find application in demography as Lotka's integral equation, the study of viscoelastic materials, in actuarial science through the renewal equation, and in fluid mechanics to describe the flow behavior near finite-sized boundaries.","2022-12-04","2022-12-20 11:41:19","2023-03-19 10:48:02","2022-12-20 11:41:19","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1125547908","","C:\Users\isido\Zotero\storage\BXA6JUFN\Volterra_integral_equation.html","","integral equations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSIFH68Z","preprint","2017","Herrmann, Samuel; Zucca, Cristina","Exact simulation of the first-passage time of diffusions","","","","","http://arxiv.org/abs/1705.06881","Since diﬀusion processes arise in so many diﬀerent ﬁelds, eﬃcient technics for the simulation of sample paths, like discretization schemes, represent crucial tools in applied probability. Such methods permit to obtain approximations of the ﬁrst-passage times as a by-product. For eﬃciency reasons, it is particularly challenging to simulate directly this hitting time by avoiding to construct the whole paths. In the Brownian case, the distribution of the ﬁrst-passage time is explicitly known and can be easily used for simulation purposes. The authors introduce a new rejection sampling algorithm which permits to perform an exact simulation of the ﬁrst-passage time for general one-dimensional diﬀusion processes. The efﬁciency of the method, which is essentially based on Girsanov’s transformation, is described through theoretical results and numerical examples.","2017-05-19","2022-12-20 11:45:15","2023-03-19 10:47:55","2022-12-20 11:45:15","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1705.06881 [math]","","C:\Users\isido\Zotero\storage\UZ8C3VE3\Herrmann en Zucca - 2017 - Exact simulation of the first-passage time of diff.pdf","","brownian motion","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1705.06881","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6S2E2MV5","journalArticle","","Drabeck, Florian","Monte Carlo Simulation of Boundary Crossing Probabilities for a Brownian Motion and Curved Boundaries","","","","","","We are concerned with the probability that a standard Brownian motion W (t) crosses a curved boundary c(t) on a  nite interval [0, T ]. Let this probability be denoted by Q(c(t); T ). Except for linear functions c(t) and a few other special cases no explicit, analytic formula for Q(c(t); T ) is available. Thus numerical methods need to be applied for general boundaries to obtain approximate solutions. Some authors use for example integral equations. However, most of these numerical methods are either intractable or di cult to asses in terms of their accuracy. Due to recent advances in research another way of estimating Q(c(t); T ) seems feasible: Monte Carlo Simulation. Wang and Pötzelberger (1997) derived an explicit formula for the boundary crossing probability of piecewise linear functions which has the form of an expectation. Based on this formula we proceed as follows: First we approximate the general boundary c(t) by a piecewise linear function cm(t) on a uniform partition 0 = t0 < t1... < tm = T . Then we simulate Brownian sample paths in order to evaluate the expectation in the formula of the authors for cm(t). The bias resulting when estimating Q(cm(t); T ) rather than Q(c(t); T ) can be bounded by a formula of Borovkov and Novikov (2005). Whereas the bias decreases at a rate of O(1/m2) for a partition rank m, the standard error due to Monte Carlo simulation only decays at a rate of O(1/√n), where n is the number of simulation cycles. Hence the standard deviation   or the variance respectively   is the main limiting factor when increasing the accuracy. The main goal of this dissertation is to  nd and evaluate variance reducing techniques in order to enhance the quality of the Monte Carlo estimator for Q(c(t); T ). Among the techniques we discuss are: • Antithetic Sampling, • Strati ed Sampling, • Importance Sampling, • Control Variates, • Transforming the original problem. We analyze each of these techniques thoroughly from a theoretical point of view. Further, we test each technique empirically through simulation experiments on several carefully chosen boundaries. In order to asses our results we set them in relation to a previously established benchmark. We are interested in the relative reduction in the mean squared error (= sum of the squared bias and variance) due to a given technique, where the computational e ort remains constant. As a result of this dissertation we derive some very potent techniques that yield a substantial improvement in terms of accuracy. We even discuss an approach that improves the rate at which our biased Monte Carlo estimator converges to the correct result.","","2022-12-20 11:47:54","2023-08-03 17:57:13","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\36MEIWXP\Drabeck - Monte Carlo Simulation of Boundary Crossing Probab.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2EV8VV9","journalArticle","2017","Jin, Zhiyong; Wang, Liqun","First Passage Time for Brownian Motion and Piecewise Linear Boundaries","Methodology and Computing in Applied Probability","","1387-5841, 1573-7713","10.1007/s11009-015-9475-2","http://link.springer.com/10.1007/s11009-015-9475-2","We propose a new approach to calculating the first passage time densities for Brownian motion crossing piecewise linear boundaries which can be discontinuous. Using this approach we obtain explicit formulas for the first passage densities and show that they are continuously differentiable except at the break points of the boundaries. Furthermore, these formulas can be used to approximate the first passage time distributions for general nonlinear boundaries. The numerical computation can be easily done by using the Monte Carlo integration, which is straightforward to implement. Some numerical examples are presented for illustration. This approach can be further extended to compute two-sided boundary crossing distributions.","2017-03","2022-12-20 11:52:56","2023-03-19 10:47:39","2022-12-20 11:52:56","237-253","","1","19","","Methodol Comput Appl Probab","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\BNBKMEFU\Jin en Wang - 2017 - First Passage Time for Brownian Motion and Piecewi.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRSNTZYG","journalArticle","2018","Sabelfeld, Karl K.","Application of the von Mises–Fisher distribution to Random Walk on Spheres method for solving high-dimensional diffusion–advection–reaction equations","Statistics & Probability Letters","","01677152","10.1016/j.spl.2018.03.002","https://linkinghub.elsevier.com/retrieve/pii/S0167715218301160","We suggest a new efficient and reliable random walk method, continuous both in space and time, for solving high-dimensional diffusion–advection–reaction equations. It is based on a discovered intrinsic relation between the von Mises–Fisher distribution on a sphere with this type of equations. It can be formulated as follows: the von Mises–Fisher distribution uniquely defines the solution of a diffusion–advection equation in any bounded or unbounded domain if the relevant boundary value problem for this equation satisfies regular existence and uniqueness conditions. Both two- and three-dimensional transient equations are included in our considerations. The accuracy and the cost of the suggested random walk on spheres method are estimated.","2018-07","2022-12-20 18:49:27","2023-03-19 10:47:33","2022-12-20 18:49:27","137-142","","","138","","Statistics & Probability Letters","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\E78HU5DQ\Sabelfeld - 2018 - Application of the von Mises–Fisher distribution t.pdf","","brownian motion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MXJ5LN5U","journalArticle","2022","Qi, Yang; Seyb, Dario; Bitterli, Benedikt; Jarosz, Wojciech","A bidirectional formulation for Walk on Spheres","Computer Graphics Forum","","0167-7055, 1467-8659","10.1111/cgf.14586","https://onlinelibrary.wiley.com/doi/10.1111/cgf.14586","Numerically solving partial differential equations (PDEs) is central to many applications in computer graphics and scientific modeling. Conventional methods for solving PDEs often need to discretize the space first, making them less efficient for complex geometry. Unlike conventional methods, the walk on spheres (WoS) algorithm recently introduced to graphics is a grid-free Monte Carlo method that can provide numerical solutions of Poisson equations without discretizing space. We draw analogies between WoS and classical rendering algorithms, and find that the WoS algorithm is conceptually equivalent to forward path tracing. Inspired by similar approaches in light transport, we propose a novel WoS reformulation that operates in the reverse direction, starting at source points and estimating the Green’s function at “sensor” points. Implementations of this algorithm show improvement over classical WoS in solving Poisson equation with sparse sources. Our approach opens exciting avenues for future algorithms for PDE estimation which, analogous to light transport, connect WoS walks starting from sensors and sources and combine different strategies for robust solution algorithms in all cases.","2022-07","2022-12-22 14:21:42","2023-03-19 10:47:06","2022-12-22 14:21:42","51-62","","4","41","","Computer Graphics Forum","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\Y6LCPRIN\Qi e.a. - 2022 - A bidirectional formulation for Walk on Spheres.pdf","","monte carlo; PDE; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E23XPQSS","journalArticle","2022","Rioux-Lavoie, Damien; Sugimoto, Ryusuke; Özdemir, Tümay; Shimada, Naoharu H.; Batty, Christopher; Nowrouzezahrai, Derek; Hachisuka, Toshiya","A Monte Carlo Method for Fluid Simulation","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3550454.3555450","https://dl.acm.org/doi/10.1145/3550454.3555450","We present a novel Monte Carlo-based fluid simulation approach capable of pointwise and stochastic estimation of fluid motion. Drawing on the Feynman-Kac representation of the vorticity transport equation, we propose a recursive Monte Carlo estimator of the Biot-Savart law and extend it with a stream function formulation that allows us to treat free-slip boundary conditions using a Walk-on-Spheres algorithm. Inspired by the Monte Carlo literature in rendering, we design and compare variance reduction schemes suited to a fluid simulation context for the first time, show its applicability to complex boundary settings, and detail a simple and practical implementation with temporal grid caching. We validate the correctness of our approach via quantitative and qualitative evaluations – across a range of settings and domain geometries – and thoroughly explore its parameters’ design space. Finally, we provide an in-depth discussion of several axes of future work building on this new numerical simulation modality. CCS Concepts: • Mathematics of computing → Probabilistic algorithms; Partial differential equations; • Computing methodologies → Modeling and simulation.","2022-12","2022-12-22 15:05:35","2023-03-19 10:46:52","2022-12-22 15:05:35","1-16","","6","41","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\76CW9YCY\Rioux-Lavoie e.a. - 2022 - A Monte Carlo Method for Fluid Simulation.pdf","","monte carlo; PDE; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YCBGETU","journalArticle","2019","Sabelfeld, Karl","Random walk on rectangles and parallelepipeds algorithm for solving transient anisotropic drift-diffusion-reaction problems","Monte Carlo Methods and Applications","","","10.1515/mcma-2019-2039","","In this paper a random walk on arbitrary rectangles (2D) and parallelepipeds (3D) algorithm is developed for solving transient anisotropic drift-diffusion-reaction equations. The method is meshless, both in space and time. The approach is based on a rigorous representation of the first passage time and exit point distributions for arbitrary rectangles and parallelepipeds. The probabilistic representation is then transformed to a form convenient for stochastic simulation. The method can be used to calculate fluxes to any desired part of the boundary, from arbitrary sources. A global version of the method we call here as a stochastic expansion from cell to cell (SECC) algorithm for calculating the whole solution field is suggested. Application of this method to solve a system of transport equations for electrons and holes in a semicoductor is discussed. This system consists of the continuity equations for particle densities and a Poisson equation for electrostatic potential. To validate the method we have derived a series of exact solutions of the drift-diffusion-reaction problem in a three-dimensional layer presented in the last section in details.","2019-05-10","2022-12-22 15:21:22","2023-03-19 10:46:37","","","","","25","","Monte Carlo Methods and Applications","","","","","","","","","","","","","ResearchGate","","","","","https://www.researchgate.net/publication/333002793_Random_walk_on_rectangles_and_parallelepipeds_algorithm_for_solving_transient_anisotropic_drift-diffusion-reaction_problems","monte carlo; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPFUSDD2","journalArticle","2017","Sabelfeld, Karl K.","Random walk on spheres algorithm for solving transient drift-diffusion-reaction problems","Monte Carlo Methods and Applications","","1569-3961","10.1515/mcma-2017-0113","https://www.degruyter.com/document/doi/10.1515/mcma-2017-0113/html","We suggest in this paper a Random Walk on Spheres (RWS) method for solving transient drift-diffusion-reaction problems which is an extension of our algorithm we developed recently [26] for solving steady-state drift-diffusion problems. Both two-dimensional and three-dimensional problems are solved. Survival probability, first passage time and the exit position for a sphere (disc) of the drift-diffusion-reaction process are explicitly derived from a generalized spherical integral relation we prove both for two-dimensional and three-dimensional problems. The distribution of the exit position on the sphere has the form of the von Mises–Fisher distribution which can be simulated efficiently. Rigorous expressions are derived in the case of constant velocity drift, but the algorithm is then extended to solve drift-diffusion-reaction problems with arbitrary varying drift velocity vector. The method can efficiently be applied to calculate the fluxes of the solution to any part of the boundary. This can be done by applying a reciprocity theorem which we prove here for the drift-diffusion-reaction problems with general boundary conditions. Applications of this approach to methods of cathodoluminescence (CL) and electron beam induced current (EBIC) imaging of defects and dislocations in semiconductors are presented.","2017-09-01","2022-12-22 15:24:08","2023-03-19 10:46:24","2022-12-22 15:24:08","189-212","","3","23","","","","","","","","","","en","","","","","www.degruyter.com","","Publisher: De Gruyter","","","","walk on spheres","cathodoluminescence; Drift-diffusion-reaction equation; reciprocity relation; Robin boundary conditions; spherical integral relation; von Mises–Fisher distribution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZU58MPQ4","journalArticle","1997","Veach, Eric","Robust Monte Carlo Methods for Light Transport Simulation. Ph.D. Dissertation. Stanford University.","Robust Monte Carlo Methods for Light Transport Simulation.","","","","","Light transport algorithms generate realistic images by simulating the emission and scattering of light in an artificial environment. Applications include lighting design, architecture, and computer animation, while related engineering disciplines include neutron transport and radiative heat transfer. The main challenge with these algorithms is the high complexity of the geometric, scattering, and illumination models that are typically used. In this dissertation, we develop new Monte Carlo techniques that greatly extend the range of input models for which light transport simulations are practical. Our contributions include new theoretical models, statistical methods, and rendering algorithms. We start by developing a rigorous theoretical basis for bidirectional light transport algorithms (those that combine direct and adjoint techniques). First, we propose a linear operator formulation that does not depend on any assumptions about the physical validity of the input scene. We show how to obtain mathematically correct results using a variety of bidirectional techniques. Next we derive a different formulation, such that for any physically valid input scene, the transport operators are symmetric. This symmetry is important for both theory and implementations, and is based on a new reciprocity condition that we derive for transmissive materials. Finally, we show how light transport can be formulated as an integral over a space of paths. This framework allows new sampling and integration techniques to be applied, such as the Metropolis sampling algorithm. We also use this model to investigate the limitations of unbiased Monte Carlo methods, and to show that certain kinds of paths cannot be sampled. Our statistical contributions include a new technique called multiple importance sampling, which can greatly increase the robustness of Monte Carlo integration. It uses more than one sampling technique to evaluate an integral, and then combines these samples in a vi way that is provably close to optimal. This leads to estimators that have low variance for a broad class of integrands. We also describe a new variance reduction technique called efficiency-optimized Russian roulette. Finally, we link these ideas together to obtain new Monte Carlo light transport algorithms. Bidirectional path tracing uses a family of different path sampling techniques that generate some path vertices starting from a light source, and some starting from a sensor. We show that when these techniques are combined using multiple importance sampling, a large range of difficult lighting effects can be handled efficiently. The algorithm is unbiased, handles arbitrary geometry and materials, and is relatively simple to implement. The second algorithm we describe is Metropolis light transport, inspired by the Metropolis sampling method from computational physics. Paths are generated by following a random walk through path space, such that the probability density of visiting each path is proportional to the contribution it makes to the ideal image. The resulting algorithm is unbiased, uses little storage, handles arbitrary geometry and materials, and can be orders of magnitude more efficient than previous unbiased approaches. It performs especially well on problems that are usually considered difficult, e.g. those involving bright indirect light, small geometric holes, or glossy surfaces. To our knowledge, this is the first application of the Metropolis method to transport problems of any kind.","1997","2022-12-23 16:13:42","2023-08-03 17:56:34","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\HDZ56Y9U\Veach - 1997 - Robust Monte Carlo Methods for Light Transport Sim.pdf","","importance sampling; monte carlo; rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EDUNYYUM","journalArticle","2018","Novák, Jan; Georgiev, Iliyan; Hanika, Johannes; Jarosz, Wojciech","Monte Carlo Methods for Volumetric Light Transport Simulation","Computer Graphics Forum","","01677055","10.1111/cgf.13383","https://onlinelibrary.wiley.com/doi/10.1111/cgf.13383","The wide adoption of path-tracing algorithms in high-end realistic rendering has stimulated many diverse research initiatives. In this paper we present a coherent survey of methods that utilize Monte Carlo integration for estimating light transport in scenes containing participating media. Our work complements the volume-rendering state-of-the-art report by Cerezo et al. [CPP∗05]; we review publications accumulated since its publication over a decade ago, and include earlier methods that are key for building light transport paths in a stochastic manner. We begin by describing analog and non-analog procedures for freepath sampling and discuss various expected-value, collision, and track-length estimators for computing transmittance. We then review the various rendering algorithms that employ these as building blocks for path sampling. Special attention is devoted to null-collision methods that utilize ﬁctitious matter to handle spatially varying densities; we import two “next-ﬂight” estimators originally developed in nuclear sciences. Whenever possible, we draw connections between image-synthesis techniques and methods from particle physics and neutron transport to provide the reader with a broader context.","2018-05","2022-12-23 16:33:45","2023-03-19 10:44:43","2022-12-23 16:33:45","551-576","","2","37","","Computer Graphics Forum","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\8Y3IJRVP\Novák e.a. - 2018 - Monte Carlo Methods for Volumetric Light Transport.pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KWRF38L","journalArticle","1990","Delaurentis, J.M; Romero, L.A","A Monte Carlo method for poisson's equation","Journal of Computational Physics","","00219991","10.1016/0021-9991(90)90199-B","https://linkinghub.elsevier.com/retrieve/pii/002199919090199B","This investigation presents an analysis of a Monte Carlo method for estimating local solutions to the Dirichlet problem for Poisson’s equation. The probabilistic algorithm consists of a modified “walk on spheres” that includes the effects from internal sources as part of the random process. A new derivation of the asymptotic expressions for the rate of convergence and average runtime of the algorithm is presented. These estimates are used to compare the Monte Carlo method with discrete difference schemes.Numerical experiments involving some two-dimensional problems contirm the efficiency of the probabilistic scheme. ‘87 1990 Academic Press. Inc","1990-09","2022-12-26 14:52:10","2023-08-03 17:54:32","2022-12-26 14:52:10","123-140","","1","90","","Journal of Computational Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\HV3ST26K\Delaurentis en Romero - 1990 - A Monte Carlo method for poisson's equation.pdf","","monte carlo; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2L8527MK","document","","","screened poisson equation via WoS","","","","","","","","2022-12-27 11:06:11","2023-03-19 10:43:30","","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\M6U2RW8L\screened poisson with WoS.pdf","","walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X46BAB9Z","journalArticle","2008","Halton, John H.","Sequential Monte Carlo for linear systems – a practical summary","Monte Carlo Methods and Applications","","0929-9629, 1569-3961","10.1515/MCMA.2008.001","https://www.degruyter.com/document/doi/10.1515/MCMA.2008.001/html","This paper has been written in response to many requests for a practical guide to the use of the technique of sequential Monte Carlo in the fast numerical solving of large systems of linear equations. This method, which I have used with considerable success to solve such problems, improving the tricks of the trade as I learned more about it, has suffered from some neglect through the mathematical difﬁculty, for some of those who are more interested in using the tool than in thinking about it, of some of the theoretical aspects of rigorously proving its validity, which – at this juncture – is no longer in question. I hope that I have now closed this gap in the related literature.","2008-01","2023-01-04 12:53:02","2023-03-19 10:38:20","2023-01-04 12:53:02","1-27","","1","14","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\YGVFCZZK\Halton - 2008 - Sequential Monte Carlo for linear systems – a prac.pdf","","monte carlo; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9T8ITHFC","journalArticle","2004","Efendiev, Y.; Ginting, V.; Hou, T. Y.","Multiscale Finite Element Methods for Nonlinear Problems and Their Applications","Communications in Mathematical Sciences","","15396746, 19450796","10.4310/CMS.2004.v2.n4.a2","http://www.intlpress.com/site/pub/pages/journals/items/cms/content/vols/0002/0004/a002/","In this paper we propose a generalization of multiscale ﬁnite element methods (MsFEM) to nonlinear problems. We study the convergence of the proposed method for nonlinear elliptic equations and propose an oversampling technique. Numerical examples demonstrate that the oversampling technique greatly reduces the error. The application of MsFEM to porous media ﬂows is considered. Finally, we describe further generalizations of MsFEM to nonlinear time-dependent equations and discuss the convergence of the method for various kinds of heterogeneities.","2004","2023-01-05 13:23:41","2023-03-19 10:38:06","2023-01-05 13:23:41","553-589","","4","2","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\T66753T4\Efendiev e.a. - 2004 - Multiscale Finite Element Methods for Nonlinear Pr.pdf","","PDE; nonlinear PDE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X59QGGAT","journalArticle","","Linetsky, Vadim","The Path Integral Approach to Financial Modeling and Options Pricing","","","","","","In this paper we review some applications of the path integral methodology of quantum mechanics to ﬁnancial modeling and options pricing. A path integral is deﬁned as a limit of the sequence of ﬁnite-dimensional integrals, in a much the same way as the Riemannian integral is deﬁned as a limit of the sequence of ﬁnite sums. The risk-neutral valuation formula for path-dependent options contingent upon multiple underlying assets admits an elegant representation in terms of path integrals (Feynman–Kac formula). The path integral representation of transition probability density (Green’s function) explicitly satisﬁes the diffusion PDE. Gaussian path integrals admit a closed-form solution given by the Van Vleck formula. Analytical approximations are obtained by means of the semiclassical (moments) expansion. Difﬁcult path integrals are computed by numerical procedures, such as Monte Carlo simulation or deterministic discretization schemes. Several examples of pathdependent options are treated to illustrate the theory (weighted Asian options, ﬂoating barrier options, and barrier options with ladder-like barriers).","","2023-01-05 15:46:56","2023-03-19 10:36:41","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\3ZDBN84W\Linetsky - The Path Integral Approach to Financial Modeling a.pdf","","examen padintegralen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J58S7M9S","journalArticle","2015","Das Sarma, Atish; Molla, Anisur Rahaman; Pandurangan, Gopal; Upfal, Eli","Fast distributed PageRank computation","Theoretical Computer Science","","03043975","10.1016/j.tcs.2014.04.003","https://linkinghub.elsevier.com/retrieve/pii/S0304397514002709","Over the last decade, PageRank has gained importance in a wide range of applications and domains, ever since it ﬁrst proved to be effective in determining node importance in large graphs (and was a pioneering idea behind Google’s search engine). In distributed computing alone, PageRank vector, or more generally random walk based quantities have been used for several different applications ranging from determining important nodes, load balancing, search, and identifying connectivity structures. Surprisingly, however, there has been little work towards designing provably eﬃcient fully-distributed algorithms for computing PageRank. The diﬃculty is that traditional matrix–vector multiplication style iterative methods may not always adapt well to the distributed setting owing to communication bandwidth restrictions and convergence rates.","2015-01","2023-01-05 19:24:52","2023-03-19 10:32:15","2023-01-05 19:24:52","113-121","","","561","","Theoretical Computer Science","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\FLUGEZHI\Das Sarma e.a. - 2015 - Fast distributed PageRank computation.pdf","","page rank","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PP2CP2XW","preprint","2021","Zhang, Qi; Yao, Zhengan; Liang, Jun; Zhang, Zanbo","An Advanced Parallel PageRank Algorithm","","","","","http://arxiv.org/abs/2112.07363","Initially used to rank web pages, PageRank has now been applied in may ﬁelds. In general case, there are plenty of special vertices such as dangling vertices and unreferenced vertices in the graph. Existing PageRank algorithms usually consider them as ‘bad‘ vertices since they may take troubles. However, in this paper, we propose a parallel PageRank algorithm which can take advantage of these special vertices. For this end, we ﬁrstly interpret PageRank from the information transmitting perspective and give a constructive deﬁnition of PageRank. Then, based on the information transmitting interpretation, a parallel PageRank algorithm which we call the Information Transmitting Algorithm(ITA) is proposed. We prove that the dangling vertices can increase ITA’s convergence rate and the unreferenced vertices and weak unreferenced vertices can decrease ITA’s calculations. Compared with the MONTE CARLO method, ITA has lower bandwidth requirement. Compared with the power method, ITA has higher convergence rate and generates less calculations. Finally, experimental results on four data sets demonstrate that ITA is 1.5-4 times faster than the power method and converges more uniformly.","2021-12-12","2023-01-05 19:43:35","2023-03-19 10:32:01","2023-01-05 19:43:35","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2112.07363 [cs]","","C:\Users\isido\Zotero\storage\YZS4ETMH\Zhang e.a. - 2021 - An Advanced Parallel PageRank Algorithm.pdf","","page rank","Computer Science - Networking and Internet Architecture","","","","","","","","","","","","","","","","","","","arXiv:2112.07363","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLCJPW43","conferencePaper","2019","Yang, Renchi; Xiao, Xiaokui; Wei, Zhewei; Bhowmick, Sourav S.; Zhao, Jun; Li, Rong-Hua","Efficient Estimation of Heat Kernel PageRank for Local Clustering","Proceedings of the 2019 International Conference on Management of Data","","","10.1145/3299869.3319886","http://arxiv.org/abs/1904.02707","Given an undirected graph G and a seed node s, the local clustering problem aims to identify a high-quality cluster containing s in time roughly proportional to the size of the cluster, regardless of the size of G. This problem finds numerous applications on large-scale graphs. Recently, heat kernel PageRank (HKPR), which is a measure of the proximity of nodes in graphs, is applied to this problem and found to be more efficient compared with prior methods. However, existing solutions for computing HKPR either are prohibitively expensive or provide unsatisfactory error approximation on HKPR values, rendering them impractical especially on billion-edge graphs. In this paper, we present TEA and TEA+, two novel local graph clustering algorithms based on HKPR, to address the aforementioned limitations. Specifically, these algorithms provide non-trivial theoretical guarantees in relative error of HKPR values and the time complexity. The basic idea is to utilize deterministic graph traversal to produce a rough estimation of exact HKPR vector, and then exploit Monte-Carlo random walks to refine the results in an optimized and non-trivial way. In particular, TEA+ offers practical efficiency and effectiveness due to non-trivial optimizations. Extensive experiments on real-world datasets demonstrate that TEA+ outperforms the state-of-the-art algorithm by more than four times on most benchmark datasets in terms of computational time when achieving the same clustering quality, and in particular, is an order of magnitude faster on large graphs including the widely studied Twitter and Friendster datasets.","2019-06-25","2023-01-05 19:45:34","2023-03-19 10:31:46","2023-01-05 19:45:34","1339-1356","","","","","","","","","","","","","en","","","","","arXiv.org","","arXiv:1904.02707 [cs]","","C:\Users\isido\Zotero\storage\AZE6CUJG\Yang e.a. - 2019 - Efficient Estimation of Heat Kernel PageRank for L.pdf","","page rank","Computer Science - Databases; Computer Science - Social and Information Networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRIUFVDM","preprint","2022","Salaün, Corentin; Gruson, Adrien; Hua, Binh-Son; Hachisuka, Toshiya; Singh, Gurprit","Regression-based Monte Carlo Integration","","","","","http://arxiv.org/abs/2211.07422","Monte Carlo integration is typically interpreted as an estimator of the expected value using stochastic samples. There exists an alternative interpretation in calculus where Monte Carlo integration can be seen as estimating a \emph{constant} function -- from the stochastic evaluations of the integrand -- that integrates to the original integral. The integral mean value theorem states that this \emph{constant} function should be the mean (or expectation) of the integrand. Since both interpretations result in the same estimator, little attention has been devoted to the calculus-oriented interpretation. We show that the calculus-oriented interpretation actually implies the possibility of using a more \emph{complex} function than a \emph{constant} one to construct a more efficient estimator for Monte Carlo integration. We build a new estimator based on this interpretation and relate our estimator to control variates with least-squares regression on the stochastic samples of the integrand. Unlike prior work, our resulting estimator is \emph{provably} better than or equal to the conventional Monte Carlo estimator. To demonstrate the strength of our approach, we introduce a practical estimator that can act as a simple drop-in replacement for conventional Monte Carlo integration. We experimentally validate our framework on various light transport integrals. The code is available at \url{https://github.com/iribis/regressionmc}.","2022-11-14","2023-01-05 21:27:42","2023-03-18 21:20:49","2023-01-05 21:27:42","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2211.07422 [cs]","","C:\Users\isido\Zotero\storage\FDCESJF7\Salaün e.a. - 2022 - Regression-based Monte Carlo Integration.pdf","","monte carlo; rendering; control variates","Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:2211.07422","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTW7X9CU","preprint","2023","Albert, Jaroslav","A tau-leaping method for computing joint probability distributions of the first-passage time and position of a Brownian particle","","","","","http://arxiv.org/abs/2301.00647","First passage time (FPT), also known as ﬁrst hitting time, is the time a particle, subject to some stochastic process, hits or crosses a closed surface for the very ﬁrst time. τ -leaping methods are a class of stochastic algorithms in which, instead of simulating every single reaction, many reactions are “leaped” over in order to shorten the computing time. In this paper we developed a τ -leaping method for computing the FPT and position in arbitrary volumes for a Brownian particle governed by the Langevin equation. The τ -leaping method proposed here works as follows. A sphere is inscribed within the volume of interest (VOI) centered at the initial particle’s location. On this sphere, the FPT is sampled, as well as the position, which becomes the new initial position. Then, another sphere, centered at this new location, is inscribed. This process continues until the sphere becomes smaller than some minimal radius Rmin. When this occurs, the τ -leaping switches to the conventional Monte Carlo, which runs until the particle either crosses the surface of the VOI or ﬁnds its way to a position where a sphere of radius > Rmin can be inscribed. The switching between τ -leaping and MC continues until the particle crosses the surface of the VOI. The purpose of a minimal radius is to avoid having to sample the velocities, which become irrelevant when the particle diﬀuses beyond a certain distance, i. e. Rmin The size of this radius depends on the system parameters and on one’s notion of accuracy: the larger this radius the more accurate the τ -leaping method, but also less eﬃcient. This trade oﬀ between accuracy and eﬃciency is discussed. For two VOI, the τ -leaping method is shown to be accurate and more eﬃcient than MC by at least a factor of 10 and up to a factor of about 110. However, while MC becomes exponentially slower with increasing VOI, the eﬃciency of the τ -leaping method remains relatively unchanged. Thus, the τ -leaping method can potentially be many orders of magnitude more eﬃcient than MC.","2023-01-02","2023-01-05 21:32:56","2023-03-18 21:20:32","2023-01-05 21:32:56","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2301.00647 [cond-mat, q-bio]","","C:\Users\isido\Zotero\storage\J5YXETE7\Albert - 2023 - A tau-leaping method for computing joint probabili.pdf","","brownian motion","Condensed Matter - Soft Condensed Matter; Quantitative Biology - Molecular Networks","","","","","","","","","","","","","","","","","","","arXiv:2301.00647","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KV3SI95Y","journalArticle","2019","Kondapaneni, Ivo; Vevoda, Petr; Grittmann, Pascal; Skřivan, Tomáš; Slusallek, Philipp; Křivánek, Jaroslav","Optimal multiple importance sampling","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3306346.3323009","https://dl.acm.org/doi/10.1145/3306346.3323009","Multiple Importance Sampling (MIS) is a key technique for achieving robustness of Monte Carlo estimators in computer graphics and other fields. We derive optimal weighting functions for MIS that provably minimize the variance of an MIS estimator, given a set of sampling techniques. We show that the resulting variance reduction over the balance heuristic can be higher than predicted by the variance bounds derived by Veach and Guibas, who assumed only non-negative weights in their proof. We theoretically analyze the variance of the optimal MIS weights and show the relation to the variance of the balance heuristic. Furthermore, we establish a connection between the new weighting functions and control variates as previously applied to mixture sampling. We apply the new optimal weights to integration problems in light transport and show that they allow for new design considerations when choosing the appropriate sampling techniques for a given integration problem.","2019-08-31","2023-01-06 10:08:17","2023-03-18 21:20:20","2023-01-06 10:08:17","1-14","","4","38","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\LN9YUIJZ\Kondapaneni e.a. - 2019 - Optimal multiple importance sampling.pdf","","monte carlo; rendering; importance sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IYB3M8IG","preprint","2020","Müller, Thomas; Rousselle, Fabrice; Novák, Jan; Keller, Alexander","Neural Control Variates","","","","","http://arxiv.org/abs/2006.01524","We propose neural control variates (NCV) for unbiased variance reduction in parametric Monte Carlo integration. So far, the core challenge of applying the method of control variates has been finding a good approximation of the integrand that is cheap to integrate. We show that a set of neural networks can face that challenge: a normalizing flow that approximates the shape of the integrand and another neural network that infers the solution of the integral equation. We also propose to leverage a neural importance sampler to estimate the difference between the original integrand and the learned control variate. To optimize the resulting parametric estimator, we derive a theoretically optimal, variance-minimizing loss function, and propose an alternative, composite loss for stable online training in practice. When applied to light transport simulation, neural control variates are capable of matching the state-of-the-art performance of other unbiased approaches, while providing means to develop more performant, practical solutions. Specifically, we show that the learned light-field approximation is of sufficient quality for high-order bounces, allowing us to omit the error correction and thereby dramatically reduce the noise at the cost of negligible visible bias.","2020-09-04","2023-01-06 10:14:46","2023-03-18 21:19:58","2023-01-06 10:14:46","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2006.01524 [cs, stat]","","C:\Users\isido\Zotero\storage\VJD8P7DL\Müller e.a. - 2020 - Neural Control Variates.pdf","","monte carlo; rendering; control variates; machine learning","Computer Science - Machine Learning; Statistics - Machine Learning; Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:2006.01524","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K4Y7RS8G","preprint","2019","Müller, Thomas; McWilliams, Brian; Rousselle, Fabrice; Gross, Markus; Novák, Jan","Neural Importance Sampling","","","","","http://arxiv.org/abs/1808.03856","We propose to use deep neural networks for generating samples in Monte Carlo integration. Our work is based on non-linear independent components estimation (NICE), which we extend in numerous ways to improve performance and enable its application to integration problems. First, we introduce piecewise-polynomial coupling transforms that greatly increase the modeling power of individual coupling layers. Second, we propose to preprocess the inputs of neural networks using one-blob encoding, which stimulates localization of computation and improves inference. Third, we derive a gradient-descent-based optimization for the KL and the $\chi^2$ divergence for the specific application of Monte Carlo integration with unnormalized stochastic estimates of the target distribution. Our approach enables fast and accurate inference and efficient sample generation independently of the dimensionality of the integration domain. We show its benefits on generating natural images and in two applications to light-transport simulation: first, we demonstrate learning of joint path-sampling densities in the primary sample space and importance sampling of multi-dimensional path prefixes thereof. Second, we use our technique to extract conditional directional densities driven by the product of incident illumination and the BSDF in the rendering equation, and we leverage the densities for path guiding. In all applications, our approach yields on-par or higher performance than competing techniques at equal sample count.","2019-09-03","2023-01-06 10:20:22","2023-03-18 21:19:35","2023-01-06 10:20:22","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1808.03856 [cs, stat]","","C:\Users\isido\Zotero\storage\UQDR2FVH\Müller e.a. - 2019 - Neural Importance Sampling.pdf","","monte carlo; rendering; importance sampling; machine learning","Computer Science - Machine Learning; Statistics - Machine Learning; Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:1808.03856","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9BFESRU","journalArticle","2020","Ruppert, Lukas; Herholz, Sebastian; Lensch, Hendrik P. A.","Robust fitting of parallax-aware mixtures for path guiding","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3386569.3392421","https://dl.acm.org/doi/10.1145/3386569.3392421","Effective local light transport guiding demands for high quality guiding information, i.e., a precise representation of the directional incident radiance distribution at every point inside the scene. We introduce a parallax-aware distribution model based on parametric mixtures. By parallax-aware warping of the distribution, the local approximation of the 5D radiance field remains valid and precise across large spatial regions, even for close-by contributors. Our robust optimization scheme fits parametric mixtures to radiance samples collected in previous rendering passes. Robustness is achieved by splitting and merging of components refining the mixture. These splitting and merging decisions minimize and bound the expected variance of the local radiance estimator. In addition, we extend the fitting scheme to a robust, iterative update method, which allows for incremental training of our model using smaller sample batches. This results in more frequent training updates and, at the same time, significantly reduces the required sample memory footprint. The parametric representation of our model allows for the application of advanced importance sampling methods such as radiance-based, cosine-aware, and even product importance sampling. Our method further smoothly integrates next-event estimation (NEE) into path guiding, avoiding importance sampling of contributions better covered by NEE. The proposed robust fitting and update scheme, in combination with the parallax-aware representation, results in faster learning and lower variance compared to state-of-the-art path guiding approaches.","2020-08-31","2023-01-06 10:21:50","2023-03-18 21:19:18","2023-01-06 10:21:50","","","4","39","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\Y3W4KYQT\Ruppert e.a. - 2020 - Robust fitting of parallax-aware mixtures for path.pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFWUYRXJ","preprint","2017","Dahm, Ken; Keller, Alexander","Learning Light Transport the Reinforced Way","","","","","http://arxiv.org/abs/1701.07403","We show that the equations of reinforcement learning and light transport simulation are related integral equations. Based on this correspondence, a scheme to learn importance while sampling path space is derived. The new approach is demonstrated in a consistent light transport simulation algorithm that uses reinforcement learning to progressively learn where light comes from. As using this information for importance sampling includes information about visibility, too, the number of light transport paths with zero contribution is dramatically reduced, resulting in much less noisy images within a ﬁxed time budget.","2017-08-15","2023-01-06 10:22:43","2023-03-18 21:18:05","2023-01-06 10:22:43","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1701.07403 [cs]","","C:\Users\isido\Zotero\storage\2D4V4CM6\Dahm en Keller - 2017 - Learning Light Transport the Reinforced Way.pdf","","rendering; machine learning; reinforcement learning","Computer Science - Machine Learning; Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:1701.07403","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPSS8XTH","journalArticle","","Manzi, Marco; Kettunen, Markus; Aittala, Miika; Lehtinen, Jaakko; Durand, Frédo; Zwicker, Matthias","Gradient-Domain Bidirectional Path Tracing","","","","","","Gradient-domain path tracing has recently been introduced as an efﬁcient realistic image synthesis algorithm. This paper introduces a bidirectional gradient-domain sampler that outperforms traditional bidirectional path tracing often by a factor of two to ﬁve in terms of squared error at equal render time. It also improves over unidirectional gradient-domain path tracing in challenging visibility conditions, similarly to how conventional bidirectional path tracing improves over its unidirectional counterpart. Our algorithm leverages a novel multiple importance sampling technique and an efﬁcient implementation of a high-quality shift mapping suitable for bidirectional path tracing. We demonstrate the versatility of our approach in several challenging light transport scenarios.","","2023-01-06 10:23:18","2023-03-18 21:16:45","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\G9T7TZDT\Manzi e.a. - Gradient-Domain Bidirectional Path Tracing.pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3A579MRC","preprint","2019","Durkan, Conor; Bekasov, Artur; Murray, Iain; Papamakarios, George","Cubic-Spline Flows","","","","","http://arxiv.org/abs/1906.02145","A normalizing ﬂow models a complex probability density as an invertible transformation of a simple density. The invertibility means that we can evaluate densities and generate samples from a ﬂow. In practice, autoregressive ﬂow-based models are slow to invert, making either density estimation or sample generation slow. Flows based on coupling transforms are fast for both tasks, but have previously performed less well at density estimation than autoregressive ﬂows. We stack a new coupling transform, based on monotonic cubic splines, with LU-decomposed linear layers. The resulting cubic-spline ﬂow retains an exact onepass inverse, can be used to generate high-quality images, and closes the gap with autoregressive ﬂows on a suite of density-estimation tasks.","2019-06-05","2023-01-06 10:24:27","2023-03-18 21:16:40","2023-01-06 10:24:27","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1906.02145 [cs, stat]","","C:\Users\isido\Zotero\storage\FG5VAIUR\Durkan e.a. - 2019 - Cubic-Spline Flows.pdf","","machine learning","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1906.02145","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JXNHCLY","preprint","2019","Durkan, Conor; Bekasov, Artur; Murray, Iain; Papamakarios, George","Neural Spline Flows","","","","","http://arxiv.org/abs/1906.04032","A normalizing ﬂow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the ﬂexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the ﬂexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline ﬂows improve density estimation, variational inference, and generative modeling of images.","2019-12-02","2023-01-06 10:24:49","2023-03-18 21:16:10","2023-01-06 10:24:49","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1906.04032 [cs, stat]","","C:\Users\isido\Zotero\storage\RNWFF9CZ\Durkan e.a. - 2019 - Neural Spline Flows.pdf","","machine learning","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1906.04032","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5FBPAZ4","preprint","2021","Papamakarios, George; Nalisnick, Eric; Rezende, Danilo Jimenez; Mohamed, Shakir; Lakshminarayanan, Balaji","Normalizing Flows for Probabilistic Modeling and Inference","","","","","http://arxiv.org/abs/1912.02762","Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.","2021-04-08","2023-01-06 10:25:05","2023-03-18 21:16:00","2023-01-06 10:25:05","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1912.02762 [cs, stat]","","C:\Users\isido\Zotero\storage\WS7G7WN2\Papamakarios e.a. - 2021 - Normalizing Flows for Probabilistic Modeling and I.pdf","","importance sampling; machine learning","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1912.02762","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LVTNKR3","preprint","2019","Jaini, Priyank; Selby, Kira A.; Yu, Yaoliang","Sum-of-Squares Polynomial Flow","","","","","http://arxiv.org/abs/1905.02325","Triangular map is a recent construct in probability theory that allows one to transform any source probability density function to any target density function. Based on triangular maps, we propose a general framework for high-dimensional density estimation, by specifying one-dimensional transformations (equivalently conditional densities) and appropriate conditioner networks. This framework (a) reveals the commonalities and differences of existing autoregressive and ﬂow based methods, (b) allows a uniﬁed understanding of the limitations and representation power of these recent approaches and, (c) motivates us to uncover a new Sum-of-Squares (SOS) ﬂow that is interpretable, universal, and easy to train. We perform several synthetic experiments on various density geometries to demonstrate the beneﬁts (and shortcomings) of such transformations. SOS ﬂows achieve competitive results in simulations and several real-world datasets.","2019-06-10","2023-01-06 10:25:18","2023-03-18 21:15:50","2023-01-06 10:25:18","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1905.02325 [cs, stat]","","C:\Users\isido\Zotero\storage\PCM8RNZR\Jaini e.a. - 2019 - Sum-of-Squares Polynomial Flow.pdf","","importance sampling; machine learning","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1905.02325","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AK43FR5V","preprint","2022","Beznea, Lucian; Cimpean, Iulian; Lupascu-Stamate, Oana; Popescu, Ionel; Zarnescu, Arghir","From Monte Carlo to neural networks approximations of boundary value problems","","","","","http://arxiv.org/abs/2209.01432","In this paper we study probabilistic and neural network approximations for solutions to Poisson equation subject to H¨older or C2 data in general bounded domains of Rd. We aim at two fundamental goals.","2022-09-03","2023-01-06 10:25:51","2023-03-18 21:15:16","2023-01-06 10:25:51","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2209.01432 [cs, math]","","C:\Users\isido\Zotero\storage\G4JL3TT7\Beznea e.a. - 2022 - From Monte Carlo to neural networks approximations.pdf","","monte carlo; PDE; machine learning","Computer Science - Machine Learning; Mathematics - Probability; Mathematics - Numerical Analysis; Computer Science - Artificial Intelligence; Mathematics - Analysis of PDEs","","","","","","","","","","","","","","","","","","","arXiv:2209.01432","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDJCDHRQ","journalArticle","2007","Zergaïnoh, Anissa; Chihab, Najat; Astruc, Jean Pierre","Construction of Orthonormal Piecewise Polynomial Scaling and Wavelet Bases on Non-Equally Spaced Knots","EURASIP Journal on Advances in Signal Processing","","1687-6180","10.1155/2007/27427","https://asp-eurasipjournals.springeropen.com/articles/10.1155/2007/27427","his paper investigates the mathematical framework of multiresolution analysis based on irregularly spaced knots sequence. Our presentation is based on the construction of nested nonuniform spline multiresolution spaces. From these spaces, we present the construction of orthonormal scaling and wavelet basis functions on bounded intervals. For any arbitrary degree of the spline function, we provide an explicit generalization allowing the construction of the scaling and wavelet bases on the nontraditional sequences. We show that the orthogonal decomposition is implemented using filter banks where the coefficients depend on the location of the knots on the sequence. Examples of orthonormal spline scaling and wavelet bases are provided. This approach can be used to interpolate irregularly sampled signals in an efficient way, by keeping the multiresolution approach.","2007-12","2023-01-08 14:49:13","2023-08-03 17:49:48","2023-01-08 14:49:13","027427","","1","2007","","EURASIP J. Adv. Signal Process.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\IA4NHCZX\Zergaïnoh e.a. - 2007 - Construction of Orthonormal Piecewise Polynomial S.pdf","","wavelets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSZZAWZI","preprint","2021","Subr, Kartic","Q-NET: A Network for Low-Dimensional Integrals of Neural Proxies","","","","","http://arxiv.org/abs/2006.14396","Many applications require the calculation of integrals of multidimensional functions. A general and popular procedure is to estimate integrals by averaging multiple evaluations of the function. Often, each evaluation of the function entails costly computations. The use of a \emph{proxy} or surrogate for the true function is useful if repeated evaluations are necessary. The proxy is even more useful if its integral is known analytically and can be calculated practically. We propose the use of a versatile yet simple class of artificial neural networks -- sigmoidal universal approximators -- as a proxy for functions whose integrals need to be estimated. We design a family of fixed networks, which we call Q-NETs, that operate on parameters of a trained proxy to calculate exact integrals over \emph{any subset of dimensions} of the input domain. We identify transformations to the input space for which integrals may be recalculated without resampling the integrand or retraining the proxy. We highlight the benefits of this scheme for a few applications such as inverse rendering, generation of procedural noise, visualization and simulation. The proposed proxy is appealing in the following contexts: the dimensionality is low ($<10$D); the estimation of integrals needs to be decoupled from the sampling strategy; sparse, adaptive sampling is used; marginal functions need to be known in functional form; or when powerful Single Instruction Multiple Data/Thread (SIMD/SIMT) pipelines are available for computation.","2021-03-30","2023-01-08 17:33:21","2023-03-18 21:14:27","2023-01-08 17:33:21","","","","","","","Q-NET","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2006.14396 [cs, stat]","","C:\Users\isido\Zotero\storage\N8BQBFKD\Subr - 2021 - Q-NET A Network for Low-Dimensional Integrals of .pdf","","machine learning","Computer Science - Machine Learning; Statistics - Machine Learning; Computer Science - Neural and Evolutionary Computing","","","","","","","","","","","","","","","","","","","arXiv:2006.14396","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XZWWP2V","conferencePaper","2019","Duminil-Copin, Hugo","SIXTY YEARS OF PERCOLATION","Proceedings of the International Congress of Mathematicians (ICM 2018)","978-981-327-287-3 978-981-327-288-0","","10.1142/9789813272880_0162","https://www.worldscientific.com/doi/abs/10.1142/9789813272880_0162","Percolation models describe the inside of a porous material. The theory emerged timidly in the middle of the twentieth century before becoming one of the major objects of interest in probability and mathematical physics. The golden age of percolation is probably the eighties, during which most of the major results were obtained for the most classical of these models, named Bernoulli percolation, but it is really the two following decades which put percolation theory at the crossroad of several domains of mathematics. In this broad review, we propose to describe brieﬂy some recent progress as well as some famous challenges remaining in the ﬁeld. This review is not intended to probabilists (and a fortiori not to specialists in percolation theory): the target audience is mathematicians of all kinds.","2019-05","2023-01-09 20:52:43","2023-01-09 20:52:44","2023-01-09 20:52:43","2829-2856","","","","","","","","","","","WORLD SCIENTIFIC","Rio de Janeiro, Brazil","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\KAH28XWG\Duminil-Copin - 2019 - SIXTY YEARS OF PERCOLATION.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Congress of Mathematicians 2018","","","","","","","","","","","","","","",""
"MTNHCBJF","videoRecording","2018","Enthought","UMAP Uniform Manifold Approximation and Projection for Dimension Reduction | SciPy 2018 |","","","","","https://www.youtube.com/watch?v=nq6iPZVUxZU","","2018-07-14","2023-01-10 16:37:30","2023-03-18 21:13:53","2023-01-10 16:37:30","","","","","","","","","","","","","","","","","","","YouTube","","","","","","machine learning","","","","","","","","","","","","","","","","","","","","","","26:05","","","","","","","","","","","","","","","","","","","","","","","","",""
"6CV9BW8H","videoRecording","2019","PyData","A Bluffer's Guide to Dimension Reduction - Leland McInnes","","","","","https://www.youtube.com/watch?v=9iol3Lk6kyU","","2019-02-01","2023-01-10 16:50:08","2023-03-18 21:13:46","2023-01-10 16:50:08","","","","","","","","","","","","","","","","","","","YouTube","","","","","","machine learning","","","","","","","","","","","","","","","","","","","","","","36:33","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFL6BJ5W","videoRecording","2020","Stitch Fix Multithreaded","Algo Hour - Nearest Neighbor Descent (and friends) | Dr. Leland McInnes","","","","","https://www.youtube.com/watch?v=OvT2NY_FV_g","","2020-05-22","2023-01-10 17:07:12","2023-03-18 21:13:38","2023-01-10 17:07:12","","","","","","","","","","","","","","","","","","","YouTube","","","","","","machine learning","","","","","","","","","","","","","","","","","","","","","","54:10","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8ZXGQLI","videoRecording","2016","Enthought","High Quality, High Performance Clustering with HDBSCAN | SciPy 2016 | Leland McInnes","","","","","https://www.youtube.com/watch?v=AgPQ76RIi6A","","2016-07-15","2023-01-10 17:19:13","2023-03-18 21:13:32","2023-01-10 17:19:13","","","","","","","","","","","","","","","","","","","YouTube","","","","","","machine learning","","","","","","","","","","","","","","","","","","","","","","22:56","","","","","","","","","","","","","","","","","","","","","","","","",""
"XLR4E6C8","preprint","2021","Hajimohammadi, Zeinab; Parand, Kourosh; Ghodsi, Ali","Legendre Deep Neural Network (LDNN) and its application for approximation of nonlinear Volterra Fredholm Hammerstein integral equations","","","","","http://arxiv.org/abs/2106.14320","Various phenomena in biology, physics, and engineering are modeled by diﬀerential equations. These diﬀerential equations including partial diﬀerential equations and ordinary diﬀerential equations can be converted and represented as integral equations. In particular, Volterra–Fredholm–Hammerstein integral equations are the main type of these integral equations and researchers are interested in investigating and solving these equations. In this paper, we propose Legendre Deep Neural Network (LDNN) for solving nonlinear Volterra–Fredholm–Hammerstein integral equations (V-F-H-IEs). LDNN utilizes Legendre orthogonal polynomials as activation functions of the Deep structure. We present how LDNN can be used to solve nonlinear V-F-H-IEs. We show using the Gaussian quadrature collocation method in combination with LDNN results in a novel numerical solution for nonlinear V-F-H-IEs. Several examples are given to verify the performance and accuracy of LDNN.","2021-06-27","2023-01-10 17:54:46","2023-03-18 21:13:25","2023-01-10 17:54:46","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2106.14320 [cs, math]","","C:\Users\isido\Zotero\storage\PYEIWQ2R\Hajimohammadi e.a. - 2021 - Legendre Deep Neural Network (LDNN) and its applic.pdf","","integral equations; machine learning","Computer Science - Machine Learning; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2106.14320","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILUFNPTC","preprint","2021","Formica, M. R.; Ostrovsky, E.; Sirota, L.","Method Monte-Carlo for solving of non-linear integral equations","","","","","http://arxiv.org/abs/2102.07859","We oﬀer in this short report a simple Monte - Carlo method for solving a well posed non - linear integral equations of second Fredholm’s and Volterra’s type and built a conﬁdence region for solution in an uniform norm, applying the grounded Central Limit Theorem in the Banach space of continuous functions.","2021-02-15","2023-01-10 17:58:16","2023-03-18 21:11:50","2023-01-10 17:58:16","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2102.07859 [cs, math]","","C:\Users\isido\Zotero\storage\INK9IZXC\Formica e.a. - 2021 - Method Monte-Carlo for solving of non-linear integ.pdf","","monte carlo; integral equations","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2102.07859","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YN9EMEQQ","preprint","2022","Azze, Abel; D'Auria, Bernardo; García-Portugués, Eduardo","Optimal exercise of American options under time-dependent Ornstein-Uhlenbeck processes","","","","","http://arxiv.org/abs/2211.04095","We study the barrier that gives the optimal time to exercise an American option written on a time-dependent Ornstein–Uhlenbeck process, a diﬀusion often adopted by practitioners to model commodity prices and interest rates. By framing the optimal exercise of the American option as a problem of optimal stopping and relying on probabilistic arguments, we provide a non-linear Volterra-type integral equation characterizing the exercise boundary, develop a novel comparison argument to derive upper and lower bounds for such a boundary, and prove its diﬀerentiability and Lipschitz continuity in any closed interval that excludes the expiration date. We implement a Picard iteration algorithm to solve the Volterra integral equation and show illustrative examples that shed light on the boundary’s dependence on the process’s drift and volatility.","2022-11-08","2023-01-10 17:59:14","2023-03-19 15:57:33","2023-01-10 17:59:14","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2211.04095 [math, q-fin]","","C:\Users\isido\Zotero\storage\G2H9S8M4\Azze e.a. - 2022 - Optimal exercise of American options under time-de.pdf","","finance","Mathematics - Probability; Quantitative Finance - Mathematical Finance; Quantitative Finance - Pricing of Securities; 60G40, 60J60","","","","","","","","","","","","","","","","","","","arXiv:2211.04095","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FEWY6WAM","preprint","2022","Schneider, Ryan; Gharibnejad, Heman; Schneider, Barry I.","ITVOLT: An Iterative Solver for Volterra Integral Equations with Application to the Time-Dependent Schr\""odinger Equation","","","","","http://arxiv.org/abs/2210.15677","We present a novel iterative method for solving Volterra integral equations of the second kind. Based on global Lagrange interpolation, the method is simple to implement and applicable to a wide variety of problems. Here, we present the method in detail and discuss several applications, emphasizing in particular its use on the time-dependent Schro¨dinger equation.","2022-10-27","2023-01-10 18:00:48","2023-03-18 21:10:20","2023-01-10 18:00:48","","","","","","","ITVOLT","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2210.15677 [physics]","","C:\Users\isido\Zotero\storage\VKU8FNSZ\Schneider e.a. - 2022 - ITVOLT An Iterative Solver for Volterra Integral .pdf","","integral equations","Mathematics - Numerical Analysis; 45D05, 65F10, 65D32; Physics - Computational Physics","","","","","","","","","","","","","","","","","","","arXiv:2210.15677","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GQYEJXLI","preprint","2021","Crucinio, Francesca R.; Doucet, Arnaud; Johansen, Adam M.","A Particle Method for Solving Fredholm Equations of the First Kind","","","","","http://arxiv.org/abs/2009.09974","Fredholm integral equations of the ﬁrst kind are the prototypical example of ill-posed linear inverse problems. They model, among other things, reconstruction of distorted noisy observations and indirect density estimation and also appear in instrumental variable regression. However, their numerical solution remains a challenging problem. Many techniques currently available require a preliminary discretization of the domain of the solution and make strong assumptions about its regularity. For example, the popular expectation maximization smoothing (EMS) scheme requires the assumption of piecewise constant solutions which is inappropriate for most applications. We propose here a novel particle method that circumvents these two issues. This algorithm can be thought of as a Monte Carlo approximation of the EMS scheme which not only performs an adaptive stochastic discretization of the domain but also results in smooth approximate solutions. We analyze the theoretical properties of the EMS iteration and of the corresponding particle algorithm. Compared to standard EMS, we show experimentally that our novel particle method provides state-of-the-art performance for realistic systems, including motion deblurring and reconstruction of cross-section images of the brain from positron emission tomography.","2021-04-23","2023-01-10 18:16:51","2023-03-18 21:10:01","2023-01-10 18:16:51","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2009.09974 [stat]","","C:\Users\isido\Zotero\storage\HMHHAWGP\Crucinio e.a. - 2021 - A Particle Method for Solving Fredholm Equations o.pdf","","integral equations","Statistics - Computation; Statistics - Methodology","","","","","","","","","","","","","","","","","","","arXiv:2009.09974","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H4GRUBHP","preprint","2019","Keller, Alexander; Dahm, Ken","Integral Equations and Machine Learning","","","","","http://arxiv.org/abs/1712.06115","As both light transport simulation and reinforcement learning are ruled by the same Fredholm integral equation of the second kind, reinforcement learning techniques may be used for photorealistic image synthesis: Eﬃciency may be dramatically improved by guiding light transport paths by an approximate solution of the integral equation that is learned during rendering. In the light of the recent advances in reinforcement learning for playing games, we investigate the representation of an approximate solution of an integral equation by artiﬁcial neural networks and derive a loss function for that purpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural networks with standard information instead of linear information and naturally are able to generate an arbitrary number of training samples. The methods are demonstrated for applications in light transport simulation.","2019-01-30","2023-01-10 18:24:11","2023-03-18 21:18:28","2023-01-10 18:24:11","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1712.06115 [cs]","","C:\Users\isido\Zotero\storage\Q43J8XEA\Keller en Dahm - 2019 - Integral Equations and Machine Learning.pdf","","integral equations; machine learning; reinforcement learning","Computer Science - Machine Learning; Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:1712.06115","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7IQWMKP","preprint","2021","Gopalakrishna, Chaitanya","A note on Fredholm integral equation","","","","","http://arxiv.org/abs/2106.07194","This note gives results on the existence of semi-continuous solutions of a Fredholm integral equation of the second kind using Tarski’s ﬁxed point theorem.","2021-06-14","2023-01-10 18:48:19","2023-03-18 21:06:01","2023-01-10 18:48:19","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2106.07194 [math]","","C:\Users\isido\Zotero\storage\BF5MEFDI\Gopalakrishna - 2021 - A note on Fredholm integral equation.pdf","","integral equations","Mathematics - Analysis of PDEs; 45B05, 47H10, 06B23; Mathematics - Rings and Algebras","","","","","","","","","","","","","","","","","","","arXiv:2106.07194","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PWYAGEF9","journalArticle","2021","Yang, Xiao-lin; Wang, Jian-cheng; Yang, Chu-yuan","A New Fast Monte Carlo Code for Solving Radiative Transfer Equations based on Neumann Solution","The Astrophysical Journal Supplement Series","","0067-0049, 1538-4365","10.3847/1538-4365/abec73","http://arxiv.org/abs/2104.07007","In this paper, we proposed a new Monte Carlo radiative transport (MCRT) scheme, which is based completely on the Neumann series solution of Fredholm integral equation. This scheme indicates that the essence of MCRT is the calculation of inﬁnite terms of multiple integrals in Neumann solution simultaneously. Under this perspective we redescribed MCRT procedure systematically, in which the main work amounts to choose an associated probability distribution function (PDF) for a set of random variables and the corresponding unbiased estimation functions. We can select a relatively optimal estimation procedure that has a lower variance from an inﬁnite possible choices, such as the term by term estimation. In this scheme, MCRT can be regarded as a pure problem of integral evaluation, rather than as the tracing of random walking photons. Keeping this in mind, one can avert some subtle intuitive mistakes. In addition the δ-functions in these integrals can be eliminated in advance by integrating them out directly. This fact together with the optimal chosen random variables can remarkably improve the Monte Carlo (MC) computational eﬃciency and accuracy, especially in systems with axial or spherical symmetry. An MCRT code, Lemona(Linear Integral Equations’ Monte Carlo Solver Based on the Neumann solution), has been developed completely based on this scheme. Finally, we intend to verify the validation of Lemon, a suite of test problems mainly restricted to ﬂat spacetime have been reproduced and the corresponding results are illustrated in detail.","2021-06-01","2023-01-10 18:54:28","2023-03-18 21:05:55","2023-01-10 18:54:28","29","","2","254","","ApJS","","","","","","","","en","","","","","arXiv.org","","arXiv:2104.07007 [astro-ph, physics:physics]","","C:\Users\isido\Zotero\storage\5R9X8WF9\2104.07007.pdf","","monte carlo; integral equations","Physics - Computational Physics; Astrophysics - High Energy Astrophysical Phenomena","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BN2E9PFX","preprint","2014","Ostrovsky, E.; Sirota, L.","Unbiased Monte Carlo estimation for solving of linear integral equation, with error estimate","","","","","http://arxiv.org/abs/1408.4205","We oﬀer a new Monte-Carlo method for solving linear integral equation which gives the unbiased estimation for solution of Volterra’s and Fredholm’s type, and consider the problem of conﬁdence region building.","2014-08-18","2023-01-10 19:07:59","2023-03-18 21:04:59","2023-01-10 19:07:59","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1408.4205 [math]","","C:\Users\isido\Zotero\storage\UBUR3CE9\Ostrovsky en Sirota - 2014 - Unbiased Monte Carlo estimation for solving of lin.pdf","","monte carlo; integral equations","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1408.4205","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXKKIQYU","preprint","2023","Carmon, Yair; Jambulapati, Arun; Jin, Yujia; Lee, Yin Tat; Liu, Daogao; Sidford, Aaron; Tian, Kevin","ReSQueing Parallel and Private Stochastic Convex Optimization","","","","","http://arxiv.org/abs/2301.00457","We introduce a new tool for stochastic convex optimization (SCO): a Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function convolved with a (Gaussian) probability density. Combining ReSQue with recent advances in ball oracle acceleration [CJJ+20, ACJ+21], we develop algorithms achieving state-of-the-art complexities for SCO in parallel and private settings. For a SCO objective constrained to the unit ball in Rd, we obtain the following results (up to polylogarithmic factors).","2023-01-01","2023-01-11 11:07:00","2023-03-18 21:04:11","2023-01-11 11:07:00","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2301.00457 [cs, math, stat]","","C:\Users\isido\Zotero\storage\JDNVG82B\Carmon e.a. - 2023 - ReSQueing Parallel and Private Stochastic Convex O.pdf","","optimization","Computer Science - Machine Learning; Statistics - Machine Learning; Mathematics - Optimization and Control; Computer Science - Cryptography and Security; Computer Science - Data Structures and Algorithms","","","","","","","","","","","","","","","","","","","arXiv:2301.00457","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNV9Y9VM","preprint","2022","He, Haoze; Dube, Parijat","Accelerating Parallel Stochastic Gradient Descent via Non-blocking Mini-batches","","","","","http://arxiv.org/abs/2211.00889","SOTA decentralized SGD algorithms can overcome the bandwidth bottleneck at the parameter server by using communication collectives like Ring All-Reduce for synchronization. While the parameter updates in distributed SGD may happen asynchronously there is still a synchronization barrier to make sure that the local training epoch at every learner is complete before the learners can advance to the next epoch. The delays in waiting for the slowest learners(stragglers) remain to be a problem in the synchronization steps of these state-of-the-art decentralized frameworks. In this paper, we propose the (de)centralized Non-blocking SGD (Non-blocking SGD) which can address the straggler problem in a heterogeneous environment. The main idea of Non-blocking SGD is to split the original batch into mini-batches, then accumulate the gradients and update the model based on ﬁnished mini-batches. The Non-blocking idea can be implemented using decentralized algorithms including Ring All-reduce, D-PSGD, and MATCHA to solve the straggler problem. Moreover, using gradient accumulation to update the model also guarantees convergence and avoids gradient staleness. Run-time analysis with random straggler delays and computational efﬁciency/throughput of devices is also presented to show the advantage of Non-blocking SGD. Experiments on a suite of datasets and deep learning networks validate the theoretical analyses and demonstrate that Non-blocking SGD speeds up the training and fastens the convergence. Compared with the state-of-the-art decentralized asynchronous algorithms like D-PSGD and MACHA, Non-blocking SGD takes up to 2x fewer time to reach the same training loss in a heterogeneous environment.","2022-11-09","2023-01-11 12:54:14","2023-03-18 20:59:10","2023-01-11 12:54:14","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2211.00889 [cs]","","C:\Users\isido\Zotero\storage\5TLNEYY3\He en Dube - 2022 - Accelerating Parallel Stochastic Gradient Descent .pdf","","optimization","Computer Science - Machine Learning; Computer Science - Distributed, Parallel, and Cluster Computing","","","","","","","","","","","","","","","","","","","arXiv:2211.00889","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VU5QKL6E","preprint","2022","Mohamad, Saad; Alamri, Hamad; Bouchachia, Abdelhamid","Scaling up Stochastic Gradient Descent for Non-convex Optimisation","","","","","http://arxiv.org/abs/2210.02882","Stochastic gradient descent (SGD) is a widely adopted iterative method for optimizing differentiable objective functions. In this paper, we propose and discuss a novel approach to scale up SGD in applications involving non-convex functions and large datasets. We address the bottleneck problem arising when using both shared and distributed memory. Typically, the former is bounded by limited computation resources and bandwidth whereas the latter suffers from communication overheads. We propose a uniﬁed distributed and parallel implementation of SGD (named DPSGD) that relies on both asynchronous distribution and lock-free parallelism. By combining two strategies into a uniﬁed framework, DPSGD is able to strike a better trade-off between local computation and communication. The convergence properties of DPSGD are studied for non-convex problems such as those arising in statistical modelling and machine learning. Our theoretical analysis shows that DPSGD leads to speed-up with respect to the number of cores a√nd number of workers while guaranteeing an asymptotic convergence rate of O(1/ T ) given that the number of cores is bounded by T 1/4 and the number of workers is bounded by T 1/2 where T is the number of iterations. The potential gains that can be achieved by DPSGD are demonstrated empirically on a stochastic variational inference problem (Latent Dirichlet Allocation) and on a deep reinforcement learning (DRL) problem (advantage actor critic - A2C) resulting in two algorithms: DPSVI and HSA2C. Empirical results validate our theoretical ﬁndings. Comparative studies are conducted to show the performance of the proposed DPSGD against the state-of-the-art DRL algorithms.","2022-10-06","2023-01-11 12:58:02","2023-03-18 20:59:01","2023-01-11 12:58:02","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2210.02882 [cs, math, stat]","","C:\Users\isido\Zotero\storage\UJS9IZZ9\Mohamad e.a. - 2022 - Scaling up Stochastic Gradient Descent for Non-con.pdf","","optimization","Computer Science - Machine Learning; Statistics - Machine Learning; Mathematics - Optimization and Control; Computer Science - Distributed, Parallel, and Cluster Computing","","","","","","","","","","","","","","","","","","","arXiv:2210.02882","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Z6HNLBL","journalArticle","","Zinkevich, Martin A; Smola, Alex; Weimer, Markus; Li, Lihong","Parallelized Stochastic Gradient Descent","","","","","","With the increase in available data parallel machine learning has become an increasingly pressing problem. In this paper we present the ﬁrst parallel stochastic gradient descent algorithm including a detailed analysis and experimental evidence. Unlike prior work on parallel optimization algorithms [5, 7] our variant comes with parallel acceleration guarantees and it poses no overly tight latency constraints, which might only be available in the multicore setting. Our analysis introduces a novel proof technique — contractive mappings to quantify the speed of convergence of parameter distributions to their asymptotic limits. As a side effect this answers the question of how quickly stochastic gradient descent algorithms reach the asymptotically normal regime [1, 8].","","2023-01-11 13:02:51","2023-03-18 20:58:55","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\7SDXTQBD\Zinkevich e.a. - Parallelized Stochastic Gradient Descent.pdf","","optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9P3M9CG2","videoRecording","2020","Abhishek Gupta","Recursive Stochastic Algorithms: A Markov Chain Perspective","","","","","https://www.youtube.com/watch?v=f1IP6rpqaEE","Creative Commons Attribution license (reuse allowed)","2020-10-08","2023-01-11 13:58:11","2023-03-18 20:58:49","2023-01-11 13:58:11","","","","","","","Recursive Stochastic Algorithms","","","","","","","","","","","","YouTube","","","","","","unsorted important","","","","","","","","","","","","","","","","","","","","","","1:18:09","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZC3GT8J","preprint","2021","Gupta, Abhishek; Haskell, William B.","Convergence of Recursive Stochastic Algorithms using Wasserstein Divergence","","","","","http://arxiv.org/abs/2003.11403","This paper develops a uniﬁed framework, based on iterated random operator theory, to analyze the convergence of constant stepsize recursive stochastic algorithms (RSAs). RSAs use randomization to eﬃciently compute expectations, and so their iterates form a stochastic process. The key idea of our analysis is to lift the RSA into an appropriate higher-dimensional space and then express it as an equivalent Markov chain. Instead of determining the convergence of this Markov chain (which may not converge under constant stepsize), we study the convergence of the distribution of this Markov chain. To study this, we deﬁne a new notion of Wasserstein divergence. We show that if the distribution of the iterates in the Markov chain satisfy a contraction property with respect to the Wasserstein divergence, then the Markov chain admits an invariant distribution. We show that convergence of a large family of constant stepsize RSAs can be understood using this framework, and we provide several detailed examples.","2021-01-05","2023-01-11 14:08:41","2023-03-18 20:58:43","2023-01-11 14:08:41","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2003.11403 [cs, eess, math, stat]","","C:\Users\isido\Zotero\storage\IAT28HNB\Gupta en Haskell - 2021 - Convergence of Recursive Stochastic Algorithms usi.pdf","","unsorted important","Computer Science - Machine Learning; Statistics - Machine Learning; Mathematics - Probability; Mathematics - Optimization and Control; 93E35, 60J20, 68Q32; Electrical Engineering and Systems Science - Systems and Control","","","","","","","","","","","","","","","","","","","arXiv:2003.11403","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9AVEBRT4","journalArticle","2015","Akhtar, Muhammad Naveed; Durad, Muhammad Hanif; Ahmed, Asad","SOLVING INITIAL VALUE ORDINARY DIFFERENTIAL EQUATIONS BY MONTE CARLO METHOD","","","","","","The objective of this paper is to perform a computational analysis of an existing Monte Carlo based algorithm to solve initial value problem of ordinary differential equations (ODEs). Firstly the problems associated with the existing algorithm have been rectified by suggesting a new elaborate algorithm. Then the new algorithm has been applied to solve different types of ODEs including simple, explicit coupled, implicit and coupled system of first order ODEs. Furthermore the same has also been implemented to known physical systems such as Van der Pol equation and SIR epidemic model. The limitations of proposed algorithm have also been identified by applying Lipschitz continuity check for an exemplary ODE. Finally it has been demonstrated that it still very difficult to propose a computationally efficient algorithm to solve ODEs with considerable accuracy using Monte Carlo method.","2015","2023-01-12 15:03:28","2023-03-18 20:53:57","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\WTUKCBSR\Akhtar e.a. - 2015 - SOLVING INITIAL VALUE ORDINARY DIFFERENTIAL EQUATI.pdf","","monte carlo; ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VVX6NL9","encyclopediaArticle","2022","","Magnus expansion","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Magnus_expansion&oldid=1117728056","In mathematics and physics, the Magnus expansion, named after Wilhelm Magnus (1907–1990), provides an exponential representation of the solution of a first-order homogeneous linear differential equation for a linear operator. In particular, it furnishes the fundamental matrix of a system of linear ordinary differential equations of order n with varying coefficients. The exponent is aggregated as an infinite series, whose terms involve multiple integrals and nested commutators.","2022-10-23","2023-01-12 17:52:00","2023-01-12 17:52:00","2023-01-12 17:52:00","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1117728056","","C:\Users\isido\Zotero\storage\WKBPK8ZV\Magnus_expansion.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"56PWSC7E","journalArticle","2019","Vaibhav, Vishal","Efficient Nonlinear Fourier Transform Algorithms of Order Four on Equispaced Grid","IEEE Photonics Technology Letters","","1041-1135, 1941-0174","10.1109/LPT.2019.2925052","http://arxiv.org/abs/1903.11702","We explore two classes of exponential integrators in this letter to design nonlinear Fourier transform (NFT) algorithms with a desired accuracy-complexity trade-off and a convergence order of 4 on an equispaced grid. The integrating factor based method in the class of Runge-Kutta methods yield algorithms with complexity O(N log2 N) (where N is the number of samples of the signal) which have superior accuracy-complexity trade-off than any of the fast methods known currently. The integrators based on Magnus series expansion, namely, standard and commutator-free Magnus methods yield algorithms of complexity O(N2) that have superior error behavior even for moderately small step-sizes and higher signal strengths.","2019-08-01","2023-01-12 19:04:31","2023-01-12 19:04:31","2023-01-12 19:04:31","1269-1272","","15","31","","IEEE Photon. Technol. Lett.","","","","","","","","en","","","","","arXiv.org","","arXiv:1903.11702 [physics]","","C:\Users\isido\Zotero\storage\Y6ZICUXL\Vaibhav - 2019 - Efficient Nonlinear Fourier Transform Algorithms o.pdf","","","Mathematics - Numerical Analysis; Physics - Computational Physics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YT2SM8YE","encyclopediaArticle","2022","","Baker–Campbell–Hausdorff formula","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Baker%E2%80%93Campbell%E2%80%93Hausdorff_formula&oldid=1115922051","In mathematics, the Baker–Campbell–Hausdorff formula is the solution for                         Z                 {\displaystyle Z}    to the equation for possibly noncommutative X and Y in the Lie algebra of a Lie group. There are various ways of writing the formula, but all ultimately yield an expression for                         Z                 {\displaystyle Z}    in Lie algebraic terms, that is, as a formal series (not necessarily convergent) in                         X                 {\displaystyle X}    and                         Y                 {\displaystyle Y}    and iterated commutators thereof. The first few terms of this series are: where ""                        ⋯                 {\displaystyle \cdots }   "" indicates terms involving higher commutators of                         X                 {\displaystyle X}    and                         Y                 {\displaystyle Y}   . If                         X                 {\displaystyle X}    and                         Y                 {\displaystyle Y}    are sufficiently small elements of the Lie algebra                                                 g                                     {\displaystyle {\mathfrak {g}}}    of a Lie group                         G                 {\displaystyle G}   , the series is convergent. Meanwhile, every element                         g                 {\displaystyle g}    sufficiently close to the identity in                         G                 {\displaystyle G}    can be expressed as                         g         =                    e                        X                                     {\displaystyle g=e^{X}}    for a small                         X                 {\displaystyle X}    in                                                 g                                     {\displaystyle {\mathfrak {g}}}   . Thus, we can say that near the identity the group multiplication in                         G                 {\displaystyle G}   —written as                                    e                        X                                        e                        Y                             =                    e                        Z                                     {\displaystyle e^{X}e^{Y}=e^{Z}}   —can be expressed in purely Lie algebraic terms. The Baker–Campbell–Hausdorff formula can be used to give comparatively simple proofs of deep results in the Lie group–Lie algebra correspondence. If                         X                 {\displaystyle X}    and                         Y                 {\displaystyle Y}    are sufficiently small                         n         ×         n                 {\displaystyle n\times n}    matrices, then                         Z                 {\displaystyle Z}    can be computed as the logarithm of                                    e                        X                                        e                        Y                                     {\displaystyle e^{X}e^{Y}}   , where the exponentials and the logarithm can be computed as power series. The point of the Baker–Campbell–Hausdorff formula is then the highly nonobvious claim that                         Z         :=         log         ⁡                    (                                       e                                X                                                        e                                Y                                                  )                          {\displaystyle Z:=\log \left(e^{X}e^{Y}\right)}    can be expressed as a series in repeated commutators of                         X                 {\displaystyle X}    and                         Y                 {\displaystyle Y}   . Modern expositions of the formula can be found in, among other places, the books of Rossmann and Hall.","2022-10-13","2023-01-12 19:07:44","2023-03-19 15:58:54","2023-01-12 19:07:44","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1115922051","","","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JW5HV8Q","journalArticle","2013","Galtier, M.; Blanco, S.; Caliot, C.; Coustet, C.; Dauchet, J.; El Hafi, M.; Eymet, V.; Fournier, R.; Gautrais, J.; Khuong, A.; Piaud, B.; Terrée, G.","Integral formulation of null-collision Monte Carlo algorithms","Journal of Quantitative Spectroscopy and Radiative Transfer","","00224073","10.1016/j.jqsrt.2013.04.001","https://linkinghub.elsevier.com/retrieve/pii/S0022407313001350","At the kinetic level, the meaning of null-collisions is straightforward: they correspond to pureforward scattering events. We here discuss their technical signiﬁcance in integral terms. We ﬁrst consider a most standard null-collision Monte Carlo algorithm and show how it can be rigorously justiﬁed starting from a Fredholm equivalent to the radiative transfer equation. Doing so, we also prove that null-collision algorithms can be slightly modiﬁed so that they deal with unexpected occurrences of negative values of the null-collision coeﬃcient (when the upper bound of the heterogeneous extinction coeﬃcient is nonstrict). We then describe technically, in full details, the resulting algorithm, when applied to the evaluation of the local net-power density within a bounded, heterogeneous, multiple scattering and emitting/absorbing medium. The corresponding integral formulation is then explored theoretically in order to distinguish the statistical signiﬁcance of introducing null-collisions from that of the integral-structure underlying modiﬁcation.","2013-08","2023-01-12 20:06:16","2023-03-18 20:53:30","2023-01-12 20:06:16","57-68","","","125","","Journal of Quantitative Spectroscopy and Radiative Transfer","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\7WE6YFYN\Galtier e.a. - 2013 - Integral formulation of null-collision Monte Carlo.pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTEYQJ78","journalArticle","2017","Kutz, Peter; Habel, Ralf; Li, Yining Karl; Novák, Jan","Spectral and decomposition tracking for rendering heterogeneous volumes","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3072959.3073665","https://dl.acm.org/doi/10.1145/3072959.3073665","We present two novel unbiased techniques for sampling free paths in heterogeneous participating media. Our               decomposition tracking               accelerates free-path construction by splitting the medium into a control component and a residual component and sampling each of them separately. To minimize expensive evaluations of spatially varying collision coefficients, we define the control component to allow constructing free paths in closed form. The residual heterogeneous component is then homogenized by adding a fictitious medium and handled using weighted delta tracking, which removes the need for computing strict bounds of the extinction function. Our second contribution,               spectral tracking               , enables efficient light transport simulation in chromatic media. We modify free-path distributions to minimize the fluctuation of path throughputs and thereby reduce the estimation variance. To demonstrate the correctness of our algorithms, we derive them               directly               from the radiative transfer equation by extending the integral formulation of null-collision algorithms recently developed in reactor physics. This mathematical framework, which we thoroughly review, encompasses existing trackers and postulates an entire family of new estimators for solving transport problems; our algorithms are examples of such. We analyze the proposed methods in canonical settings and on production scenes, and compare to the current state of the art in simulating light transport in heterogeneous participating media.","2017-08-31","2023-01-12 20:07:57","2023-03-18 20:53:20","2023-01-12 20:07:57","1-16","","4","36","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\49PCP84W\Kutz e.a. - 2017 - Spectral and decomposition tracking for rendering .pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4JVTM6R","bookSection","2020","Billaud-Friess, Marie; Macherey, Arthur; Nouy, Anthony; Prieur, Clémentine","Stochastic methods for solving high-dimensional partial differential equations","","","","","http://arxiv.org/abs/1905.05423","We propose algorithms for solving high-dimensional Partial Diﬀerential Equations (PDEs) that combine a probabilistic interpretation of PDEs, through Feynman-Kac representation, with sparse interpolation. Monte-Carlo methods and time-integration schemes are used to estimate pointwise evaluations of the solution of a PDE. We use a sequential control variates algorithm, where control variates are constructed based on successive approximations of the solution of the PDE. Two diﬀerent algorithms are proposed, combining in diﬀerent ways the sequential control variates algorithm and adaptive sparse interpolation. Numerical examples will illustrate the behavior of these algorithms.","2020","2023-01-14 09:22:48","2023-03-18 20:53:02","2023-01-14 09:22:48","125-141","","","324","","","","","","","","","","en","","","","","arXiv.org","","DOI: 10.1007/978-3-030-43465-6_6 arXiv:1905.05423 [math]","","C:\Users\isido\Zotero\storage\9PRXYL9X\Billaud-Friess e.a. - 2020 - Stochastic methods for solving high-dimensional pa.pdf","","PDE","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4H34FJQ","preprint","2022","Leluc, Rémi; Portier, François; Segers, Johan; Zhuman, Aigerim","A Quadrature Rule combining Control Variates and Adaptive Importance Sampling","","","","","http://arxiv.org/abs/2205.11890","Driven by several successful applications such as in stochastic gradient descent or in Bayesian computation, control variates have become a major tool for Monte Carlo integration. However, standard methods do not allow the distribution of the particles to evolve during the algorithm, as is the case in sequential simulation methods. Within the standard adaptive importance sampling framework, a simple weighted least squares approach is proposed to improve the procedure with control variates. The procedure takes the form of a quadrature rule with adapted quadrature weights to reﬂect the information brought in by the control variates. The quadrature points and weights do not depend on the integrand, a computational advantage in case of multiple integrands. Moreover, the target density needs to be known only up to a multiplicative constant. Our main result is a non-asymptotic bound on the probabilistic error of the procedure. The bound proves that for improving the estimate’s accuracy, the beneﬁts from adaptive importance sampling and control variates can be combined. The good behavior of the method is illustrated empirically on synthetic examples and real-world data for Bayesian linear regression.","2022-10-05","2023-01-14 10:00:33","2023-03-18 20:50:13","2023-01-14 10:00:33","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2205.11890 [cs, math, stat]","","C:\Users\isido\Zotero\storage\BVHY6BXX\Leluc e.a. - 2022 - A Quadrature Rule combining Control Variates and A.pdf","","importance sampling; integration; control variates","Computer Science - Machine Learning; Statistics - Machine Learning; Mathematics - Statistics Theory","","","","","","","","","","","","","","","","","","","arXiv:2205.11890","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2679QTUF","preprint","2022","Fu, Fengjiang; Wang, Xiaoqun","Convergence analysis of a quasi-Monte Carlo-based deep learning algorithm for solving partial differential equations","","","","","http://arxiv.org/abs/2210.16196","Deep learning methods have achieved great success in solving partial diﬀerential equations (PDEs), where the loss is often deﬁned as an integral. The accuracy and eﬃciency of these algorithms depend greatly on the quadrature method. We propose to apply quasi-Monte Carlo (QMC) methods to the Deep Ritz Method (DRM) for solving the Neumann problems for the Poisson equation and the static Schr¨odinger equation. For error estimation, we decompose the error of using the deep learning algorithm to solve PDEs into the generalization error, the approximation error and the training error. We establish the upper bounds and prove that QMC-based DRM achieves an asymptotically smaller error bound than DRM. Numerical experiments show that the proposed method converges faster in all cases and the variances of the gradient estimators of randomized QMC-based DRM are much smaller than those of DRM, which illustrates the superiority of QMC in deep learning over MC.","2022-10-28","2023-01-14 20:47:26","2023-03-18 20:49:41","2023-01-14 20:47:26","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2210.16196 [cs, math]","","C:\Users\isido\Zotero\storage\SAFYTMXD\Fu en Wang - 2022 - Convergence analysis of a quasi-Monte Carlo-based .pdf","","monte carlo","Computer Science - Machine Learning; Mathematics - Numerical Analysis; 35J20, 35Q68, 65D30, 65N15, 68T07","","","","","","","","","","","","","","","","","","","arXiv:2210.16196","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8J5DJGS","journalArticle","2022","Wang, Xiaoyu; Yuan, Ya-xiang","Stochastic Trust Region Methods with Trust Region Radius Depending on Probabilistic Models","Journal of Computational Mathematics","","0254-9409, 1991-7139","10.4208/jcm.2012-m2020-0144","http://arxiv.org/abs/1904.03342","We present a stochastic trust-region model-based framework in which its radius is related to the probabilistic models. Especially, we propose a speciﬁc algorithm, termed STRME, in which the trust-region radius depends linearly on the latest model gradient. The complexity of STRME method in non-convex, convex and strongly convex settings has all been analyzed, which matches the existing algorithms based on probabilistic properties. In addition, several numerical experiments are carried out to reveal the beneﬁts of the proposed methods compared to the existing stochastic trust-region methods and other relevant stochastic gradient methods.","2022-06","2023-01-15 11:56:09","2023-03-18 20:49:33","2023-01-15 11:56:09","295-336","","2","40","","JCM","","","","","","","","en","","","","","arXiv.org","","arXiv:1904.03342 [math]","","C:\Users\isido\Zotero\storage\78W97RZH\Wang en Yuan - 2022 - Stochastic Trust Region Methods with Trust Region .pdf","","optimization","Mathematics - Optimization and Control; 65K05, 65K10, 90C60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V8LT2F5X","preprint","2022","Fang, Yuchen; Na, Sen; Mahoney, Michael W.; Kolar, Mladen","Fully Stochastic Trust-Region Sequential Quadratic Programming for Equality-Constrained Optimization Problems","","","","","http://arxiv.org/abs/2211.15943","We propose a trust-region stochastic sequential quadratic programming algorithm (TR-StoSQP) to solve nonlinear optimization problems with stochastic objectives and deterministic equality constraints. We consider a fully stochastic setting, where in each iteration a single sample is generated to estimate the objective gradient. The algorithm adaptively selects the trust-region radius and, compared to the existing line-search StoSQP schemes, allows us to employ indeﬁnite Hessian matrices (i.e., Hessians without modiﬁcation) in SQP subproblems. As a trust-region method for constrained optimization, our algorithm needs to address an infeasibility issue—the linearized equality constraints and trust-region constraints might lead to infeasible SQP subproblems. In this regard, we propose an adaptive relaxation technique to compute the trial step that consists of a normal step and a tangential step. To control the lengths of the two steps, we adaptively decompose the trust-region radius into two segments based on the proportions of the feasibility and optimality residuals to the full KKT residual. The normal step has a closed form, while the tangential step is solved from a trust-region subproblem, to which a solution ensuring the Cauchy reduction is suﬃcient for our study. We establish the global almost sure convergence guarantee for TR-StoSQP, and illustrate its empirical performance on both a subset of problems in the CUTEst test set and constrained logistic regression problems using data from the LIBSVM collection.","2022-11-29","2023-01-15 12:28:52","2023-03-18 20:49:26","2023-01-15 12:28:52","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2211.15943 [math, stat]","","C:\Users\isido\Zotero\storage\HIZ86IVL\Fang e.a. - 2022 - Fully Stochastic Trust-Region Sequential Quadratic.pdf","","optimization","Statistics - Machine Learning; Mathematics - Optimization and Control; Statistics - Computation","","","","","","","","","","","","","","","","","","","arXiv:2211.15943","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9VN6R4RF","preprint","2019","Curtis, Frank E.; Shi, Rui","A Fully Stochastic Second-Order Trust Region Method","","","","","http://arxiv.org/abs/1911.06920","A stochastic second-order trust region method is proposed, which can be viewed as a second-order extension of the trust-region-ish (TRish) algorithm proposed by Curtis et al. [INFORMS J. Optim. 1(3) 200–220, 2019]. In each iteration, a search direction is computed by (approximately) solving a trust region subproblem deﬁned by stochastic gradient and Hessian estimates. The algorithm has convergence guarantees for stochastic minimization in the fully stochastic regime, meaning that guarantees hold when each stochastic gradient is required merely to be an unbiased estimate of the true gradient with bounded variance and when the stochastic Hessian estimates are bounded uniformly in norm. The algorithm is also equipped with a worst-case complexity guarantee in the nearly deterministic regime, i.e., when the stochastic gradient and Hessian estimates are very close in expectation to the true gradients and Hessians. The results of numerical experiments for training convolutional neural networks for image classiﬁcation and training a recurrent neural network for time series forecasting are presented. These results show that the algorithm can outperform a stochastic gradient approach and the ﬁrst-order TRish algorithm in practice.","2019-11-15","2023-01-15 12:31:06","2023-03-18 20:49:19","2023-01-15 12:31:06","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1911.06920 [math]","","C:\Users\isido\Zotero\storage\3QTRRJEB\Curtis en Shi - 2019 - A Fully Stochastic Second-Order Trust Region Metho.pdf","","optimization","Mathematics - Optimization and Control","","","","","","","","","","","","","","","","","","","arXiv:1911.06920","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GC9E4KQ3","journalArticle","2020","Chauhan, Vinod Kumar; Sharma, Anuj; Dahiya, Kalpana","Stochastic Trust Region Inexact Newton Method for Large-scale Machine Learning","International Journal of Machine Learning and Cybernetics","","1868-8071, 1868-808X","10.1007/s13042-019-01055-9","http://arxiv.org/abs/1812.10426","Nowadays stochastic approximation methods are one of the major research direction to deal with the large-scale machine learning problems. From stochastic ﬁrst order methods, now the focus is shifting to stochastic second order methods due to their faster convergence and availability of computing resources. In this paper, we have proposed a novel Stochastic Trust RegiOn Inexact Newton method, called as STRON, to solve large-scale learning problems which uses conjugate gradient (CG) to inexactly solve trust region subproblem. The method uses progressive subsampling in the calculation of gradient and Hessian values to take the advantage of both, stochastic and full-batch regimes. We have extended STRON using existing variance reduction techniques to deal with the noisy gradients and using preconditioned conjugate gradient (PCG) as subproblem solver, and empirically proved that they do not work as expected, for the large-scale learning problems. Finally, our empirical results prove eﬃcacy of the proposed method against existing methods with bench marked datasets.","2020-07","2023-01-15 12:31:26","2023-03-18 20:49:14","2023-01-15 12:31:26","1541-1555","","7","11","","Int. J. Mach. Learn. & Cyber.","","","","","","","","en","","","","","arXiv.org","","arXiv:1812.10426 [cs, stat]","","C:\Users\isido\Zotero\storage\7YWNREP2\Chauhan e.a. - 2020 - Stochastic Trust Region Inexact Newton Method for .pdf","","optimization","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBIYSWBJ","videoRecording","2021","Stand-up Maths","How does Dobble (Spot It) work?","","","","","https://www.youtube.com/watch?v=VTDKqW_GLkw","","2021-04-30","2023-01-16 13:29:01","2023-01-16 13:29:01","2023-01-16 13:29:01","","","","","","","","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","28:36","","","","","","","","","","","","","","","","","","","","","","","","",""
"5DUKLXYL","encyclopediaArticle","2022","","Aitken's delta-squared process","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Aitken%27s_delta-squared_process&oldid=1115576594","In numerical analysis, Aitken's delta-squared process or Aitken extrapolation is a series acceleration method, used for accelerating the rate of convergence of a sequence. It is named after Alexander Aitken, who introduced this method in 1926. Its early form was known to Seki Kōwa (end of 17th century) and was found for rectification of the circle, i.e. the calculation of π. It is most useful for accelerating the convergence of a sequence that is converging linearly.","2022-10-12","2023-01-16 16:21:27","2023-01-16 16:21:27","2023-01-16 16:21:27","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1115576594","","C:\Users\isido\Zotero\storage\QPP3CBBR\Aitken's_delta-squared_process.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D76YE6FY","encyclopediaArticle","2022","","Runge's phenomenon","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Runge%27s_phenomenon&oldid=1127648067","In the mathematical field of numerical analysis, Runge's phenomenon (German: [ˈʁʊŋə]) is a problem of oscillation at the edges of an interval that occurs when using polynomial interpolation with polynomials of high degree over a set of equispaced interpolation points. It was discovered by Carl David Tolmé Runge (1901) when exploring the behavior of errors when using polynomial interpolation to approximate certain functions. The discovery was important because it shows that going to higher degrees does not always improve accuracy. The phenomenon is similar to the Gibbs phenomenon in Fourier series approximations.","2022-12-15","2023-01-18 20:57:45","2023-01-18 20:57:45","2023-01-18 20:57:44","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1127648067","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9A9Q5UIA","encyclopediaArticle","2022","","Gibbs phenomenon","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Gibbs_phenomenon&oldid=1120811333","In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The function's                         N                 {\displaystyle N}   th partial Fourier series (formed by summing its                         N                 {\displaystyle N}    lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the function's actual values. This approximation error approaches a limit of about 9% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.The Gibbs phenomenon was observed by experimental physicists, but was believed to be due to imperfections in the measuring apparatus, and it is one cause of ringing artifacts in signal processing.","2022-11-08","2023-01-18 20:57:51","2023-01-18 20:57:51","2023-01-18 20:57:51","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1120811333","","C:\Users\isido\Zotero\storage\H38JL4E9\Gibbs_phenomenon.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IGKF6LI","preprint","2022","Penent, Guillaume; Privault, Nicolas","Numerical evaluation of ODE solutions by Monte Carlo enumeration of Butcher series","","","","","http://arxiv.org/abs/2201.05998","We present an algorithm for the numerical solution of ordinary diﬀerential equations by random enumeration of the Butcher trees used in the implementation of the RungeKutta method. Our Monte Carlo scheme allows for the direct numerical evaluation of an ODE solution at any given time within a certain interval, without iteration through multiple time steps. In particular, this approach does not involve a discretization step size, and it does not require the truncation of Taylor series.","2022-08-24","2023-01-20 09:27:05","2023-03-19 11:07:58","2023-01-20 09:27:05","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2201.05998 [cs, math]","","C:\Users\isido\Zotero\storage\UXRFJ68P\Penent en Privault - 2022 - Numerical evaluation of ODE solutions by Monte Car.pdf","","monte carlo; ODE; green function","Mathematics - Probability; Mathematics - Numerical Analysis; 65L06, 34A25, 34-04, 05C05, 65C05","","","","","","","","","","","","","","","","","","","arXiv:2201.05998","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5HXPC7H7","journalArticle","2006","Mori, Masatake; Echigo, Toshihiko","Numerical Green’s function method based on the DE transformation","Japan Journal of Industrial and Applied Mathematics","","0916-7005, 1868-937X","10.1007/BF03167550","http://link.springer.com/10.1007/BF03167550","A method for numerical solution of boundary value problems with ordinary diﬀerential equation based on the method of Green’s function incorporated with the double exponential transformation is presented. The method proposed does not require solving a system of linear equations and gives an approximate solution of very high accuracy with a small number of function evaluations. The error of the method is O (exp (−C1N/ log(C2N ))) where N is a parameter representing the number of function evaluations and C1 and C2 are some positive constants. Numerical examples also prove the high eﬃciency of the method. An alternative method via an integral equation is presented which can be used when the Green’s function corresponding to the given equation is not available.","2006-06","2023-01-20 09:42:40","2023-03-18 20:48:52","2023-01-20 09:42:40","193-205","","2","23","","Japan J. Indust. Appl. Math.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\U5ZLG7FE\Mori en Echigo - 2006 - Numerical Green’s function method based on the DE .pdf","","green function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UA5NRBZW","journalArticle","2019","Ermakov, S. M.; Tovstik, T. M.","Monte Carlo Method for Solving ODE Systems","Vestnik St. Petersburg University, Mathematics","","1063-4541, 1934-7855","10.1134/S1063454119030087","https://link.springer.com/10.1134/S1063454119030087","The Monte Carlo method is applied to solve Cauchy problems for a system of linear and nonlinear ordinary differential equations. The Monte Carlo method is relevant for the solution of large systems of equations and in the case of small smoothness of initial functions. In this case, the system is reduced to an equivalent system of integral equations of the Volterra type. For linear systems, this transformation allows removing constraints connected with a convergence of a majorizing process. Examples of estimates of solution functionals are provided, and a behavior of their variances are discussed. In the general case, a solution interval is divided into finite subintervals, on which the nonlinear function is approximated by a polynomial. The obtained integral equation is solved by using branched Markov chains with absorption. Algorithm parallelization problems arising in this case are discussed in this paper. A one-dimensional cubic equation is considered as an example. A choice of transition densities of branching is discussed. A method of generations is described in detail. Numerical results are compared with a solution obtained by the Runge–Kutta method.","2019-07","2023-01-20 09:43:02","2023-03-18 20:48:42","2023-01-20 09:43:02","272-280","","3","52","","Vestnik St.Petersb. Univ.Math.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\UM598GXH\Ermakov en Tovstik - 2019 - Monte Carlo Method for Solving ODE Systems.pdf","","monte carlo; ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JG29V6PV","journalArticle","2021","Ermakov, S. M.; Smilovitskiy, M. G.","The Monte Carlo Method for Solving Large Systems of Linear Ordinary Differential Equations","Vestnik St. Petersburg University, Mathematics","","1063-4541, 1934-7855","10.1134/S1063454121010064","https://link.springer.com/10.1134/S1063454121010064","The Monte Carlo method to solve the Cauchy problem for large systems of linear differential equations is proposed in this paper. Firstly, a quick overview of previously obtained results from applying the approach towards the Fredholm-type integral equations is made. In the main part of the paper, the method is applied towards a linear ODE system that is transformed into an equivalent system of the Volterra-type integral equations, which makes it possible to remove the limitations due to the conditions of convergence of the majorant series. The following key theorems are stated. Theorem 1 provides the necessary compliance conditions that should be imposed upon the transition propability and initial distribution densities that initiate the corresponding Markov chain, for which equality between the mathematical expectation of the estimate and the functional of interest would hold. Theorem 2 formulates the equation that governs the estimate’s variance. Theorem 3 states the Markov chain parameters that minimize the variance of the estimate of the functional. Proofs are given for all three theorems. In the practical part of this paper, the proposed method is used to solve a linear ODE system that describes a closed queueing system of ten conventional machines and seven conventional service persons. The solutions are obtained for systems with both constant and time-dependent matrices of coefficients, where the machine breakdown intensity is time dependent. In addition, the solutions obtained by the Monte Carlo and Runge–Kutta methods are compared. The results are presented in the corresponding tables.","2021-01","2023-01-20 09:55:47","2023-06-19 12:49:37","2023-01-20 09:55:47","28-38","","1","54","","Vestnik St.Petersb. Univ.Math.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\EXRTHDXP\Ermakov en Smilovitskiy - 2021 - The Monte Carlo Method for Solving Large Systems o.pdf","","monte carlo; linear systems; MC ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULM9AGUM","journalArticle","","Halton, John H","Sequential Monte Carlo techniques for solving non-linear systems","Linear Systems","","","","","Given a system of m equations F(x ) = 0 (where m is large and x is an unknown m-vector), we seek to apply sequential Monte Carlo [SMC] methods to find solutions efficiently. This paper follows up on a previous paper by the same author, in which consideration was limited to linear systems of the form Ax = a (where, again, m is large, A is a known (m¥m) matrix, a is a known m-vector, and x is an unknown m-vector). It was shown there that effective techniques could reduce computation times dramatically (speed-up factors of 550 to 26,000 were obtained in sample calculations).","","2023-01-20 18:11:24","2023-03-18 20:46:28","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\GNEKPJHM\Halton - Sequential Monte Carlo techniques for solving non-.pdf","","monte carlo; nonlinear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSK2T2V4","journalArticle","1974","Nekrutkin, V.V.","Direct and conjugate Neumann-Ulam schemes for solving non-linear integral equations","USSR Computational Mathematics and Mathematical Physics","","00415553","10.1016/0041-5553(74)90167-0","https://linkinghub.elsevier.com/retrieve/pii/0041555374901670","ELEMENTARY unbiased estimates are constructed for a linear functional of the solution of a non-linear integral equation of fairly general type. The method of constructing the estimates, which is based on the “equivalence” of the initial equation to an infinite system of linear equations, makes it possible to transfer to the so-called conjugate Neumann-Ulam scheme, which can prove more advantageous when solving physical problems.","1974-01","2023-01-20 18:23:26","2023-08-03 17:48:36","2023-01-20 18:23:26","39-45","","6","14","","USSR Computational Mathematics and Mathematical Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\48XNIP74\Nekrutkin - 1974 - Direct and conjugate Neumann-Ulam schemes for solv.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW85UZ53","document","","","THE NEYMAN-ULAM SCHEME IN THE NON-LINEAR CASE*","","","","","","","","2023-01-20 18:24:16","2023-03-18 20:45:45","","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\SSN79QHC\1-s2.0-0041555373900980-main.pdf","","monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZB5PTJDF","encyclopediaArticle","2022","","Exponential integrator","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Exponential_integrator&oldid=1123597413","Exponential integrators are a class of numerical methods for the solution of ordinary differential equations, specifically initial value problems.  This large class of methods from numerical analysis is based on the exact integration of the linear part of the initial value problem. Because the linear part is integrated exactly, this can help to mitigate the stiffness of a differential equation. Exponential integrators can be constructed to be explicit or implicit for numerical ordinary differential equations or serve as the time integrator for numerical partial differential equations.","2022-11-24","2023-01-22 21:01:01","2023-03-18 20:41:28","2023-01-22 21:01:01","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1123597413","","C:\Users\isido\Zotero\storage\XH6LIQZ3\Exponential_integrator.html","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJB4PHU9","journalArticle","2005","Hochbruck, Marlis; Ostermann, Alexander","Exponential Runge–Kutta methods for parabolic problems","Applied Numerical Mathematics","","01689274","10.1016/j.apnum.2004.08.005","https://linkinghub.elsevier.com/retrieve/pii/S0168927404001400","The aim of this paper is to construct exponential Runge-Kutta methods of collocation type and to analyze their convergence properties for linear and semilinear parabolic problems. For the analysis, an abstract Banach space framework of sectorial operators and locally Lipschitz continuous nonlinearities is chosen. This framework includes interesting examples like reaction-diﬀusion equations. It is shown that the methods converge at least with their stage order, and that convergence of higher order (up to the classical order) occurs, if the problem has suﬃcient temporal and spatial smoothness. The latter, however, might require the source function to fulﬁl unnatural boundary conditions. Therefore, the classical order is not always obtained and an order reduction must be expected, in general.","2005-05","2023-01-22 21:12:12","2023-03-18 20:41:20","2023-01-22 21:12:12","323-339","","2-4","53","","Applied Numerical Mathematics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\NHR96XVY\Hochbruck en Ostermann - 2005 - Exponential Runge–Kutta methods for parabolic prob.pdf","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5ZS76WE","journalArticle","2010","Hochbruck, Marlis; Ostermann, Alexander","Exponential integrators","Acta Numerica","","0962-4929, 1474-0508","10.1017/S0962492910000048","https://www.cambridge.org/core/product/identifier/S0962492910000048/type/journal_article","In this paper we consider the construction, analysis, implementation and application of exponential integrators. The focus will be on two types of stiff problems. The first one is characterized by a Jacobian that possesses eigenvalues with large negative real parts. Parabolic partial differential equations and their spatial discretization are typical examples. The second class consists of highly oscillatory problems with purely imaginary eigenvalues of large modulus. Apart from motivating the construction of exponential integrators for various classes of problems, our main intention in this article is to present the mathematics behind these methods. We will derive error bounds that are independent of stiffness or highest frequencies in the system.             Since the implementation of exponential integrators requires the evaluation of the product of a matrix function with a vector, we will briefly discuss some possible approaches as well. The paper concludes with some applications, in which exponential integrators are used.","2010-05","2023-01-23 20:33:08","2023-03-18 20:41:15","2023-01-23 20:33:08","209-286","","","19","","Acta Numerica","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\C73HIPVU\Hochbruck en Ostermann - 2010 - Exponential integrators.pdf","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5F4A5X4","journalArticle","2000","Bergamaschi, Luca; Vianello, Marco","Efficient computation of the exponential operator for large, sparse, symmetric matrices","Numerical Linear Algebra with Applications","","1070-5325, 1099-1506","10.1002/(SICI)1099-1506(200001/02)7:1<27::AID-NLA185>3.0.CO;2-4","https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1099-1506(200001/02)7:1<27::AID-NLA185>3.0.CO;2-4","In this paper we compare Krylov subspace methods with Chebyshev series expansion for approximating the matrix exponential operator on large, sparse, symmetric matrices. Experimental results upon negative-deﬁnite matrices with very large size, arising from (2D and 3D) FE and FD spatial discretization of linear parabolic PDEs, demonstrate that the Chebyshev method can be an effective alternative to Krylov techniques, especially when memory bounds do not allow the storage of all Ritz vectors. We discuss also sensitivity of Chebyshev convergence to extreme eigenvalue approximation, as well as reliability of various a priori and a posteriori error estimates for both methods.","2000-01","2023-01-23 20:58:20","2023-03-18 20:41:10","2023-01-23 20:58:20","27-45","","1","7","","Numer. Linear Algebra Appl.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\5HP78YEJ\Bergamaschi en Vianello - 2000 - Efficient computation of the exponential operator .pdf","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGQ3JN9R","encyclopediaArticle","2022","","Padé approximant","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Pad%C3%A9_approximant&oldid=1123396275","In mathematics, a Padé approximant is the ""best"" approximation of a function near a specific point by a rational function of given order. Under this technique, the approximant's power series agrees with the power series of the function it is approximating.  The technique was developed around 1890 by Henri Padé, but goes back to Georg Frobenius, who introduced the idea and investigated the features of rational approximations of power series. The Padé approximant often gives better approximation of the function than truncating its Taylor series, and it may still work where the Taylor series does not converge. For these reasons Padé approximants are used extensively in computer calculations. They have also been used as auxiliary functions in Diophantine approximation and transcendental number theory, though for sharp results ad hoc methods— in some sense inspired by the Padé theory— typically replace them. Since Padé approximant is a rational function, an artificial singular point may occur as an approximation, but this can be avoided by Borel–Padé analysis. The reason why the Padé approximant tends to be a better approximation than a truncating Taylor series is clear from the viewpoint of the multi-point summation method. Since there are many cases in which the asymptotic expansion at infinity becomes 0 or a constant, it can be interpreted as the ""incomplete two-point Padé approximation"", in which the ordinary Padé approximation improves the method truncating a Taylor series.","2022-11-23","2023-01-23 21:13:48","2023-01-23 21:13:48","2023-01-23 21:13:48","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1123396275","","C:\Users\isido\Zotero\storage\KVILJA4H\Padé_approximant.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFXB57DW","journalArticle","2014","Sastre, J.; Ibáñez, J.; Ruiz, P.; Defez, E.","Accurate and efficient matrix exponential computation","International Journal of Computer Mathematics","","0020-7160, 1029-0265","10.1080/00207160.2013.791392","http://www.tandfonline.com/doi/abs/10.1080/00207160.2013.791392","This work gives a new formula for the forward relative error of matrix exponential Taylor approximation and proposes new bounds for it depending on the matrix size and the Taylor approximation order, providing a new efficient scaling and squaring Taylor algorithm for the matrix exponential. A Matlab version of the new algorithm is provided and compared with Pade  ́ state-of-the-art algorithms obtaining higher accuracy in the majority of tests at similar or even lower cost.","2014-01-02","2023-01-23 21:18:10","2023-08-03 17:47:49","2023-01-23 21:18:10","97-112","","1","91","","International Journal of Computer Mathematics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\QEY4VDFZ\Sastre e.a. - 2014 - Accurate and efficient matrix exponential computat.pdf","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4MW9JWQK","encyclopediaArticle","2022","","Matrix exponential","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Matrix_exponential&oldid=1122134034","In mathematics, the matrix exponential is a matrix function on square matrices analogous to the ordinary exponential function. It is used to solve systems of linear differential equations. In the theory of Lie groups, the matrix exponential gives the exponential map between a matrix Lie algebra and the corresponding Lie group. Let X  be an n×n real or complex matrix. The exponential of X, denoted by eX or exp(X), is the n×n matrix given by the power series where                                    X                        0                                     {\displaystyle X^{0}}    is defined to be the identity matrix                         I                 {\displaystyle I}    with the same dimensions as                         X                 {\displaystyle X}   .The above series always converges, so the exponential of X is well-defined. If X is a 1×1 matrix the matrix exponential of X is a 1×1 matrix whose single element is the ordinary exponential of the single element of X.","2022-11-16","2023-01-23 21:25:25","2023-03-18 20:40:49","2023-01-23 21:25:25","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1122134034","","","","exponential integrators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"325A7RN6","journalArticle","2022","Ermakov, S. M.; Surovikina, T. O.","Backward Iterations for Solving Integral Equations with Polynomial Nonlinearity","Vestnik St. Petersburg University, Mathematics","","1063-4541, 1934-7855","10.1134/S1063454122010046","https://link.springer.com/10.1134/S1063454122010046","The theory of adjoint operators is widely used in solving applied multidimensional problems with the Monte Carlo method. Efficient algorithms are constructed using the duality principle for many problems described in linear integral equations of the second kind. On the other hand, important applications of adjoint equations for designing experiments were suggested by G.I. Marchuk and his colleagues in their respective works. Some results obtained in these fields are also generalized to the case of nonlinear operators. Linearization methods are mostly used for that purpose. The results for Lyapunov–Schmidt nonlinear polynomial equations are obtained in the theory of Monte Carlo methods. However, many interesting questions in this subject area remain open. New results about dual processes used for solving polynomial equations with the Monte Carlo method are presented. In particular, the adjoint Markov process for the branching process and corresponding unbiased estimate of the functional of the solution to the equation are constructed in the general form. The possibility of constructing an adjoint operator to a nonlinear one is discussed.","2022-03","2023-01-24 15:09:45","2023-03-18 20:40:32","2023-01-24 15:09:45","16-26","","1","55","","Vestnik St.Petersb. Univ.Math.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\MGBUUSKA\Ermakov en Surovikina - 2022 - Backward Iterations for Solving Integral Equations.pdf","","integral equations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBNSUT7K","preprint","2023","Li, Yongming; Neufeld, Ariel","Quantum Monte Carlo algorithm for solving Black-Scholes PDEs for high-dimensional option pricing in finance and its proof of overcoming the curse of dimensionality","","","","","http://arxiv.org/abs/2301.09241","In this paper we provide a quantum Monte Carlo algorithm to solve high-dimensional Black-Scholes PDEs with correlation for high-dimensional option pricing. The payoﬀ function of the option is of general form and is only required to be continuous and piece-wise aﬃne (CPWA), which covers most of the relevant payoﬀ functions used in ﬁnance. We provide a rigorous error analysis and complexity analysis of our algorithm. In particular, we prove that the computational complexity of our algorithm is bounded polynomially in the space dimension d of the PDE and the reciprocal of the prescribed accuracy ε and so demonstrate that our quantum Monte Carlo algorithm does not suﬀer from the curse of dimensionality.","2023-01-22","2023-01-24 15:53:34","2023-03-19 11:08:07","2023-01-24 15:53:34","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2301.09241 [quant-ph, q-fin]","","C:\Users\isido\Zotero\storage\2UE3LKA6\Li en Neufeld - 2023 - Quantum Monte Carlo algorithm for solving Black-Sc.pdf","","monte carlo; ODE","Quantitative Finance - Computational Finance; Mathematics - Numerical Analysis; Quantitative Finance - Mathematical Finance; Quantum Physics","","","","","","","","","","","","","","","","","","","arXiv:2301.09241","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZH2DB9F2","encyclopediaArticle","2022","","Stochastic partial differential equation","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Stochastic_partial_differential_equation&oldid=1129102419","Stochastic partial differential equations (SPDEs) generalize partial differential equations via random force terms and coefficients, in the same way ordinary stochastic differential equations generalize ordinary differential equations. They have relevance to quantum field theory, statistical mechanics, and spatial modeling.","2022-12-23","2023-01-24 16:02:55","2023-01-24 16:02:55","2023-01-24 16:02:55","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1129102419","","C:\Users\isido\Zotero\storage\KXX22C9Y\Stochastic_partial_differential_equation.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HL55QPUC","preprint","2022","Becker, Sebastian; Jentzen, Arnulf; Müller, Marvin S.; von Wurstemberger, Philippe","Learning the random variables in Monte Carlo simulations with stochastic gradient descent: Machine learning for parametric PDEs and financial derivative pricing","","","","","http://arxiv.org/abs/2202.02717","In financial engineering, prices of financial products are computed approximately many times each trading day with (slightly) different parameters in each calculation. In many financial models such prices can be approximated by means of Monte Carlo (MC) simulations. To obtain a good approximation the MC sample size usually needs to be considerably large resulting in a long computing time to obtain a single approximation. In this paper we introduce a new approximation strategy for parametric approximation problems including the parametric financial pricing problems described above. A central aspect of the approximation strategy proposed in this article is to combine MC algorithms with machine learning techniques to, roughly speaking, learn the random variables (LRV) in MC simulations. In other words, we employ stochastic gradient descent (SGD) optimization methods not to train parameters of standard artificial neural networks (ANNs) but to learn random variables appearing in MC approximations. We numerically test the LRV strategy on various parametric problems with convincing results when compared with standard MC simulations, Quasi-Monte Carlo simulations, SGD-trained shallow ANNs, and SGD-trained deep ANNs. Our numerical simulations strongly indicate that the LRV strategy might be capable to overcome the curse of dimensionality in the $L^\infty$-norm in several cases where the standard deep learning approach has been proven not to be able to do so. This is not a contradiction to lower bounds established in the scientific literature because this new LRV strategy is outside of the class of algorithms for which lower bounds have been established in the scientific literature. The proposed LRV strategy is of general nature and not only restricted to the parametric financial pricing problems described above, but applicable to a large class of approximation problems.","2022-02-06","2023-01-24 16:21:57","2023-03-18 20:40:07","2023-01-24 16:21:57","","","","","","","Learning the random variables in Monte Carlo simulations with stochastic gradient descent","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2202.02717 [cs, math]","","C:\Users\isido\Zotero\storage\ZT28NZYQ\Becker e.a. - 2022 - Learning the random variables in Monte Carlo simul.pdf","","monte carlo; PDE; optimization; machine learning","Mathematics - Probability; Mathematics - Numerical Analysis; Mathematics - Analysis of PDEs; 35K15, 65C05, 65M75, 68T99, 91G20","","","","","","","","","","","","","","","","","","","arXiv:2202.02717","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DEIPCR4","preprint","2022","Nguwi, Jiang Yu; Penent, Guillaume; Privault, Nicolas","A fully nonlinear Feynman-Kac formula with derivatives of arbitrary orders","","","","","http://arxiv.org/abs/2201.03882","We present an algorithm for the numerical solution of nonlinear parabolic partial diﬀerential equations. This algorithm extends the classical Feynman-Kac formula to fully nonlinear partial diﬀerential equations, by using random trees that carry information on nonlinearities on their branches. It applies to functional, non-polynomial nonlinearities that are not treated by standard branching arguments, and deals with derivative terms of arbitrary orders. A Monte Carlo numerical implementation is provided.","2022-12-14","2023-01-24 16:29:09","2023-03-18 20:39:17","2023-01-24 16:29:09","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2201.03882 [math]","","C:\Users\isido\Zotero\storage\XRMIKRSC\Nguwi e.a. - 2022 - A fully nonlinear Feynman-Kac formula with derivat.pdf","","monte carlo; PDE","Mathematics - Probability; Mathematics - Analysis of PDEs; 35G20, 35K55, 35K58, 35B65, 60J85, 60G51, 65C05","","","","","","","","","","","","","","","","","","","arXiv:2201.03882","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYJ9QE2D","encyclopediaArticle","2023","","Branching process","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Branching_process&oldid=1131945188","In probability theory, a branching process is a type of mathematical object known as a stochastic process, which consists of collections of random variables. The random variables of a stochastic process are indexed by the natural numbers. The original purpose of branching processes was to serve as a mathematical model of a population in which each individual in generation                         n                 {\displaystyle n}    produces some random number of individuals in generation                         n         +         1                 {\displaystyle n+1}   , according, in the simplest case, to a fixed probability distribution that does not vary from individual to individual. Branching processes are used to model reproduction; for example, the individuals might correspond to bacteria, each of which generates 0, 1, or 2 offspring with some probability in a single time unit.  Branching processes can also be used to model other systems with similar dynamics, e.g., the spread of surnames in genealogy or the propagation of neutrons in a nuclear reactor. A central question in the theory of branching processes is the probability of ultimate extinction, where no individuals exist after some finite number of generations.  Using Wald's equation, it can be shown that starting with one individual in generation zero, the expected size of generation n equals μn where μ is the expected number of children of each individual.  If μ < 1, then the expected number of individuals goes rapidly to zero, which implies ultimate extinction with probability 1 by Markov's inequality.  Alternatively, if μ > 1, then the probability of ultimate extinction is less than 1 (but not necessarily zero; consider a process where each individual either has 0 or 100 children with equal probability. In that case, μ = 50, but probability of ultimate extinction is greater than 0.5, since that's the probability that the first individual has 0 children).  If μ = 1, then ultimate extinction occurs with probability 1 unless each individual always has exactly one child. In theoretical ecology, the parameter μ of a branching process is called the basic reproductive rate.","2023-01-06","2023-01-24 16:43:50","2023-01-24 16:43:50","2023-01-24 16:43:50","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1131945188","","C:\Users\isido\Zotero\storage\NDK5UH98\Branching_process.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGVPH3T5","preprint","2016","Henry-Labordere, Pierre; Oudjane, Nadia; Tan, Xiaolu; Touzi, Nizar; Warin, Xavier","Branching diffusion representation of semilinear PDEs and Monte Carlo approximation","","","","","http://arxiv.org/abs/1603.01727","We provide a representation result of parabolic semi-linear PD-Es, with polynomial nonlinearity, by branching diﬀusion processes. We extend the classical representation for KPP equations, introduced by Skorokhod [23], Watanabe [27] and McKean [18], by allowing for polynomial nonlinearity in the pair (u, Du), where u is the solution of the PDE with space gradient Du. Similar to the previous literature, our result requires a non-explosion condition which restrict to “small maturity” or “small nonlinearity” of the PDE. Our main ingredient is the automatic diﬀerentiation technique as in [15], based on the Malliavin integration by parts, which allows to account for the nonlinearities in the gradient. As a consequence, the particles of our branching diﬀusion are marked by the nature of the nonlinearity. This new representation has very important numerical implications as it is suitable for Monte Carlo simulation. Indeed, this provides the ﬁrst numerical method for high dimensional nonlinear PDEs with error estimate induced by the dimension-free Central limit theorem. The complexity is also easily seen to be of the order of the squared dimension. The ﬁnal section of this paper illustrates the eﬃciency of the algorithm by some high dimensional numerical experiments.","2016-03-05","2023-01-24 16:53:08","2023-03-18 20:37:24","2023-01-24 16:53:08","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1603.01727 [math]","","C:\Users\isido\Zotero\storage\6HC4YVGI\Henry-Labordere e.a. - 2016 - Branching diffusion representation of semilinear P.pdf","","monte carlo; PDE","Mathematics - Probability; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1603.01727","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MV22E3D5","preprint","2022","Hout, Karel in 't; Lamotte, Pieter","Efficient numerical valuation of European options under the two-asset Kou jump-diffusion model","","","","","http://arxiv.org/abs/2207.10060","This paper concerns the numerical solution of the two-dimensional time-dependent partial integro-diﬀerential equation (PIDE) that holds for the values of European-style options under the two-asset Kou jump-diﬀusion model. A main feature of this equation is the presence of a nonlocal double integral term. For its numerical evaluation, we extend a highly eﬃcient algorithm derived by Toivanen [30] in the case of the one-dimensional Kou integral. The acquired algorithm for the two-dimensional Kou integral has optimal computational cost: the number of basic arithmetic operations is directly proportional to the number of spatial grid points in the semidiscretization. For the eﬀective discretization in time, we study seven contemporary operator splitting schemes of the implicit-explicit (IMEX) and the alternating direction implicit (ADI) kind. All these schemes allow for a convenient, explicit treatment of the integral term. By ample numerical experiments for put-on-the-average option values, the stability and convergence behaviour as well as the mutual performance of the seven operator splitting schemes are investigated. Moreover, the Greeks Delta and Gamma are considered.","2022-07-20","2023-01-24 17:20:25","2023-03-18 20:36:35","2023-01-24 17:20:25","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2207.10060 [cs, math, q-fin]","","C:\Users\isido\Zotero\storage\65FUB6WN\Hout en Lamotte - 2022 - Efficient numerical valuation of European options .pdf","","finance","Quantitative Finance - Computational Finance; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2207.10060","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4J4JQIU6","journalArticle","2021","Černý, Aleš; Ruf, Johannes","Simplified stochastic calculus with applications in Economics and Finance","European Journal of Operational Research","","03772217","10.1016/j.ejor.2020.12.037","http://arxiv.org/abs/1912.03651","The paper introduces a simple way of recording and manipulating general stochastic processes without explicit reference to a probability measure. In the new calculus, operations traditionally presented in a measure-speciﬁc way are instead captured by tracing the behaviour of jumps (also when no jumps are physically present). The calculus is fail-safe in that, under minimal assumptions, all informal calculations yield mathematically well-deﬁned stochastic processes. The calculus is also intuitive as it allows the user to pretend all jumps are of compound Poisson type. The new calculus is very eﬀective when it comes to computing drifts and expected values that possibly involve a change of measure. Such drift calculations yield, for example, partial integro–diﬀerential equations, Hamilton–Jacobi–Bellman equations, Feynman–Kac formulae, or exponential moments needed in numerous applications. We provide several illustrations of the new technique, among them a novel result on the Margrabe option to exchange one defaultable asset for another.","2021-09","2023-01-24 17:55:38","2023-03-18 20:36:26","2023-01-24 17:55:38","547-560","","2","293","","European Journal of Operational Research","","","","","","","","en","","","","","arXiv.org","","arXiv:1912.03651 [math, q-fin]","","C:\Users\isido\Zotero\storage\7NICUN3Z\Černý en Ruf - 2021 - Simplified stochastic calculus with applications i.pdf","","finance","Mathematics - Probability; Quantitative Finance - Mathematical Finance; (Primary) 60H05, 60H10, 60G44, 60G48, (Secondary) 91B02, 91B25, 91G10","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7FY9MKB5","preprint","2021","Blechschmidt, Jan; Ernst, Oliver G.","Three Ways to Solve Partial Differential Equations with Neural Networks -- A Review","","","","","http://arxiv.org/abs/2102.11802","Neural networks are increasingly used to construct numerical solution methods for partial diﬀerential equations. In this expository review, we introduce and contrast three important recent approaches attractive in their simplicity and their suitability for high-dimensional problems: physics-informed neural networks, methods based on the Feynman-Kac formula and methods based on the solution of backward stochastic diﬀerential equations. The article is accompanied by a suite of expository software in the form of Jupyter notebooks in which each basic methodology is explained step by step, allowing for a quick assimilation and experimentation. An extensive bibliography summarizes the state of the art.","2021-04-14","2023-01-24 17:59:17","2023-03-18 20:36:11","2023-01-24 17:59:17","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2102.11802 [cs, math]","","C:\Users\isido\Zotero\storage\3CQBUAIB\Blechschmidt en Ernst - 2021 - Three Ways to Solve Partial Differential Equations.pdf","","PDE; machine learning","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2102.11802","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBPV3MJC","journalArticle","2019","E, Weinan; Hutzenthaler, Martin; Jentzen, Arnulf; Kruse, Thomas","On multilevel Picard numerical approximations for high-dimensional nonlinear parabolic partial differential equations and high-dimensional nonlinear backward stochastic differential equations","Journal of Scientific Computing","","0885-7474, 1573-7691","10.1007/s10915-018-00903-0","http://arxiv.org/abs/1708.03223","Parabolic partial diﬀerential equations (PDEs) and backward stochastic diﬀerential equations (BSDEs) are key ingredients in a number of models in physics and ﬁnancial engineering. In particular, parabolic PDEs and BSDEs are fundamental tools in the state-of-the-art pricing and hedging of ﬁnancial derivatives. The PDEs and BSDEs appearing in such applications are often high-dimensional and nonlinear. Since explicit solutions of such PDEs and BSDEs are typically not available, it is a very active topic of research to solve such PDEs and BSDEs approximately. In the recent article [E, W., Hutzenthaler, M., Jentzen, A., & Kruse, T. Linear scaling algorithms for solving high-dimensional nonlinear parabolic diﬀerential equations. arXiv:1607.03295 (2017)] we proposed a family of approximation methods based on Picard approximations and multilevel Monte Carlo methods and showed under suitable regularity assumptions on the exact solution for semilinear heat equations that the computational complexity is bounded by O(d ε−(4+δ)) for any δ ∈ (0, ∞), where d is the dimensionality of the problem and ε ∈ (0, ∞) is the prescribed accuracy. In this paper, we test the applicability of this algorithm on a variety of 100-dimensional nonlinear PDEs that arise in physics and ﬁnance by means of numerical simulations presenting approximation accuracy against runtime. The simulation results for these 100-dimensional example PDEs are very satisfactory in terms of accuracy and speed. In addition, we also provide a review of other approximation methods for nonlinear PDEs and BSDEs from the literature.","2019-06","2023-01-24 21:08:08","2023-03-19 15:58:27","2023-01-24 21:08:08","1534-1571","","3","79","","J Sci Comput","","","","","","","","en","","","","","arXiv.org","","arXiv:1708.03223 [math]","","C:\Users\isido\Zotero\storage\GNSPNCPT\E e.a. - 2019 - On multilevel Picard numerical approximations for .pdf","","PDE","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FCILPQL","preprint","2017","Warin, Xavier","Variations on branching methods for non linear PDEs","","","","","http://arxiv.org/abs/1701.07660","The branching methods developed in [9], [11] are eﬀective methods to solve some semi linear PDEs and are shown numerically to be able to solve some full non linear PDEs. These methods are however restricted to some small coeﬃcients in the PDE and small maturities. This article shows numerically that these methods can be adapted to solve the problems with longer maturities in the semi-linear case by using a new derivation scheme and some nested method. As for the case of full non linear PDEs, we introduce new schemes and we show numerically that they provide an eﬀective alternative to the schemes previously developed.","2017-01-26","2023-01-24 21:08:46","2023-03-18 20:35:40","2023-01-24 21:08:46","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1701.07660 [math]","","C:\Users\isido\Zotero\storage\CK46H39I\Warin - 2017 - Variations on branching methods for non linear PDE.pdf","","monte carlo; PDE","Mathematics - Probability; 65C05, 60J60, 60J85, 35K10","","","","","","","","","","","","","","","","","","","arXiv:1701.07660","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"434UNRWM","preprint","2018","Warin, Xavier","Nesting Monte Carlo for high-dimensional Non Linear PDEs","","","","","http://arxiv.org/abs/1804.08432","A new method based on nesting Monte Carlo is developed to solve highdimensional semi-linear PDEs. Convergence of the method is proved and its convergence rate studied. Results in high dimension for diﬀerent kind of non-linearities show its eﬃciency.","2018-05-14","2023-01-24 21:09:57","2023-03-18 20:34:47","2023-01-24 21:09:57","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1804.08432 [math]","","C:\Users\isido\Zotero\storage\LV4I2MV7\Warin - 2018 - Nesting Monte Carlo for high-dimensional Non Linea.pdf","","monte carlo; PDE","Mathematics - Probability; Primary 65C05, secondary 49L25","","","","","","","","","","","","","","","","","","","arXiv:1804.08432","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KE5VI8Y4","preprint","2018","Agarwal, Ankush; Claisse, Julien","Branching diffusion representation of semi-linear elliptic PDEs and estimation using Monte Carlo method","","","","","http://arxiv.org/abs/1704.00328","We study semi-linear elliptic PDEs with polynomial non-linearity and provide a probabilistic representation of their solution using branching diﬀusion processes. When the non-linearity involves the unknown function but not its derivatives, we extend previous results in the literature by showing that our probabilistic representation provides a solution to the PDE without assuming its existence. In the general case, we derive a new representation of the solution by using marked branching diﬀusion processes and automatic diﬀerentiation formulas to account for the non-linear gradient term. In both cases, we develop new theoretical tools to provide explicit suﬃcient conditions under which our probabilistic representations hold. As an application, we consider several examples including multi-dimensional semi-linear elliptic PDEs and estimate their solution by using the Monte Carlo method.","2018-02-14","2023-01-24 21:10:43","2023-03-18 20:34:35","2023-01-24 21:10:43","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1704.00328 [math]","","C:\Users\isido\Zotero\storage\A5D35SX4\Agarwal en Claisse - 2018 - Branching diffusion representation of semi-linear .pdf","","PDE","Mathematics - Probability; 35J61, 60H30, 60J85, 65C05","","","","","","","","","","","","","","","","","","","arXiv:1704.00328","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AAPRP6B9","encyclopediaArticle","2020","","Predictor–corrector method","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Predictor%E2%80%93corrector_method&oldid=955920527","In numerical analysis, predictor–corrector methods belong to a class of algorithms designed to integrate ordinary differential equations – to find an unknown function that satisfies a given differential equation.  All such algorithms proceed in two steps:  The initial, ""prediction"" step, starts from a function fitted to the function-values and derivative-values at a preceding set of points to extrapolate (""anticipate"") this function's value at a subsequent, new point. The next, ""corrector"" step refines the initial approximation by using the predicted value of the function and another method to interpolate that unknown function's value at the same subsequent point.","2020-05-10","2023-01-25 10:02:54","2023-03-18 20:34:19","2023-01-25 10:02:54","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 955920527","","C:\Users\isido\Zotero\storage\8KLI757A\Predictor–corrector_method.html","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLZHXC86","encyclopediaArticle","2023","","Spectral method","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Spectral_method&oldid=1134134983","Spectral methods are a class of techniques used in applied mathematics and scientific computing to numerically solve certain differential equations. The idea is to write the solution of the differential equation as a sum of certain ""basis functions"" (for example, as a Fourier series which is a sum of sinusoids) and then to choose the coefficients in the sum in order to satisfy the differential equation as well as possible. Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are generally nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains (compact support). Consequently, spectral methods connect variables globally while finite elements do so locally. Partially for this reason, spectral methods have excellent error properties, with the so-called ""exponential convergence"" being the fastest possible, when the solution is smooth. However, there are no known three-dimensional single domain spectral shock capturing results (shock waves are not smooth). In the finite element community, a method where the degree of the elements is very high or increases as the grid parameter h increases is sometimes called a spectral element method. Spectral methods can be used to solve differential equations (PDEs, ODEs, eigenvalue, etc) and optimization problems. When applying spectral methods to time-dependent PDEs, the solution is typically written as a sum of basis functions with time-dependent coefficients; substituting this in the PDE yields a system of ODEs in the coefficients which can be solved using any numerical method for ODEs. Eigenvalue problems for ODEs are similarly converted to matrix eigenvalue problems. Spectral methods were developed in a long series of papers by Steven Orszag starting in 1969 including, but not limited to, Fourier series methods for periodic geometry problems, polynomial spectral methods for finite and unbounded geometry problems, pseudospectral methods for highly nonlinear problems, and spectral iteration methods for fast solution of steady-state problems. The implementation of the spectral method is normally accomplished either with collocation or a Galerkin or a Tau approach . For very small problems, the spectral method is unique in that solutions may be written out symbolically, yielding a practical alternative to series solutions for differential equations. Spectral methods can be computationally less expensive and easier to implement than finite element methods; they shine best when high accuracy is sought in simple domains with smooth solutions. However, because of their global nature, the matrices associated with step computation are dense and computational efficiency will quickly suffer when there are many degrees of freedom (with some exceptions, for example if matrix applications can be written as Fourier transforms). For larger problems and nonsmooth solutions, finite elements will generally work better due to sparse matrices and better modelling of discontinuities and sharp bends.","2023-01-17","2023-01-25 10:23:12","2023-03-18 20:28:41","2023-01-25 10:23:12","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1134134983","","C:\Users\isido\Zotero\storage\ZM4CLCDZ\Spectral_method.html","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F3PJPR7K","encyclopediaArticle","2023","","Galerkin method","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Galerkin_method&oldid=1130900253","In mathematics, in the area of numerical analysis, Galerkin methods, named after the Russian mathematician Boris Galerkin, convert a continuous operator problem, such as a differential equation, commonly in a weak formulation, to a discrete problem by applying linear constraints determined by finite sets of basis functions. Often when referring to a Galerkin method, one also gives the name along with typical assumptions and approximation methods used:  Ritz–Galerkin method (after Walther Ritz) typically assumes symmetric and positive definite bilinear form in the weak formulation, where the differential equation for a physical system can be formulated via minimization of a quadratic function representing the system energy and the approximate solution is a linear combination of the given set of the basis functions. Bubnov–Galerkin method (after Ivan Bubnov) does not require the bilinear form to be symmetric and substitutes the energy minimization with orthogonality constraints determined by the same basis functions that are used to approximate the solution. In an operator formulation of the differential equation, Bubnov–Galerkin method can be viewed as applying an orthogonal projection to the operator. Petrov–Galerkin method (after Georgii I. Petrov) allows using basis functions for orthogonality constraints (called test basis functions) that are different from the basis functions used to approximate the solution. Petrov–Galerkin method can be viewed as an extension of Bubnov–Galerkin method, applying a projection that is not necessarily orthogonal in the operator formulation of the differential equation.Examples of Galerkin methods are: the Galerkin method of weighted residuals, the most common method of calculating the global stiffness matrix in the finite element method, the boundary element method for solving integral equations, Krylov subspace methods.","2023-01-01","2023-01-25 15:17:57","2023-03-18 20:28:38","2023-01-25 15:17:57","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1130900253","","","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZZJ97S8","encyclopediaArticle","2022","","Collocation method","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Collocation_method&oldid=1101629556","In mathematics, a collocation method is a method for the numerical solution of ordinary differential equations, partial differential equations and integral equations. The idea is to choose a finite-dimensional space of candidate solutions (usually polynomials up to a certain degree) and a number of points in the domain (called collocation points), and to select that solution which satisfies the given equation at the collocation points.","2022-08-01","2023-01-25 15:18:37","2023-03-18 20:28:34","2023-01-25 15:18:37","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1101629556","","C:\Users\isido\Zotero\storage\GENR5CET\Collocation_method.html","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BH37JDJ","journalArticle","2004","Gobet, Emmanuel; Maire, Sylvain","A spectral Monte Carlo method for the Poisson equation","Monte Carlo Methods and Applications","","1569-3961, 0929-9629","10.1515/mcma.2004.10.3-4.275","https://www.degruyter.com/document/doi/10.1515/mcma.2004.10.3-4.275/html","Using a sequential Monte Carlo algorithm, we compute a spectral approximation of the solution of the Poisson equation in dimension 1 and 2. The Feyman-Kac computation of the pointwise solution is achieved using either an integral representation or a modiﬁed walk on spheres method. The variances decrease geometrically with the number of steps. A global solution is obtained, accurate up to the interpolation error. Surprisingly, the accuracy depends very little on the absorption layer thickness of the walk on spheres.","2004-01","2023-01-25 16:00:41","2023-03-18 20:28:18","2023-01-25 16:00:41","","","3-4","10","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\I5NQN5MH\Gobet en Maire - 2004 - A spectral Monte Carlo method for the Poisson equa.pdf","","monte carlo; SALT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGQPJTAJ","preprint","2013","Maire, Sylvain; Tanré, Etienne","Monte Carlo approximations of the Neumann problem","","","","","http://arxiv.org/abs/1203.4910","We introduce Monte Carlo methods to compute the solution of elliptic equations with pure Neumann boundary conditions. We ﬁrst prove that the solution obtained by the stochastic representation has a zero mean value with respect to the invariant measure of the stochastic process associated to the equation. Pointwise approximations are computed by means of standard and new simulation schemes especially devised for local time approximation on the boundary of the domain. Global approximations are computed thanks to a stochastic spectral formulation taking into account the property of zero mean value of the solution. This stochastic formulation is asymptotically perfect in terms of conditioning. Numerical examples are given on the Laplace operator on a square domain with both pure Neumann and mixed Dirichlet-Neumann boundary conditions. A more general convection-diﬀusion equation is also numerically studied.","2013-08-27","2023-01-25 16:12:15","2023-01-25 16:12:15","2023-01-25 16:12:15","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1203.4910 [math]","","C:\Users\isido\Zotero\storage\IAB5W5EV\Maire en Tanré - 2013 - Monte Carlo approximations of the Neumann problem.pdf","","","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1203.4910","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLXV5UYY","bookSection","2009","Maire, Sylvain; Tanré, Etienne","Stochastic Spectral Formulations for Elliptic Problems","Monte Carlo and Quasi-Monte Carlo Methods 2008","978-3-642-04106-8 978-3-642-04107-5","","","http://link.springer.com/10.1007/978-3-642-04107-5_33","We describe new stochastic spectral formulations with very good properties in terms of conditioning. These formulations are built by combining Monte Carlo approximations of the Feynman-Kac formula and standard deterministic approximations on basis functions. We give error bounds on the solutions obtained using these formulations in the case of linear approximations. Some numerical tests are made on an anisotropic diﬀusion equation using a tensor product Tchebychef polynomial basis and one random point schemes quantiﬁed or not.","2009","2023-01-25 16:13:45","2023-01-25 16:13:45","2023-01-25 16:13:45","513-528","","","","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-3-642-04107-5_33","","C:\Users\isido\Zotero\storage\N6IB2UR9\Maire en Tanré - 2009 - Stochastic Spectral Formulations for Elliptic Prob.pdf","","","","L' Ecuyer, Pierre; Owen, Art B.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UTTETC2G","journalArticle","2008","Maire, Sylvain; Tanré, Etienne","Some new simulations schemes for the evaluation of Feynman–Kac representations","Monte Carlo Methods and Applications","","0929-9629, 1569-3961","10.1515/MCMA.2008.002","https://www.degruyter.com/document/doi/10.1515/MCMA.2008.002/html","We describe new variants of the Euler scheme and of the walk on spheres method for the Monte Carlo computation of Feynman-Kac representations. We optimize these variants using quantization for both source and boundary terms. Numerical tests are given on basic examples and on Monte Carlo versions of spectral methods for the Poisson equation. We especially introduce a new stochastic spectral formulation with very good properties in terms of conditioning.","2008-01","2023-01-25 16:14:04","2023-01-25 16:14:04","2023-01-25 16:14:04","","","1","14","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\P47ARGF3\Maire en Tanré - 2008 - Some new simulations schemes for the evaluation of.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WGJAN8KL","preprint","2018","Meester, Ludolf E.","Exponential convergence of adaptive importance sampling estimators for Markov chain expectations","","","","","http://arxiv.org/abs/1806.03029","In this paper it is shown that adaptive importance sampling algorithms converge at exponential rate for Markov chain expectation problems that admit a combination of a ﬁltered estimator and a Markov zero-variance measure. It extends a chain of results—special purpose proofs were already known for several cases [8, 2, 6]. A recent paper [1] provides a complete description of the class of combinations of Markov process expectations of path functionals and ﬁltered estimators that admit zero-variance importance measures that retain the Markov property. In a way, this is the maximal class for which adaptive importance sampling algorithms might exhibit exponential convergence. The main purpose of this paper is to prove that this is the case: for (most of) those combinations the natural adaptive importance sampling algorithm converges at exponential rate. In addition, the applicability of general Markov chain theory for this purpose is discussed through the analysis of a counterexample presented in [7].","2018-07-10","2023-01-25 16:16:55","2023-01-25 16:16:55","2023-01-25 16:16:55","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1806.03029 [math]","","C:\Users\isido\Zotero\storage\8BJ5II9Q\Meester - 2018 - Exponential convergence of adaptive importance sam.pdf","","","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1806.03029","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BYX88DA3","journalArticle","2014","Gobet, Emmanuel; Surana, Khushboo","A new sequential algorithm for L2-approximation and application to Monte-Carlo integration","","","","","","We design a new stochastic algorithm (called SALT) that sequentially approximates a given function in L2 w.r.t. a probability measure, using a ﬁnite sample of the distribution. By increasing the sets of approximating functions and the simulation eﬀort, we compute a L2-approximation with higher and higher accuracy. The simulation eﬀort is tuned in a robust way that ensures the convergence under rather general conditions. Then, we apply SALT to build eﬃcient control variates for accurate numerical integration. Examples and numerical experiments support the mathematical analysis.","2014","2023-01-25 16:19:32","2023-05-16 19:40:44","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\MFJ99N7L\Gobet en Surana - A new sequential algorithm for L2-approximation an.pdf","","monte carlo; SALT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XEKP5XNX","encyclopediaArticle","2022","","Eigenfunction","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Eigenfunction&oldid=1115272845","In mathematics, an eigenfunction of a linear operator D defined on some function space is any non-zero function                         f                 {\displaystyle f}    in that space that, when acted upon by D, is only multiplied by some scaling factor called an eigenvalue. As an equation, this condition can be written as for some scalar eigenvalue                         λ         .                 {\displaystyle \lambda .}    The solutions to this equation may also be subject to boundary conditions that limit the allowable eigenvalues and eigenfunctions. An eigenfunction is a type of eigenvector.","2022-10-10","2023-01-30 13:55:22","2023-01-30 13:55:22","2023-01-30 13:55:22","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1115272845","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R425XTU2","preprint","2015","Hout, Karel in 't; Toivanen, Jari","Application of Operator Splitting Methods in Finance","","","","","http://arxiv.org/abs/1504.01022","Financial derivatives pricing aims to ﬁnd the fair value of a ﬁnancial contract on an underlying asset. Here we consider option pricing in the partial differential equations framework. The contemporary models lead to one-dimensional or multidimensional parabolic problems of the convection-diffusion type and generalizations thereof. An overview of various operator splitting methods is presented for the efﬁcient numerical solution of these problems.","2015-04-04","2023-01-30 16:11:12","2023-03-18 20:27:04","2023-01-30 16:11:12","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1504.01022 [q-fin]","","C:\Users\isido\Zotero\storage\P4MV65GF\Hout en Toivanen - 2015 - Application of Operator Splitting Methods in Finan.pdf","","ODE","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:1504.01022","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NEHW9EQA","journalArticle","","Giles, Mike","Smoking adjoints, part II: fast Monte Carlo Greeks","","","","","","The efficient calculation of price sensitivities continues to be among the greatest practical challenges facing users of Monte Carlo methods in the derivatives industry. Computing Greeks is essential to hedging and risk management, but typically requires substantially more computing time than pricing a derivative. This article shows how an adjoint formula- tion can be used to accelerate the calculation of the Greeks. This method is particularly well suited to applications requiring sensitivities to a large number of parameters. Examples include interest rate derivatives requir- ing sensitivities to all initial forward rates and equity derivatives requiring sensitivities to all points on a volatility surface. The simplest methods for estimating Greeks are based on finite differ- ence approximations, in which a Monte Carlo pricing routine is rerun mul- tiple times at different settings of the input parameters in order to estimate sensitivities to the parameters. In the fixed-income setting, for example, this would mean perturbing each initial forward rate and then rerunning the Monte Carlo simulation to re-price a security or a whole book. The main virtues of this method are that it is straightforward to understand and requires no additional programming. But the bias and variance properties of finite difference estimates can be rather poor, and their computing time requirements grow with the number of input parameters. Better estimates of price sensitivities can often be derived by using in- formation about model dynamics in a Monte Carlo simulation. Techniques for doing this include the pathwise method and likelihood ratio method, both of which are reviewed in chapter 7 of Glasserman (2004). When ap- plicable, these methods produce unbiased estimates of price sensitivities from a single set of simulated paths, that is, without perturbing any para- meters. The pathwise method accomplishes this by differentiating the evo- lution of the underlying assets or state variables along each path; the likelihood ratio method instead differentiates the transition density of the underlying assets or state variables. In comparison with finite difference estimates, these methods require additional model analysis and program- ming, but the additional effort is often justified by the improvement in the quality of calculated Greeks. The adjoint method we develop here applies ideas used in computa- tional fluid dynamics (Giles & Pierce, 2000) to the calculation of pathwise estimates of Greeks. The estimate calculated using the adjoint method is identical to the ordinary pathwise estimate; its potential advantage is there- fore computational, rather than statistical. The relative merits of the ordi- nary (forward) calculation of pathwise Greeks and the adjoint calculation can be summarised as follows: a) the adjoint method is advantageous for calculating the sensitivities of a small number of securities with respect to a large number of parameters; and b) the forward method is advantageous for calculating the sensitivities of many securities with respect to a small number of parameters. The ‘small number of securities’ in this dichotomy could be an entire book, consisting of many individual securities, so long as the sensitivities to be calculated are for the book as a whole and not for the constituent securities. The rest of this article is organised as follows. The next section reviews the usual forward calculation of pathwise Greeks and the subsequent sec- tion illustrates its application in the Libor market model. We then develop the adjoint method for delta estimates, and extend it to applications such as vega estimation requiring sensitivities to parameters of model dynam- ics, rather than just sensitivities to initial conditions. We then extend it to gamma estimation. We use the Libor market model as an illustrative ex- ample in both settings. Lastly, we present numerical results that illustrate the computational savings offered by the adjoint method.","","2023-01-30 16:57:01","2023-08-03 17:46:28","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\D4MR342G\Giles - Smoking adjoints, part II fast Monte Carlo Greeks.pdf","","greeks; monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9DGX66I","preprint","2021","Maran, Andrea; Pallavicini, Andrea; Scoleri, Stefano","Chebyshev Greeks: Smoothing Gamma without Bias","","","","","http://arxiv.org/abs/2106.12431","The computation of Greeks is a fundamental task for risk managing of ﬁnancial instruments. The standard approach to their numerical evaluation is via ﬁnite diﬀerences. Most exotic derivatives are priced via Monte Carlo simulation: in these cases, it is hard to ﬁnd a fast and accurate approximation of Greeks, mainly because of the need of a tradeoﬀ between bias and variance. Recent improvements in Greeks computation, such as Adjoint Algorithmic Diﬀerentiation, are unfortunately uneﬀective on second order Greeks (such as Gamma), which are plagued by the most signiﬁcant instabilities, so that a viable alternative to standard ﬁnite diﬀerences is still lacking. We apply Chebyshev interpolation techniques to the computation of spot Greeks, showing how to improve the stability of ﬁnite diﬀerence Greeks of arbitrary order, in a simple and general way. The increased performance of the proposed technique is analyzed for a number of real payoﬀs commonly traded by ﬁnancial institutions.","2021-06-23","2023-01-30 17:59:14","2023-03-19 15:58:34","2023-01-30 17:59:14","","","","","","","Chebyshev Greeks","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2106.12431 [q-fin]","","C:\Users\isido\Zotero\storage\NAD6EA6C\Maran e.a. - 2021 - Chebyshev Greeks Smoothing Gamma without Bias.pdf","","chebychev; greeks","Quantitative Finance - Computational Finance; Quantitative Finance - Mathematical Finance; Quantitative Finance - Pricing of Securities; Quantitative Finance - Risk Management","","","","","","","","","","","","","","","","","","","arXiv:2106.12431","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GQMNHDI6","journalArticle","","Trefethen, Lloyd N","Approximation Theory and Approximation Practice","","","","","","There are quite a number of excellent books on approximation theory. Three classics are [Cheney 1966], [Davis 1975], and [Meinardus 1967], and a slightly more recent computationally oriented classic is [Powell 1981]. Perhaps the first approximation theory text was [Borel 1905]. A good deal of my emphasis will be on ideas related to Chebyshev points and polynomials, whose origins go back more than a century to mathematicians including Chebyshev (1821–1894), de la Valle  ́e Poussin (1866–1962), Bernstein (1880–1968), and Jackson (1888–1946). In the computer era, some of the early figures who developed “Chebyshev technology,” in approximately chronological order, were Lanczos, Clenshaw, Good, Fox, Elliott, Mason, Orszag, Paszkowski, and V. I. Lebedev. Five books on Chebyshev polynomials are by Snyder [1966], Paszkowski [1975], Fox and Parker [1968], Rivlin [1990], and Mason and Handscomb [2003]. One reason we emphasize Chebyshev technology so much is that in practice, for working with functions on intervals, these methods are unbeatable. For example, we shall see in Chapter 16 that the difference in approximation power between Chebyshev and “optimal” interpolation points is utterly negligible. Another reason is that if you know the Chebyshev material well, this is the best possible foundation for work on other approximation topics, and for understanding the links with Fourier analysis.","","2023-01-30 18:24:38","2023-08-03 17:43:04","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\MREQLLLP\Trefethen - Approximation Theory and Approximation Practice.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4J8EAQ4C","webpage","","","A continuous analogue of Krylov subspace methods for ODEs » Chebfun","","","","","https://www.chebfun.org/examples/ode-linear/Krylov.html","","","2023-01-30 21:10:22","2023-01-30 21:10:22","2023-01-30 21:10:22","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\DRV7T8ZF\Krylov.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DEBDAGGJ","preprint","2018","Gilles, Marc Aurèle; Townsend, Alex","Continuous analogues of Krylov methods for differential operators","","","","","http://arxiv.org/abs/1803.11049","Analogues of the conjugate gradient method, MINRES, and GMRES are derived for solving boundary value problems (BVPs) involving second-order diﬀerential operators. Two challenges arise: imposing the boundary conditions on the solution while building up a Krylov subspace, and guaranteeing convergence of the Krylov-based method on unbounded operators. Our approach employs projection operators to guarantee that the boundary conditions are satisﬁed, and we develop an operator preconditioner that ensures that an approximate solution is computed after a ﬁnite number of iterations. The developed Krylov methods are practical iterative BVP solvers that are particularly eﬃcient when a fast operator-function product is available.","2018-04-19","2023-01-30 21:16:43","2023-01-30 21:16:44","2023-01-30 21:16:43","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1803.11049 [math]","","C:\Users\isido\Zotero\storage\K2ZL49ZL\Gilles en Townsend - 2018 - Continuous analogues of Krylov methods for differe.pdf","","","Mathematics - Numerical Analysis; 65F10, 65N35, 47E05","","","","","","","","","","","","","","","","","","","arXiv:1803.11049","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HV9277SW","webpage","","","Constrained optimization in Chebfun » Chebfun","","","","","https://www.chebfun.org/examples/opt/ConstrainedOptimization.html","","","2023-01-30 21:20:03","2023-01-30 21:20:03","2023-01-30 21:20:03","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\QIPJE4L9\ConstrainedOptimization.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5UWJRU6","webpage","","","Black-Scholes PDE using operator exponential » Chebfun","","","","","https://www.chebfun.org/examples/pde/BSExponential.html","","","2023-01-30 21:31:31","2023-01-30 21:31:31","2023-01-30 21:31:31","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\F23C3NDI\BSExponential.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2D62LBUF","webpage","","","Some tricky integrals » Chebfun","","","","","https://www.chebfun.org/examples/quad/Tricky.html","","","2023-01-30 21:36:40","2023-01-30 21:36:40","2023-01-30 21:36:40","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\WBGFR5FD\Tricky.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGVIWNMZ","webpage","","","Integrating Tj(x)*Tk(y) over the unit disk » Chebfun","","","","","https://www.chebfun.org/examples/quad/TjTkDisk.html","","","2023-01-30 21:38:04","2023-01-30 21:38:04","2023-01-30 21:38:04","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\L63WYHKI\TjTkDisk.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKP6ECAQ","webpage","","","The white noise paradox » Chebfun","","","","","https://www.chebfun.org/examples/ode-random/WhiteNoiseParadox.html","","","2023-01-30 21:41:44","2023-01-30 21:41:44","2023-01-30 21:41:44","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\JEPR2VXQ\WhiteNoiseParadox.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYK39P9V","webpage","","","Geometric Brownian motion » Chebfun","","","","","https://www.chebfun.org/examples/ode-random/GBM.html","","","2023-01-30 21:43:03","2023-01-30 21:43:03","2023-01-30 21:43:03","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"974SRTC8","webpage","","","Brownian paths and random polynomials » Chebfun","","","","","https://www.chebfun.org/examples/stats/RandomPolynomials.html","","","2023-01-30 21:44:02","2023-03-18 20:26:23","2023-01-30 21:44:02","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\SPBD8LDT\RandomPolynomials.html","","finance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3GQI67YA","preprint","2021","Lavagnini, Silvia","Pricing Asian Options with Correlators","","","","","http://arxiv.org/abs/2104.11684","We derive a series expansion by Hermite polynomials for the price of an arithmetic Asian option. This series requires the computation of moments and correlators of the underlying price process, but for a polynomial jump-diﬀusion, these are given in closed form, hence no numerical simulation is required to evaluate the series. This allows, for example, for the explicit computation of Greeks. The weight function deﬁning the Hermite polynomials is a Gaussian density with scale b. We ﬁnd that the rate of convergence for the series depends on b, for which we prove a lower bound to guarantee convergence. Numerical examples show that the series expansion is accurate but unstable for initial values of the underlying process far from zero, mainly due to rounding errors.","2021-04-23","2023-01-30 22:44:59","2023-03-18 20:26:15","2023-01-30 22:44:59","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2104.11684 [q-fin]","","C:\Users\isido\Zotero\storage\AJNEHDQB\Lavagnini - 2021 - Pricing Asian Options with Correlators.pdf","","finance","Quantitative Finance - Computational Finance; Quantitative Finance - Pricing of Securities","","","","","","","","","","","","","","","","","","","arXiv:2104.11684","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZ7KHXT4","preprint","2022","Bilokon, Paul; Kucherenko, Sergei; Williams, Casey","Quasi-Monte Carlo methods for calculating derivatives sensitivities on the GPU","","","","","http://arxiv.org/abs/2209.11337","The calculation of option Greeks is vital for risk management. Traditional pathwise and ﬁnitedifference methods work poorly for higher-order Greeks and options with discontinuous payoff functions. The Quasi-Monte Carlo-based conditional pathwise method (QMC-CPW) for options Greeks allows the payoff function of options to be effectively smoothed, allowing for increased efﬁciency when calculating sensitivities. Also demonstrated in literature is the increased computational speed gained by applying GPUs to highly parallelisable ﬁnance problems such as calculating Greeks. We pair QMC-CPW with simulation on the GPU using the CUDA platform. We estimate the delta, vega and gamma Greeks of three exotic options: arithmetic Asian, binary Asian, and lookback. Not only are the beneﬁts of QMC-CPW shown through variance reduction factors of up to 1.0 × 1018, but the increased computational speed through usage of the GPU is shown as we achieve speedups over sequential CPU implementations of more than 200x for our most accurate method.","2022-09-22","2023-01-30 22:45:17","2023-03-18 20:25:59","2023-01-30 22:45:17","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2209.11337 [q-fin]","","C:\Users\isido\Zotero\storage\6BCIKW77\Bilokon e.a. - 2022 - Quasi-Monte Carlo methods for calculating derivati.pdf","","monte carlo","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:2209.11337","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5HS7XJKW","journalArticle","","Christara, Christina C; Leung, Nat Chun-Ho","Option pricing in jump diffusion models with quadratic spline collocation","","","","","","In this paper, we develop a robust numerical method in pricing options, when the underlying asset follows a jump diffusion model. We demonstrate that, with the quadratic spline collocation method, the integral approximation in the pricing PIDE is intuitively simple, and comes down to the evaluation of the probabilistic moments of the jump density. When combined with a Picard iteration scheme, the pricing problem can be solved efﬁciently. We present the method and the numerical results from pricing European and American options with Merton’s and Kou’s models.","","2023-01-30 22:45:35","2023-03-18 20:25:53","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\Z8AA6EGL\Christara en Leung - Option pricing in jump diffusion models with quadr.pdf","","finance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FWVFBI9C","preprint","2021","Hashemi, Behnam; Nakatsukasa, Yuji; Trefethen, Lloyd N.","Rectangular eigenvalue problems","","","","","http://arxiv.org/abs/2112.13698","Often the easiest way to discretize an ordinary or partial diﬀerential equation is by a rectangular numerical method, in which n basis functions are sampled at m ≫ n collocation points. We show how eigenvalue problems can be solved in this setting by QR reduction to square matrix generalized eigenvalue problems. The method applies equally in the limit “m = ∞” of eigenvalue problems for quasimatrices. Numerical examples are presented as well as pointers to some related literature.","2021-12-27","2023-01-31 09:40:37","2023-01-31 09:40:38","2023-01-31 09:40:37","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2112.13698 [cs, math]","","C:\Users\isido\Zotero\storage\MWM8W82T\Hashemi e.a. - 2021 - Rectangular eigenvalue problems.pdf","","","Mathematics - Numerical Analysis; 47A75, 65F15, 65N35","","","","","","","","","","","","","","","","","","","arXiv:2112.13698","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QS5IWQFR","preprint","2021","Trefethen, Lloyd N.","Exactness of quadrature formulas","","","","","http://arxiv.org/abs/2101.09501","The standard design principle for quadrature formulas is that they should be exact for integrands of a given class, such as polynomials of a ﬁxed degree. We show how this principle fails to predict the actual behavior in four cases: Newton–Cotes, Clenshaw–Curtis, Gauss–Legendre, and Gauss–Hermite quadrature. Three further examples are mentioned more brieﬂy.","2021-01-23","2023-01-31 09:48:54","2023-03-18 20:25:45","2023-01-31 09:48:54","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2101.09501 [cs, math]","","C:\Users\isido\Zotero\storage\UVIPUHJ5\Trefethen - 2021 - Exactness of quadrature formulas.pdf","","integration","Mathematics - Numerical Analysis; 41A55, 65D32","","","","","","","","","","","","","","","","","","","arXiv:2101.09501","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5L4YEJF4","preprint","2019","Nakatsukasa, Yuji; Trefethen, Lloyd N.","An algorithm for real and complex rational minimax approximation","","","","","http://arxiv.org/abs/1908.06001","Rational minimax approximation of real functions on real intervals is an established topic, but when it comes to complex functions or domains, there appear to be no algorithms currently in use. Such a method is introduced here, the AAA-Lawson algorithm, available in Chebfun. The new algorithm solves a wide range of problems on arbitrary domains in a fraction of a second of laptop time by a procedure consisting of two steps. First, the standard AAA algorithm is run to obtain a near-best approximation and a set of support points for a barycentric representation of the rational approximant. Then a “Lawson phase” of iteratively reweighted least-squares adjustment of the barycentric coeﬃcients is carried out to improve the approximation to minimax.","2019-08-16","2023-01-31 10:07:56","2023-01-31 10:07:56","2023-01-31 10:07:56","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1908.06001 [cs, math]","","C:\Users\isido\Zotero\storage\M6YJ3J87\Nakatsukasa en Trefethen - 2019 - An algorithm for real and complex rational minimax.pdf","","","Mathematics - Numerical Analysis; 41A20, 65D15","","","","","","","","","","","","","","","","","","","arXiv:1908.06001","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZZIL8X4","preprint","2016","Trefethen, Lloyd N.","Multivariate polynomial approximation in the hypercube","","","","","http://arxiv.org/abs/1608.02216","A theorem is proved concerning approximation of analytic functions by multivariate polynomials in the s-dimensional hypercube. The geometric convergence rate is determined not by the usual notion of degree of a multivariate polynomial, but by the Euclidean degree, deﬁned in terms of the 2-norm rather than the 1-norm of the exponent vector k of a monomial xk11 · · · xkss .","2016-08-07","2023-01-31 10:13:22","2023-01-31 10:13:22","2023-01-31 10:13:22","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1608.02216 [math]","","C:\Users\isido\Zotero\storage\HSBRRHS8\Trefethen - 2016 - Multivariate polynomial approximation in the hyper.pdf","","","Mathematics - Numerical Analysis; 41A63","","","","","","","","","","","","","","","","","","","arXiv:1608.02216","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VC8H5PMH","preprint","2015","Aurentz, Jared L.; Trefethen, Lloyd N.","Chopping a Chebyshev Series","","","","","http://arxiv.org/abs/1512.01803","Chebfun and related software projects for numerical computing with functions are based on the idea that at each step of a computation, a function f (x) deﬁned on an interval [a, b] is “rounded” to a prescribed precision by constructing a Chebyshev series and chopping it at an appropriate point. Designing a chopping algorithm with the right properties proves to be a surprisingly complex and interesting problem. We describe the chopping algorithm introduced in Chebfun Version 5.3 in 2015 after many years of discussion and the considerations that led to this design.","2015-12-06","2023-01-31 10:24:31","2023-03-18 20:25:19","2023-01-31 10:24:31","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1512.01803 [math]","","C:\Users\isido\Zotero\storage\Q3HLDCCX\Aurentz en Trefethen - 2015 - Chopping a Chebyshev Series.pdf","","chebychev","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1512.01803","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W2INF43H","journalArticle","2015","Wright, Grady B.; Javed, Mohsin; Montanelli, Hadrien; Trefethen, Lloyd N.","Extension of Chebfun to periodic functions","SIAM Journal on Scientific Computing","","1064-8275, 1095-7197","10.1137/141001007","http://arxiv.org/abs/1511.00166","Algorithms and underlying mathematics are presented for numerical computation with periodic functions via approximations to machine precision by trigonometric polynomials, including the solution of linear and nonlinear periodic ordinary diﬀerential equations. Diﬀerences from the nonperiodic Chebyshev case are highlighted.","2015-01","2023-01-31 10:25:47","2023-03-18 20:25:12","2023-01-31 10:25:47","C554-C573","","5","37","","SIAM J. Sci. Comput.","","","","","","","","en","","","","","arXiv.org","","arXiv:1511.00166 [math]","","C:\Users\isido\Zotero\storage\UEQFA5S5\Wright e.a. - 2015 - Extension of Chebfun to periodic functions.pdf","","chebychev","Mathematics - Numerical Analysis; 42A10, 42A15, 65T40","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CGAZGF6","webpage","","","Continuous analogues of matrix factorizations","","","","","https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2014.0585","","","2023-01-31 10:26:43","2023-01-31 10:26:43","2023-01-31 10:26:43","","","","","","","","","","","","","","en","","","","","","","DOI: 10.1098/rspa.2014.0585","","C:\Users\isido\Zotero\storage\24VM589B\Continuous analogues of matrix factorizations.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWVWCBNZ","journalArticle","2013","Townsend, Alex; Trefethen, Lloyd N.","An Extension of Chebfun to Two Dimensions","SIAM Journal on Scientific Computing","","1064-8275, 1095-7197","10.1137/130908002","http://epubs.siam.org/doi/10.1137/130908002","An object-oriented Matlab system is described that extends the capabilities of Chebfun to smooth functions of two variables deﬁned on rectangles. Functions are approximated to essentially machine precision by using iterative Gaussian elimination with complete pivoting to form “chebfun2” objects representing low rank approximations. Operations such as integration, diﬀerentiation, function evaluation, and transforms are particularly eﬃcient. Global optimization, the singular value decomposition, and rootﬁnding are also extended to chebfun2 objects. Numerical applications are presented.","2013-01","2023-01-31 10:46:53","2023-03-18 20:25:06","2023-01-31 10:46:53","C495-C518","","6","35","","SIAM J. Sci. Comput.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\X7345UNU\Townsend en Trefethen - 2013 - An Extension of Chebfun to Two Dimensions.pdf","","chebychev","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPP4UJM9","journalArticle","2015","Rivaz, Azim","Two-dimensional Chebyshev Polynomials for Solving Two-dimensional Integro-Differential Equations","","","","","","In this paper, we present a new approach to obtain the numerical solution of the linear twodimensional Fredholm and Volterra integro-differential equations (2D-FIDE and 2D-VIDE). First, we introduce the two-dimensional Chebyshev polynomials and construct their operational matrices of integration. Then, both of them, two-dimensional Chebyshev polynomials and their operational matrix of integration, are used to represent the matrix form of 2D-FIDE and 2D-VIDE. The main characteristic of this approach is that it reduces 2D-FIDE and 2D-VIDE to a system of linear algebraic equations. Illustrative examples are included to demonstrate the validity and applicability of the presented technique.","2015","2023-01-31 15:43:47","2023-03-18 20:24:57","","","","2","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\SPZJSJ2L\Rivaz - 2015 - Two-dimensional Chebyshev Polynomials for Solving .pdf","","chebychev","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFHJWFII","journalArticle","","Sajikumar, S","IMAGE COMPRESSION USING CHEBYSHEV POLYNOMIAL SURFACE FIT","","","","","","A lossy image compression method based on block-by-block surface fit using bivariate polynomial is proposed. Chebyshev polynomials of first kind are used to generate the surface for each block. Data compression is achieved by representing the gray level variations across any block by the parameters of the fitted surface and these parameters are stored instead of the pixel values. Compression with three coefficients and four coefficients in the fit model is proposed. In standard lossy compression techniques compression is achieved by exploiting spatial redundancies of the input data. In this proposed method compression does not depends on redundant information but depends on the block size that can be predefined. The method is best suited for high compression with reasonable reconstructed image quality. Performance was tested on number of test images using Chebyshev polynomials of different orders.","","2023-01-31 16:19:38","2023-03-18 20:24:48","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\Z7XR22R5\Sajikumar - IMAGE COMPRESSION USING CHEBYSHEV POLYNOMIAL SURFA.pdf","","chebychev","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D36A8RLK","encyclopediaArticle","2022","","Clenshaw algorithm","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Clenshaw_algorithm&oldid=1089015914","In numerical analysis, the Clenshaw algorithm, also called Clenshaw summation, is a recursive method to evaluate a linear combination of Chebyshev polynomials.  The method was published by Charles William Clenshaw in 1955. It is a generalization of Horner's method for evaluating a linear combination of monomials. It generalizes to more than just Chebyshev polynomials; it applies to any class of functions that can be defined by a three-term recurrence relation.","2022-05-21","2023-01-31 21:22:51","2023-01-31 21:22:51","2023-01-31 21:22:51","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1089015914","","C:\Users\isido\Zotero\storage\HTUIQKE9\Clenshaw_algorithm.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PV2HLZTH","forumPost","2017","Kirill","Answer to ""Clenshaw-type recurrence for derivative of Chebyshev series""","Computational Science Stack Exchange","","","","https://scicomp.stackexchange.com/a/27866","","2017-09-17","2023-01-31 21:25:09","2023-01-31 21:25:09","2023-01-31 21:25:09","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\PMJIJDW5\clenshaw-type-recurrence-for-derivative-of-chebyshev-series.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMTIPEUX","forumPost","2012","Pedro","Answer to ""Fast (approximate) evaluation of Chebyshev polynomial""","Computational Science Stack Exchange","","","","https://scicomp.stackexchange.com/a/3416","","2012-10-03","2023-01-31 21:29:55","2023-01-31 21:29:55","2023-01-31 21:29:54","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\FX7IQLE7\fast-approximate-evaluation-of-chebyshev-polynomial.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4V8UR4J","preprint","2022","Pan, Victor Y.; Go, Soo; Luan, Qi; Zhao, Liang","Fast Approximation of Polynomial Zeros and Matrix Eigenvalues","","","","","http://arxiv.org/abs/2301.11268","Given a black box (oracle) for the evaluation of a univariate polynomial p(x) of a degree d, we seek its zeros, that is, the roots of the equation p(x)=0. At FOCS 2016 Louis and Vempala approximated a largest zero of such a real-rooted polynomial within $1/2^b$, by performing at NR cost of the evaluation of Newton's ratio p(x)/p'(x) at O(b\log(d)) points x. They readily extended this root-finder to record fast approximation of a largest eigenvalue of a symmetric matrix under the Boolean complexity model. We apply distinct approach and techniques to obtain more general results at the same computational cost.","2022-12-31","2023-02-01 08:15:35","2023-02-01 08:15:36","2023-02-01 08:15:35","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2301.11268 [cs, math]","","C:\Users\isido\Zotero\storage\WNNTR8QA\Pan e.a. - 2022 - Fast Approximation of Polynomial Zeros and Matrix .pdf","","","Mathematics - Numerical Analysis; Computer Science - Symbolic Computation","","","","","","","","","","","","","","","","","","","arXiv:2301.11268","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJ6QF2CQ","preprint","2016","Dumas, Jean-Guillaume; Pan, Victor","Fast Matrix Multiplication and Symbolic Computation","","","","","http://arxiv.org/abs/1612.05766","The complexity of matrix multiplication (hereafter MM) has been intensively studied since 1969, when Strassen surprisingly decreased the exponent 3 in the cubic cost of the straightforward classical MM to log2(7) ≈ 2.8074. Applications to some fundamental problems of Linear Algebra and Computer Science have been immediately recognized, but the researchers in Computer Algebra keep discovering more and more applications even today, with no sign of slowdown. We survey the unﬁnished history of decreasing the exponent towards its information lower bound 2, recall some important techniques discovered in this process and linked to other ﬁelds of computing, reveal sample surprising applications to fast computation of the inner products of two vectors and summation of integers, and discuss the curse of recursion, which separates the progress in fast MM into its most acclaimed and purely theoretical part and into valuable acceleration of MM of feasible sizes. Then, in the second part of our paper, we cover fast MM in realistic symbolic computations and discuss applications and implementation of fast exact matrix multiplication. We ﬁrst review how most of exact linear algebra can be reduced to matrix multiplication over small ﬁnite ﬁelds. Then we highlight the diﬀerences in the design of approximate and exact implementations of fast MM, taking into account nowadays processor and memory hierarchies. In the concluding section we comment on current perspectives of the study of fast MM.","2016-12-17","2023-02-01 08:23:53","2023-02-01 08:23:53","2023-02-01 08:23:53","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1612.05766 [cs]","","C:\Users\isido\Zotero\storage\SJLTRMVL\Dumas en Pan - 2016 - Fast Matrix Multiplication and Symbolic Computatio.pdf","","","Computer Science - Symbolic Computation","","","","","","","","","","","","","","","","","","","arXiv:1612.05766","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77YIF8YL","encyclopediaArticle","2023","","Stochastic gradient descent","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&oldid=1136419553","Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in exchange for a lower convergence rate.While the basic idea behind stochastic approximation can be traced back to the Robbins–Monro algorithm of the 1950s, stochastic gradient descent has become an important optimization method in machine learning.","2023-01-30","2023-02-01 10:06:17","2023-02-01 10:06:17","2023-02-01 10:06:17","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1136419553","","C:\Users\isido\Zotero\storage\C8B3CMLS\Stochastic_gradient_descent.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EBPJ52BH","encyclopediaArticle","2022","","Augmented Lagrangian method","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Augmented_Lagrangian_method&oldid=1130093461#Alternating_direction_method_of_multipliers","Augmented Lagrangian methods are a certain class of algorithms for solving constrained optimization problems.  They have similarities to penalty methods in that they replace a constrained optimization problem by a series of unconstrained problems and add a penalty term to the objective; the difference is that the augmented Lagrangian method adds yet another term, designed to mimic a Lagrange multiplier.  The augmented Lagrangian is related to, but not identical with the method of Lagrange multipliers. Viewed differently, the unconstrained objective is the Lagrangian of the constrained problem, with an additional penalty term (the augmentation). The method was originally known as the method of multipliers, and was studied much in the 1970 and 1980s as a good alternative to penalty methods. It was first discussed by Magnus Hestenes, and by Michael Powell in 1969. The method was studied by R. Tyrrell Rockafellar in relation to Fenchel duality, particularly in relation to proximal-point methods, Moreau–Yosida regularization, and maximal monotone operators: These methods were used in structural optimization.  The method was also studied by Dimitri Bertsekas, notably in his 1982 book, together with extensions involving nonquadratic regularization functions, such as entropic regularization, which gives rise to the ""exponential method of multipliers,"" a method that handles inequality constraints with a twice differentiable augmented Lagrangian function. Since the 1970s, sequential quadratic programming (SQP) and interior point methods (IPM) have had increasing attention, in part because they more easily use sparse matrix subroutines from numerical software libraries, and in part because IPMs have proven complexity results via the theory of self-concordant functions. The augmented Lagrangian method was rejuvenated by the optimization systems LANCELOT, ALGENCAN and AMPL, which allowed sparse matrix techniques to be used on seemingly dense but ""partially separable"" problems. The method is still useful for some problems. Around 2007, there was a resurgence of augmented Lagrangian methods in fields such as total-variation denoising and compressed sensing. In particular, a variant of the standard augmented Lagrangian method that uses partial updates (similar to the Gauss–Seidel method for solving linear equations) known as the alternating direction method of multipliers or ADMM gained some attention.","2022-12-28","2023-02-01 11:34:05","2023-02-01 11:34:05","2023-02-01 11:34:05","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1130093461","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVCP6M5T","journalArticle","2019","Yuan, Di; Zhang, Xinming","An overview of numerical methods for the first kind Fredholm integral equation","SN Applied Sciences","","2523-3963, 2523-3971","10.1007/s42452-019-1228-3","http://link.springer.com/10.1007/s42452-019-1228-3","In the field of engineering technology, many problems can be transformed into the first kind Fredholm integral equation, which has a prominent feature called “ill-posedness”. This property makes it difficult to find the analytical solution of first kind Fredholm integral equation. Therefore, how to find the numerical solution of first kind Fredholm integral equation has been a common concern of domestic and overseas scholars in recent years. In this article, various numerical solution methods of first kind Fredholm integral equation are introduced in detail. First, the existence and convergence of the solution of the integral equation are given. Second, the current mainstream numerical methods, such as regularization method, wavelet analysis method and multilevel iteration method are introduced in detail. Finally, we presented a concise overview of the numerical method of first kind Fredholm integral equation.","2019-10","2023-02-01 16:47:20","2023-03-18 20:22:15","2023-02-01 16:47:20","1178","","10","1","","SN Appl. Sci.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\FTSQCFRP\Yuan en Zhang - 2019 - An overview of numerical methods for the first kin.pdf","","integral equations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCQPFSAY","journalArticle","2022","Almousa, Salah Al-Deen; Horv´ath, G´abor; Horv´ath, Ill ´es; M´esz´aros, Andr´as; Telek, Mikl ´os","The CME method: Efficient numerical inverse Laplace transformation with Concentrated Matrix Exponential distribution","ACM SIGMETRICS Performance Evaluation Review","","0163-5999","10.1145/3543146.3543155","https://dl.acm.org/doi/10.1145/3543146.3543155","Numerical inverse Laplace transformation (NILT) is an important tool in the ﬁeld of system modelling and performance analysis. The recently introduced CME method has many important advantages over the alternative numerical inverse Laplace transformation (NILT) methods. It avoids Gibbs oscillation (i.e., does not generate overshoot and undershoot), preserves the monotonicity of functions, its accuracy is gradually improving with the order, and it is numerically more stable than the alternative methods. In this paper we demonstrate these advantages and introduce our tool which implements the CME method and other popular NILT methods.","2022-06-02","2023-02-02 10:54:13","2023-02-02 10:54:14","2023-02-02 10:54:13","29-34","","4","49","","SIGMETRICS Perform. Eval. Rev.","The CME method","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\BXPJ7LAI\Almousa e.a. - 2022 - The CME method Efficient numerical inverse Laplac.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YASGE2DV","document","","","fredholm theory of elliptic problems","","","","","","","","2023-02-02 10:55:04","2023-02-02 10:55:13","","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\78DYTQZ7\[Monographs in Mathematics №101] Vitaly Volpert (auth.) - Elliptic Partial Differential Equations_ Volume 1_ Fredholm Theory of Elliptic Problems in Unbounded Domains (2011, Birkhäuser) [10.1007_978-3-0346-0.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3NUWMGE","encyclopediaArticle","2023","","Spectral density estimation","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Spectral_density_estimation&oldid=1136326946","In statistical signal processing, the goal of spectral density estimation (SDE) or simply spectral estimation  is to estimate the spectral density (also known as the power spectral density) of a signal from a sequence of time samples of the signal. Intuitively speaking, the spectral density characterizes the frequency content of the signal. One purpose of estimating the spectral density is to detect any periodicities in the data, by observing peaks at the frequencies corresponding to these periodicities. Some SDE techniques assume that a signal is composed of a limited (usually small) number of generating frequencies plus noise and seek to find the location and intensity of the generated frequencies.  Others make no assumption on the number of components and seek to estimate the whole generating spectrum.","2023-01-29","2023-02-02 17:00:03","2023-02-02 17:00:03","2023-02-02 17:00:03","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1136326946","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XT93DKQQ","webpage","","","FINITE DIFFERENCE AND SPECTRAL METHODS FOR ORDINARY AND PARTIAL DIFFERENTIAL EQUATIONS","","","","","https://www.math.hmc.edu/~dyong/math165/trefethenbook.pdf","","","2023-02-08 15:17:54","2023-03-18 20:21:21","2023-02-08 15:16:22","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\GEQEN89I\trefethenbook.pdf","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKSTIAW2","journalArticle","","Chatterjee, K; Yu, C","A Monte Carlo Algorithm for the Solution of the One-Dimensional Wave Equation","","","","","","This paper presents a 1D Monte Carlo (MC) algorithm for the solution of the wave equation. Historically, the MC method has not been applied successfully to the solution of wave problems. This can primarily be attributed to the problem of resonance in the frequency-domain Green’s function for finite geometries at length scales greater than half a wavelength. In our previously published work, we have been successful in obtaining a frequency-domain solution at multiple-wavelength length scales through the use of infinite-domain Green’s functions. In this work, we extend the algorithm to problems in the time-domain. The MC method does not require any discretization, and hence the memory requirements are lower than approaches based on discretization. Another advantage of the MC method is that the computational procedure is inherently parallelizable and an almost linear increase in computational speed can be obtained with an increase in the number of processors. The application area of our interest is in the full-wave analysis of IC interconnect structures at multi-GHz frequencies.","","2023-02-09 08:59:19","2023-03-18 20:20:53","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\Z59LHDC5\Chatterjee en Yu - A Monte Carlo Algorithm for the Solution of the On.pdf","","monte carlo; PDE; hyperbolic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZRBKHQ8","journalArticle","","Barnett, Alex H","Greens Functions for the Wave Equation","","","","","","I gather together known results on fundamental solutions to the wave equation in free space, and Greens functions in tori, boxes, and other domains. From this the corresponding fundamental solutions for the Helmholtz equation are derived, and, for the 2D case the semiclassical approximation interpreted back in the time-domain. Utility: scarring via time-dependent propagation in cavities; Math 46 course ideas.","","2023-02-09 09:17:12","2023-03-18 20:20:11","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\P38YMD3D\Barnett - Greens Functions for the Wave Equation.pdf","","PDE; hyperbolic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83Z69CK3","journalArticle","2022","Rath, Alexander; Grittmann, Pascal; Herholz, Sebastian; Weier, Philippe; Slusallek, Philipp","EARS: efficiency-aware russian roulette and splitting","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3528223.3530168","https://dl.acm.org/doi/10.1145/3528223.3530168","Russian roulette and splitting are widely used techniques to increase the efficiency of Monte Carlo estimators. But, despite their popularity, there is little work on how to best apply them. Most existing approaches rely on simple heuristics based on, e.g., surface albedo and roughness. Their efficiency often hinges on user-controlled parameters. We instead iteratively learn optimal Russian roulette and splitting factors during rendering, using a simple and lightweight data structure. Given perfect estimates of variance and cost, our fixed-point iteration provably converges to the optimal Russian roulette and splitting factors that maximize the rendering efficiency. In our application to unidirectional path tracing, we achieve consistent and significant speed-ups over the state of the art.","2022-07","2023-02-10 11:06:54","2023-03-18 20:19:50","2023-02-10 11:06:54","1-14","","4","41","","ACM Trans. Graph.","EARS","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\SX8TXAMP\Rath e.a. - 2022 - EARS efficiency-aware russian roulette and splitt.pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZTYUYV8","journalArticle","2020","West, Rex; Georgiev, Iliyan; Gruson, Adrien; Hachisuka, Toshiya","Continuous multiple importance sampling","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3386569.3392436","https://dl.acm.org/doi/10.1145/3386569.3392436","Multiple importance sampling (MIS) is a provably good way to combine a finite set of sampling techniques to reduce variance in Monte Carlo integral estimation. However, there exist integration problems for which a continuum of sampling techniques is available. To handle such cases we establish a continuous MIS (CMIS) formulation as a generalization of MIS to uncountably infinite sets of techniques. Our formulation is equipped with a base estimator that is coupled with a provably optimal balance heuristic and a practical stochastic MIS (SMIS) estimator that makes CMIS accessible to a broad range of problems. To illustrate the effectiveness and utility of our framework, we apply it to three different light transport applications, showing improved performance over the prior state-of-the-art techniques.","2020-08-31","2023-02-10 11:12:54","2023-03-18 20:19:42","2023-02-10 11:12:54","","","4","39","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\T968PF33\West e.a. - 2020 - Continuous multiple importance sampling.pdf","","monte carlo; rendering; importance sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UP4ASYSQ","preprint","2021","He, Shengyi; Jiang, Guangxin; Lam, Henry; Fu, Michael C.","Adaptive Importance Sampling for Efficient Stochastic Root Finding and Quantile Estimation","","","","","http://arxiv.org/abs/2102.10631","In solving simulation-based stochastic root-ﬁnding or optimization problems that involve rare events, such as in extreme quantile estimation, running crude Monte Carlo can be prohibitively ineﬃcient. To address this issue, importance sampling can be employed to drive down the sampling error to a desirable level. However, selecting a good importance sampler requires knowledge of the solution to the problem at hand, which is the goal to begin with and thus forms a circular challenge. We investigate the use of adaptive importance sampling to untie this circularity. Our procedure sequentially updates the importance sampler to reach the optimal sampler and the optimal solution simultaneously, and can be embedded in both sample average approximation and stochastic approximation-type algorithms. Our theoretical analysis establishes strong consistency and asymptotic normality of the resulting estimators. We also demonstrate, via a minimax perspective, the key role of using adaptivity in controlling asymptotic errors. Finally, we illustrate the eﬀectiveness of our approach via numerical experiments.","2021-02-21","2023-02-10 11:20:19","2023-03-18 20:19:24","2023-02-10 11:20:19","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2102.10631 [math, stat]","","C:\Users\isido\Zotero\storage\AJ5J334J\He e.a. - 2021 - Adaptive Importance Sampling for Efficient Stochas.pdf","","monte carlo; rendering","Mathematics - Probability; Mathematics - Optimization and Control; Statistics - Methodology","","","","","","","","","","","","","","","","","","","arXiv:2102.10631","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SV389DF","conferencePaper","2022","West, Rex; Georgiev, Iliyan; Hachisuka, Toshiya","Marginal Multiple Importance Sampling","SIGGRAPH Asia 2022 Conference Papers","978-1-4503-9470-3","","10.1145/3550469.3555388","https://dl.acm.org/doi/10.1145/3550469.3555388","Multiple importance sampling (MIS) is a powerful tool to combine different sampling techniques in a provably good manner. MIS requires that the techniques’ probability density functions (PDFs) are readily evaluable point-wise. However, this requirement may not be satisfied when (some of) those PDFs are marginals, i.e., integrals of other PDFs. We generalize MIS to combine samples from such marginal PDFs. The key idea is to consider each marginalization domain as a continuous space of sampling techniques with readily evaluable (conditional) PDFs. We stochastically select techniques from these spaces and combine the samples drawn from them into an unbiased estimator. Prior work has dealt with the special cases of multiple classical techniques or a single marginal one. Our formulation can handle mixtures of those. We apply our marginal MIS formulation to light-transport simulation to demonstrate its utility. We devise a marginal path sampling framework that makes previously intractable sampling techniques practical and significantly broadens the path-sampling choices beyond what is presently possible. We highlight results from two algorithms based on marginal MIS: a novel formulation of path-space filtering at multiple vertices along a camera path and a similar filtering method for photon-density estimation. CCS Concepts: • Computing methodologies → Rendering; Ray tracing.","2022-11-29","2023-02-10 11:23:04","2023-03-18 20:19:05","2023-02-10 11:23:04","1-8","","","","","","","","","","","ACM","Daegu Republic of Korea","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\HGCCANTP\West e.a. - 2022 - Marginal Multiple Importance Sampling.pdf","","monte carlo; rendering; importance sampling; integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SA '22: SIGGRAPH Asia 2022","","","","","","","","","","","","","","",""
"YQU8X77K","preprint","2020","Crespo, Miguel; Bernal, Felix; Jarabo, Adrian; Muñoz, Adolfo","Primary-Space Adaptive Control Variates using Piecewise-Polynomial Approximations","","","","","http://arxiv.org/abs/2008.06722","We present an unbiased numerical integration algorithm that handles both low-frequency regions and high frequency details of multidimensional integrals. It combines quadrature and Monte Carlo integration, by using a quadrature-base approximation as a control variate of the signal. We adaptively build the control variate constructed as a piecewise polynomial, which can be analytically integrated, and accurately reconstructs the low frequency regions of the integrand. We then recover the high-frequency details missed by the control variate by using Monte Carlo integration of the residual. Our work leverages importance sampling techniques by working in primary space, allowing the combination of multiple mappings; this enables multiple importance sampling in quadrature-based integration. Our algorithm is generic, and can be applied to any complex multidimensional integral. We demonstrate its effectiveness with four applications with low dimensionality: transmittance estimation in heterogeneous participating media, low-order scattering in homogeneous media, direct illumination computation, and rendering of distributed effects. Finally, we show how our technique is extensible to integrands of higher dimensionality, by computing the control variate on Monte Carlo estimates of the high-dimensional signal, and accounting for such additional dimensionality on the residual as well. In all cases, we show accurate results and faster convergence compared to previous approaches.","2020-08-15","2023-02-10 11:32:58","2023-03-18 20:18:31","2023-02-10 11:32:58","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2008.06722 [cs]","","C:\Users\isido\Zotero\storage\UYAUD2N9\Crespo e.a. - 2020 - Primary-Space Adaptive Control Variates using Piec.pdf","","monte carlo; rendering; integration; control variates","Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:2008.06722","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3I3VLE8E","journalArticle","","Lfant, Fredrik Johansson; Bordeaux, Inria","Numerical integration in complex interval arithmetic","","","","","","","","2023-02-10 14:46:17","2023-03-18 20:05:02","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\WGXY3GTI\Lfant en Bordeaux - Numerical integration in complex interval arithmet.pdf","","integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJQNG7JJ","webpage","","","Fast Wavelet Transform (FWT) Algorithm - MATLAB & Simulink","","","","","https://www.mathworks.com/help/wavelet/ug/fast-wavelet-transform-fwt-algorithm.html?ue","","","2023-02-11 08:25:10","2023-03-18 20:04:51","2023-02-11 08:25:10","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\IZRA3VBE\fast-wavelet-transform-fwt-algorithm.html","","wavelets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QCDH2DMJ","videoRecording","2020","The Abel Prize","Ingrid Daubechies: Wavelet bases: roots, surprises and applications","","","","","https://www.youtube.com/watch?v=tMV61BZCrhk","This lecture was held by Ingrid Daubechies at The University of Oslo, May 24, 2017 and was part of the Abel Prize Lectures in connection with the Abel Prize Week celebrations.  Ingrid Daubechies is a Belgian physicist and mathematician. She is best known for her work with wavelets in image compression.  Abstract: Yves Meyer's surprising construction of orthonormal bases consisting of dilates and translates of a single smooth function was followed soon after by the development of the Multiresolution Analysis framework in collaboration with Stephane Mallat. As already shown in the presentation by Stephane Mallat, this development was rooted in and used insights from a variety of fields -- ranging from pure harmonic analysis to statistics, quantum physics, geophysics and computer vision. The lecture will discuss some of those diverse roots in more detail, and also show how the new wavelet synthesis, sparked by Yves Meyer's seminal work, led to further progress in all those fields as well as others. Finally, hindsight shows that the new paradigm introduced by wavelet analysis was a first example of the power of  sparse decompositions -- and thus a prelude to another paradigm shift, that of Compressed Sensing, about which more will follow, in the presentation by Emmanuel Candès.","2020-02-03","2023-02-11 08:26:33","2023-08-01 13:59:46","2023-02-11 08:26:33","","","","","","","Ingrid Daubechies","","","","","","","","","","","","YouTube","","","","","","wavelets","","","","","","","","","","","","","","","","","","","","","","45:51","","","","","","","","","","","","","","","","","","","","","","","","",""
"4G9KSSQT","conferencePaper","1997","Unser, Michael A.","Ten good reasons for using spline wavelets","","","","10.1117/12.292801","http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=930676","The purpose of this note is to highlight some of the unique properties of spline wavelets. These wavelets can be classified in four categories: othogonal (Battle-Lemarié), semi-orthogonal (e.g., B-spline), shift-orthogonal, and biorthogonal (Cohen-DaubechiesFeauveau). Unlike most other wavelet bases, splines have explicit formulae in both the time and frequency domain, which greatly facilitates their manipulation. They allow for a progressive transition between the two extreme cases of a multiresolution: Haar's piecewise constant representation (spline of degree zero) versus Shannon's bandlimited model (which corresponds to a spline of infinite order). Spline wavelets are extremely regular and usually symmetric or anti-symmetric. They can be designed to have compact support and to achieve optimal time-frequency localization (B-spline wavelets). The underlying scaling functions are the B-splines, which are the shortest and most regular scaling functions of order L. Finally, splines have the best approximation properties among all known wavelets of a given order L. In other words, they are the best for approximating smooth functions.","1997-10-30","2023-02-11 13:03:20","2023-03-18 20:04:33","2023-02-11 13:03:20","422-431","","","","","","","","","","","","San Diego, CA","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\CQW7SJ6F\Unser - 1997 - Ten good reasons for using spline wavelets.pdf","","wavelets","","Aldroubi, Akram; Laine, Andrew F.; Unser, Michael A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Optical Science, Engineering and Instrumentation '97","","","","","","","","","","","","","","",""
"8R3ABQSM","preprint","2016","Toulis, Panos; Airoldi, Edoardo M.","Asymptotic and finite-sample properties of estimators based on stochastic gradients","","","","","http://arxiv.org/abs/1408.2923","Stochastic optimization procedures, such as stochastic gradient descent, have gained popularity for parameter estimation from large data sets. However, standard stochastic optimization procedures cannot eﬀectively combine numerical stability with statistical and computational eﬃciency. Here, we introduce an implicit stochastic gradient descent procedure, the iterates of which are implicitly deﬁned. Intuitively, implicit iterates shrink the standard iterates. The amount of shrinkage depends on the observed Fisher information matrix, which does not need to be explicitly computed in practice, thus increasing stability without increasing the computational burden. When combined with averaging, the proposed procedure achieves statistical eﬃciency as well. We derive non-asymptotic bounds and characterize the asymptotic distribution of implicit procedures. Our analysis also reveals the asymptotic variance of a number of existing procedures. We demonstrate implicit stochastic gradient descent by further developing theory for generalized linear models, Cox proportional hazards, and M-estimation problems, and by carrying out extensive experiments. Our results suggest that the implicit stochastic gradient descent procedure is poised to become the workhorse of estimation with large data sets.","2016-09-28","2023-02-11 14:07:45","2023-03-18 20:04:24","2023-02-11 14:07:45","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1408.2923 [stat]","","C:\Users\isido\Zotero\storage\IUAWENHV\Toulis en Airoldi - 2016 - Asymptotic and finite-sample properties of estimat.pdf","","optimization","Statistics - Machine Learning; Statistics - Computation; Statistics - Methodology; 62L20, 62L12, 65L20","","","","","","","","","","","","","","","","","","","arXiv:1408.2923","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YY3EUM8L","journalArticle","2020","Rath, Alexander; Grittmann, Pascal; Herholz, Sebastian; Vévoda, Petr; Slusallek, Philipp; Křivánek, Jaroslav","Variance-aware path guiding","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3386569.3392441","https://dl.acm.org/doi/10.1145/3386569.3392441","Path guiding is a promising tool to improve the performance of path tracing algorithms. However, not much research has investigated what target densities a guiding method should strive to learn for optimal performance. Instead, most previous work pursues the zero-variance goal: The local decisions are guided under the assumption that all other decisions along the random walk will be sampled perfectly. In practice, however, many decisions are poorly guided, or not guided at all. Furthermore, learned distributions are often marginalized, e.g., by neglecting the BSDF. We present a generic procedure to derive theoretically optimal target densities for local path guiding. These densities account for variance in nested estimators, and marginalize provably well over, e.g., the BSDF. We apply our theory in two state-of-the-art rendering applications: a path guiding solution for unidirectional path tracing [Müller et al. 2017] and a guiding method for light source selection for the many lights problem [Vévoda et al. 2018]. In both cases, we observe significant improvements, especially on glossy surfaces. The implementations for both applications consist of trivial modifications to the original code base, without introducing any additional overhead.","2020-08-31","2023-02-11 15:09:58","2023-03-18 20:04:04","2023-02-11 15:09:58","","","4","39","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\X79P4T7Y\Rath e.a. - 2020 - Variance-aware path guiding.pdf","","monte carlo; rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WUD8S38Z","journalArticle","","Kekkonen, Hanne","Bayesian inverse problems","","","","","","","","2023-02-13 09:36:56","2023-02-13 09:36:56","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\FC5CGCB4\Kekkonen - Bayesian inverse problems.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BR3V9MQE","preprint","2015","Dashti, Masoumeh; Stuart, Andrew M.","The Bayesian Approach To Inverse Problems","","","","","http://arxiv.org/abs/1302.6989","These lecture notes highlight the mathematical and computational structure relating to the formulation of, and development of algorithms for, the Bayesian approach to inverse problems in diﬀerential equations. This approach is fundamental in the quantiﬁcation of uncertainty within applications involving the blending of mathematical models with data. The ﬁnite dimensional situation is described ﬁrst, along with some motivational examples. Then the development of probability measures on separable Banach space is undertaken, using a random series over an inﬁnite set of functions to construct draws; these probability measures are used as priors in the Bayesian approach to inverse problems. Regularity of draws from the priors is studied in the natural Sobolev or Besov spaces implied by the choice of functions in the random series construction, and the Kolmogorov continuity theorem is used to extend regularity considerations to the space of H¨older continuous functions. Bayes’ theorem is derived in this prior setting, and here interpreted as ﬁnding conditions under which the posterior is absolutely continuous with respect to the prior, and determining a formula for the Radon-Nikodym derivative in terms of the likelihood of the data. Having established the form of the posterior, we then describe various properties common to it in the inﬁnite dimensional setting. These properties include well-posedness, approximation theory, and the existence of maximum a posteriori estimators. We then describe measure-preserving dynamics, again on the inﬁnite dimensional space, including Markov chain-Monte Carlo and sequential Monte Carlo methods, and measure-preserving reversible stochastic diﬀerential equations. By formulating the theory and algorithms on the underlying inﬁnite dimensional space, we obtain a framework suitable for rigorous analysis of the accuracy of reconstructions, of computational complexity, as well as naturally constructing algorithms which perform well under mesh reﬁnement, since they are inherently well-deﬁned in inﬁnite dimensions.","2015-07-02","2023-02-13 09:39:41","2023-02-13 09:39:41","2023-02-13 09:39:41","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1302.6989 [math]","","C:\Users\isido\Zotero\storage\L5WQXGWS\Dashti en Stuart - 2015 - The Bayesian Approach To Inverse Problems.pdf","","","Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:1302.6989","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S5KQFJF5","preprint","2023","Stein, Andreas; Hoang, Viet Ha","Multilevel Markov Chain Monte Carlo for Bayesian Elliptic Inverse Problems with Besov Random Tree Priors","","","","","http://arxiv.org/abs/2302.00678","We propose a multilevel Markov chain Monte Carlo -FEM algorithm to solve elliptic Bayesian inverse problems with ”Besov random tree prior”. These priors are given by a wavelet series with stochastic coeﬃcients, and certain terms in the expansion vanishing at random, according to the law of so-called Galton-Watson trees. This allows to incorporate random fractal structures and large deviations in the log-diﬀusion, which occur naturally in many applications from geophysics or medical imaging. This framework entails two main diﬃculties: First, the associated diﬀusion coeﬃcient does not satisfy a uniform ellipticity condition, which leads to non-integrable terms and thus divergence of standard multilevel estimators. Secondly, the associated space of parameters is Polish, but not a normed linear space. We address the ﬁrst point by introducing cut-oﬀ functions in the estimator to compensate for the non-integrable terms, while the second issue is resolved by employing an independence Metropolis-Hastings sampler. The resulting algorithm converges in the mean-square sense with essentially optimal asymptotic complexity, and dimension-independent acceptance probabilities.","2023-02-01","2023-02-13 10:50:40","2023-03-19 11:09:35","2023-02-13 10:50:40","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2302.00678 [cs, math]","","C:\Users\isido\Zotero\storage\8HQLRDI8\Stein en Hoang - 2023 - Multilevel Markov Chain Monte Carlo for Bayesian E.pdf","","monte carlo","Mathematics - Probability; Mathematics - Numerical Analysis; 35R30, 65C05, 65C40, 65N12, 65N15, 65N30, 60G60","","","","","","","","","","","","","","","","","","","arXiv:2302.00678","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHWPZTLY","journalArticle","2005","Xiu, Dongbin; Hesthaven, Jan S.","High-Order Collocation Methods for Differential Equations with Random Inputs","SIAM Journal on Scientific Computing","","1064-8275, 1095-7197","10.1137/040615201","http://epubs.siam.org/doi/10.1137/040615201","Recently there has been a growing interest in designing eﬃcient methods for the solution of ordinary/partial diﬀerential equations with random inputs. To this end, stochastic Galerkin methods appear to be superior to other nonsampling methods and, in many cases, to several sampling methods. However, when the governing equations take complicated forms, numerical implementations of stochastic Galerkin methods can become nontrivial and care is needed to design robust and eﬃcient solvers for the resulting equations. On the other hand, the traditional sampling methods, e.g., Monte Carlo methods, are straightforward to implement, but they do not oﬀer convergence as fast as stochastic Galerkin methods. In this paper, a high-order stochastic collocation approach is proposed. Similar to stochastic Galerkin methods, the collocation methods take advantage of an assumption of smoothness of the solution in random space to achieve fast convergence. However, the numerical implementation of stochastic collocation is trivial, as it requires only repetitive runs of an existing deterministic solver, similar to Monte Carlo methods. The computational cost of the collocation methods depends on the choice of the collocation points, and we present several feasible constructions. One particular choice, based on sparse grids, depends weakly on the dimensionality of the random space and is more suitable for highly accurate computations of practical applications with large dimensional random inputs. Numerical examples are presented to demonstrate the accuracy and eﬃciency of the stochastic collocation methods.","2005-01","2023-02-13 11:13:00","2023-03-18 20:03:48","2023-02-13 11:13:00","1118-1139","","3","27","","SIAM J. Sci. Comput.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\PJ6XFAQG\Xiu en Hesthaven - 2005 - High-Order Collocation Methods for Differential Eq.pdf","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7I26G9BD","preprint","2014","Teckentrup, Aretha L.; Jantsch, Peter; Webster, Clayton G.; Gunzburger, Max","A Multilevel Stochastic Collocation Method for Partial Differential Equations with Random Input Data","","","","","http://arxiv.org/abs/1404.2647","Stochastic collocation methods for approximating the solution of partial diﬀerential equations with random input data (e.g., coeﬃcients and forcing terms) suﬀer from the curse of dimensionality whereby increases in the stochastic dimension cause an explosion of the computational eﬀort. We propose and analyze a multilevel version of the stochastic collocation method that, as is the case for multilevel Monte Carlo (MLMC) methods, uses hierarchies of spatial approximations to reduce the overall computational complexity. In addition, our proposed approach utilizes, for approximation in stochastic space, a sequence of multi-dimensional interpolants of increasing ﬁdelity which can then be used for approximating statistics of the solution as well as for building highorder surrogates featuring faster convergence rates. A rigorous convergence and computational cost analysis of the new multilevel stochastic collocation method is provided, demonstrating its advantages compared to standard single-level stochastic collocation approximations as well as MLMC methods. Numerical results are provided that illustrate the theory and the eﬀectiveness of the new multilevel method.","2014-05-22","2023-02-13 11:13:55","2023-03-18 20:03:36","2023-02-13 11:13:55","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1404.2647 [math]","","C:\Users\isido\Zotero\storage\R98M8FWQ\Teckentrup e.a. - 2014 - A Multilevel Stochastic Collocation Method for Par.pdf","","random ODE","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1404.2647","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5GPLP4C","preprint","2022","Deelstra, Griselda; Grzelak, Lech A.; Wolf, Felix","Accelerated Computations of Sensitivities for xVA","","","","","http://arxiv.org/abs/2211.17026","Exposure simulations are fundamental to many xVA calculations and are a nested expectation problem where repeated portfolio valuations create a signiﬁcant computational expense. Sensitivity calculations which require shocked and unshocked valuations in bump-and-revalue schemes exacerbate the computational load. A known reduction of the portfolio valuation cost is understood to be found in polynomial approximations, which we apply in this article to interest rate sensitivities of expected exposures. We consider a method based on the approximation of the shocked and unshocked valuation functions, as well as a novel approach in which the diﬀerence between these functions is approximated. Convergence results are shown, and we study the choice of interpolation nodes. Numerical experiments with interest rate derivatives are conducted to demonstrate the high accuracy and remarkable computational cost reduction. We further illustrate how the method can be extended to more general xVA models using the example of CVA with wrong-way risk.","2022-11-30","2023-02-13 11:15:17","2023-03-18 20:03:15","2023-02-13 11:15:17","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2211.17026 [q-fin]","","C:\Users\isido\Zotero\storage\GCGYS354\Deelstra e.a. - 2022 - Accelerated Computations of Sensitivities for xVA.pdf","","chebyhev","Quantitative Finance - Computational Finance; Quantitative Finance - Risk Management; 91G20, 91G30","","","","","","","","","","","","","","","","","","","arXiv:2211.17026","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FZQ8RRU","preprint","2013","Steffes-lai, Daniela; Rosseel, Eveline; Clees, Tanja","Interpolation methods to compute statistics of a stochastic partial differential equation","","","","","http://arxiv.org/abs/1309.3853","This paper considers the analysis of partial diﬀerential equations (PDE) containing multiple random variables. Recently developed collocation methods enable the construction of high-order stochastic solutions by converting a stochastic PDE into a system of deterministic PDEs. This interpolation method requires that the probability distribution of all random input variables is known a priori, which is often not the case in industrially relevant applications. Additionally, this method suﬀers from a curse of dimensionality, i.e., the number of deterministic PDEs to be solved grows exponentially with respect to the number of random variables. This paper presents an alternative interpolation method, based on a radial basis function (RBF) metamodel, to compute statistics of the stochastic PDE. The RBF metamodel can be constructed even if the probability distribution of all random variables is not known. Then, a lot of statistic scenarios with diﬀerent probability distributions of the random variables can be computed with this single metamodel. In order to reduce the model complexity, we present a parameter screening technique which can be combined with an interpolation method to solve a reduced stochastic model. Numerical results of a model problem demonstrate that the RBF metamodel is as fast as a low order collocation approach and achieves a good accuracy. The parameter screening is able to reduce the dimension and, thus, to accelerate the computation of the stochastic solution.","2013-09-16","2023-02-13 11:19:53","2023-02-13 11:19:54","2023-02-13 11:19:53","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1309.3853 [math]","","C:\Users\isido\Zotero\storage\DUFXWZYZ\Steffes-lai e.a. - 2013 - Interpolation methods to compute statistics of a s.pdf","","","Mathematics - Numerical Analysis; 35R60, 62H25, 93B35, 65N22","","","","","","","","","","","","","","","","","","","arXiv:1309.3853","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VYXF8QHR","preprint","2016","Gaß, Maximilian; Glau, Kathrin; Mahlstedt, Mirco; Mair, Maximilian","Chebyshev Interpolation for Parametric Option Pricing","","","","","http://arxiv.org/abs/1505.04648","Recurrent tasks such as pricing, calibration and risk assessment need to be executed accurately and in real-time. Simultaneously we observe an increase in model sophistication on the one hand and growing demands on the quality of risk management on the other. To address the resulting computational challenges, it is natural to exploit the recurrent nature of these tasks. We concentrate on Parametric Option Pricing (POP) and show that polynomial interpolation in the parameter space promises to reduce run-times while maintaining accuracy. The attractive properties of Chebyshev interpolation and its tensorized extension enable us to identify criteria for (sub)exponential convergence and explicit error bounds. We show that these results apply to a variety of European (basket) options and aﬃne asset models. Numerical experiments conﬁrm our ﬁndings. Exploring the potential of the method further, we empirically investigate the eﬃciency of the Chebyshev method for multivariate and path-dependent options.","2016-07-08","2023-02-13 11:27:30","2023-03-18 20:02:13","2023-02-13 11:27:30","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1505.04648 [q-fin]","","C:\Users\isido\Zotero\storage\3RRJ3YJB\Gaß e.a. - 2016 - Chebyshev Interpolation for Parametric Option Pric.pdf","","chebychev","Quantitative Finance - Computational Finance; 91G60, 41A10","","","","","","","","","","","","","","","","","","","arXiv:1505.04648","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4L7IEST7","preprint","2017","Glau, Kathrin; Herold, Paul; Madan, Dilip B.; Pötz, Christian","The Chebyshev method for the implied volatility","","","","","http://arxiv.org/abs/1710.01797","The implied volatility is a crucial element of any ﬁnancial toolbox, since it is used for quoting and the hedging of options as well as for model calibration. In contrast to the BlackScholes formula its inverse, the implied volatility, is not explicitly available and numerical approximation is required. We propose a bivariate interpolation of the implied volatility surface based on Chebyshev polynomials. This yields a closed-form approximation of the implied volatility, which is easy to implement and to maintain. We prove a subexponential error decay. This allows us to obtain an accuracy close to machine precision with polynomials of a low degree. We compare the performance of the method in terms of runtime and accuracy to the most common reference methods. In contrast to existing interpolation methods, the proposed method is able to compute the implied volatility for all relevant option data. In this context, numerical experiments conﬁrm a considerable increase in eﬃciency, especially for large data sets.","2017-10-04","2023-02-13 11:29:32","2023-03-18 20:02:05","2023-02-13 11:29:32","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1710.01797 [q-fin]","","C:\Users\isido\Zotero\storage\3VZDVADR\Glau e.a. - 2017 - The Chebyshev method for the implied volatility.pdf","","chebychev","Quantitative Finance - Computational Finance; 91G60, 90-08, 65D05","","","","","","","","","","","","","","","","","","","arXiv:1710.01797","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9C5TFE5F","preprint","2020","Glau, Kathrin; Wunderlich, Linus","The Deep Parametric PDE Method: Application to Option Pricing","","","","","http://arxiv.org/abs/2012.06211","We propose the deep parametric PDE method to solve high-dimensional parametric partial diﬀerential equations. A single neural network approximates the solution of a whole family of PDEs after being trained without the need of sample solutions. As a practical application, we compute option prices in the multivariate Black-Scholes model. After a single training phase, the prices for diﬀerent time, state and model parameters are available in milliseconds. We evaluate the accuracy in the price and a generalisation of the implied volatility with examples of up to 25 dimensions. A comparison with alternative machine learning approaches, conﬁrms the eﬀectiveness of the approach.","2020-12-11","2023-02-13 12:12:25","2023-02-13 12:12:26","2023-02-13 12:12:25","","","","","","","The Deep Parametric PDE Method","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2012.06211 [q-fin]","","C:\Users\isido\Zotero\storage\3AXRVL4J\Glau en Wunderlich - 2020 - The Deep Parametric PDE Method Application to Opt.pdf","","","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:2012.06211","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GC5A9D9V","preprint","2019","Glau, Kathrin; Kressner, Daniel; Statti, Francesco","Low-rank tensor approximation for Chebyshev interpolation in parametric option pricing","","","","","http://arxiv.org/abs/1902.04367","Treating high dimensionality is one of the main challenges in the development of computational methods for solving problems arising in ﬁnance, where tasks such as pricing, calibration, and risk assessment need to be performed accurately and in real-time. Among the growing literature addressing this problem, Gass et al. [14] propose a complexity reduction technique for parametric option pricing based on Chebyshev interpolation. As the number of parameters increases, however, this method is aﬀected by the curse of dimensionality. In this article, we extend this approach to treat high-dimensional problems: Additionally exploiting low-rank structures allows us to consider parameter spaces of high dimensions. The core of our method is to express the tensorized interpolation in tensor train (TT) format and to develop an eﬃcient way, based on tensor completion, to approximate the interpolation coeﬃcients. We apply the new method to two model problems: American option pricing in the Heston model and European basket option pricing in the multi-dimensional Black-Scholes model. In these examples we treat parameter spaces of dimensions up to 25. The numerical results conﬁrm the low-rank structure of these problems and the eﬀectiveness of our method compared to advanced techniques.","2019-02-12","2023-02-13 12:16:17","2023-03-18 20:01:54","2023-02-13 12:16:17","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1902.04367 [q-fin]","","C:\Users\isido\Zotero\storage\5FSQELEL\Glau e.a. - 2019 - Low-rank tensor approximation for Chebyshev interp.pdf","","chebyhev; finance","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:1902.04367","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGJUSC5B","preprint","2019","Glau, Kathrin; Pachon, Ricardo; Pötz, Christian","Speed-up credit exposure calculations for pricing and risk management","","","","","http://arxiv.org/abs/1912.01280","We introduce a new method to calculate the credit exposure of European and path-dependent options. The proposed method is able to calculate accurate expected exposure and potential future exposure proﬁles under the riskneutral and the real-world measure. Key advantage of is that it delivers an accuracy comparable to a full re-evaluation and at the same time it is faster than a regression-based method. Core of the approach is solving a dynamic programming problem by function approximation. This yields a closed form approximation along the paths together with the option’s delta and gamma. The simple structure allows for highly eﬃcient evaluation of the exposures, even for a large number of simulated paths. The approach is ﬂexible in the model choice, payoﬀ proﬁles and asset classes. We validate the accuracy of the method numerically for three diﬀerent equity products and a Bermudan interest rate swaption. Benchmarking against the popular least-squares Monte Carlo approach shows that our method is able to deliver a higher accuracy in a faster runtime.","2019-12-03","2023-02-13 12:18:55","2023-03-18 20:01:22","2023-02-13 12:18:55","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1912.01280 [q-fin]","","C:\Users\isido\Zotero\storage\5CIFA7XE\Glau e.a. - 2019 - Speed-up credit exposure calculations for pricing .pdf","","finance","Quantitative Finance - Computational Finance; Quantitative Finance - Risk Management","","","","","","","","","","","","","","","","","","","arXiv:1912.01280","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NXWYV3MR","preprint","2018","Glau, Kathrin; Mahlstedt, Mirco; Pötz, Christian","A new approach for American option pricing: The Dynamic Chebyshev method","","","","","http://arxiv.org/abs/1806.05579","We introduce a new method to price American options based on Chebyshev interpolation. In each step of a dynamic programming time-stepping we approximate the value function with Chebyshev polynomials. The key advantage of this approach is that it allows to shift the model-dependent computations into an oﬄine phase prior to the time-stepping. In the oﬄine part a family of generalised (conditional) moments is computed by an appropriate numerical technique such as a Monte Carlo, PDE or Fourier transform based method. Thanks to this methodological ﬂexibility the approach applies to a large variety of models. Online, the backward induction is solved on a discrete Chebyshev grid, and no (conditional) expectations need to be computed. For each time step the method delivers a closed form approximation of the price function along with the options’ delta and gamma. Moreover, the same family of (conditional) moments yield multiple outputs including the option prices for diﬀerent strikes, maturities and diﬀerent payoﬀ proﬁles. We provide a theoretical error analysis and ﬁnd conditions that imply explicit error bounds for a variety of stock price models. Numerical experiments conﬁrm the fast convergence of prices and sensitivities. An empirical investigation of accuracy and runtime also shows an eﬃciency gain compared with the least-square Monte-Carlo method introduced by Longstaﬀ and Schwartz (2001).","2018-06-14","2023-02-13 12:26:36","2023-03-18 20:00:52","2023-02-13 12:26:36","","","","","","","A new approach for American option pricing","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1806.05579 [q-fin]","","C:\Users\isido\Zotero\storage\5CD69T7N\Glau e.a. - 2018 - A new approach for American option pricing The Dy.pdf","","finance","Quantitative Finance - Computational Finance; 91G60, 41A10","","","","","","","","","","","","","","","","","","","arXiv:1806.05579","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XHY9MSE","journalArticle","2022","Nesterov, Yurii; Florea, Mihai I.","Gradient Methods with Memory","Optimization Methods and Software","","1055-6788, 1029-4937","10.1080/10556788.2020.1858831","http://arxiv.org/abs/2105.09241","In this paper, we consider gradient methods for minimizing smooth convex functions, which employ the information obtained at the previous iterations in order to accelerate the convergence towards the optimal solution. This information is used in the form of a piece-wise linear model of the objective function, which provides us with much better prediction abilities as compared with the standard linear model. To the best of our knowledge, this approach was never really applied in Convex Minimization to diﬀerentiable functions in view of the high complexity of the corresponding auxiliary problems. However, we show that all necessary computations can be done very eﬃciently. Consequently, we get new optimization methods, which are better than the usual Gradient Methods both in the number of oracle calls and in the computational time. Our theoretical conclusions are conﬁrmed by preliminary computational experiments.","2022-05-04","2023-02-14 11:11:38","2023-02-14 11:11:40","2023-02-14 11:11:38","936-953","","3","37","","Optimization Methods and Software","","","","","","","","en","","","","","arXiv.org","","arXiv:2105.09241 [math]","","C:\Users\isido\Zotero\storage\EZKMSTTQ\Nesterov en Florea - 2022 - Gradient Methods with Memory.pdf","","","Mathematics - Optimization and Control; 68Q25, 65Y20, 90C25","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9IG24US","journalArticle","2022","Anikin, Anton; Gasnikov, Alexander; Gornov, Alexander; Kamzolov, Dmitry; Maximov, Yury; Nesterov, Yurii","Efficient Numerical Methods to Solve Sparse Linear Equations with Application to PageRank","Optimization Methods and Software","","1055-6788, 1029-4937","10.1080/10556788.2020.1858297","http://arxiv.org/abs/1508.07607","Over the last two decades, the PageRank problem has received increased interest from the academic community as an efficient tool to estimate web-page importance in information retrieval. Despite numerous developments, the design of efficient optimization algorithms for the PageRank problem is still a challenge. This paper proposes three new algorithms with a linear-time complexity for solving the problem over a bounded-degree graph. The idea behind them is to set up the PageRank as a convex minimization problem over a unit simplex, and then solve it using iterative methods with small iteration complexity. Our theoretical results are supported by an extensive empirical justification using real-world and simulated data.","2022-05-04","2023-02-14 11:18:15","2023-03-19 17:19:21","2023-02-14 11:18:15","907-935","","3","37","","Optimization Methods and Software","","","","","","","","en","","","","","arXiv.org","","arXiv:1508.07607 [math]","","C:\Users\isido\Zotero\storage\7AQ4PXSZ\Anikin e.a. - 2022 - Efficient Numerical Methods to Solve Sparse Linear.pdf","","linear systems; page rank","Mathematics - Optimization and Control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JBYFX7Q","journalArticle","2021","Vicini, Delio; Speierer, Sébastien; Jakob, Wenzel","Path replay backpropagation: differentiating light paths using constant memory and linear time","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3450626.3459804","https://dl.acm.org/doi/10.1145/3450626.3459804","Differentiable physically-based rendering has become an indispensable tool for solving inverse problems involving light. Most applications in this area jointly optimize a large set of scene parameters to minimize an objective function, in which case reverse-mode differentiation is the method of choice for obtaining parameter gradients.             However, existing techniques that perform the necessary differentiation step suffer from either statistical bias or a prohibitive cost in terms of memory and computation time. For example, standard techniques for automatic differentiation based on program transformation or Wengert tapes lead to impracticably large memory usage when applied to physically-based rendering algorithms. A recently proposed adjoint method by Nimier-David et al. [2020] reduces this to a constant memory footprint, but the computation time for unbiased gradient estimates then becomes quadratic in the number of scattering events along a light path. This is problematic when the scene contains highly scattering materials like participating media.             In this paper, we propose a new unbiased backpropagation algorithm for rendering that only requires constant memory, and whose computation time is linear in the number of scattering events (i.e., just like path tracing). Our approach builds on the invertibility of the local Jacobian at scattering interactions to recover the various quantities needed for reverse-mode differentiation. Our method also extends to specular materials such as smooth dielectrics and conductors that cannot be handled by prior work.","2021-08-31","2023-02-17 21:29:58","2023-03-18 19:58:58","2023-02-17 21:29:58","1-14","","4","40","","ACM Trans. Graph.","Path replay backpropagation","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\CYDBTJMN\Vicini e.a. - 2021 - Path replay backpropagation differentiating light.pdf","","monte carlo; rendering; inverse problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXGSRH2D","preprint","2022","Sinha, Devang; Chakrabarty, Siddhartha P.","Multilevel Monte Carlo and its Applications in Financial Engineering","","","","","http://arxiv.org/abs/2209.14549","In this article, we present a review of the recent developments on the topic of Multilevel Monte Carlo (MLMC) algorithm, in the paradigm of applications in ﬁnancial engineering. We speciﬁcally focus on the recent studies conducted in two subareas, namely, option pricing and ﬁnancial risk management. For the former, the discussion involves incorporation of the importance sampling algorithm, in conjunction with the MLMC estimator, thereby constructing a hybrid algorithm in order to achieve reduction for the overall variance of the estimator. In case of the latter, we discuss the studies carried out in order to construct an efﬁcient algorithm in order to estimate the risk measures of Value-at-Risk (VaR) and Conditional Var (CVaR), in an efﬁcient manner. In this regard, we brieﬂy discuss the motivation and the construction of an adaptive sampling algorithm with an aim to efﬁciently estimate the nested expectation, which, in general is computationally expensive.","2022-09-29","2023-02-18 14:06:58","2023-03-18 19:58:43","2023-02-18 14:06:58","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2209.14549 [q-fin]","","C:\Users\isido\Zotero\storage\YZXZQ439\Sinha en Chakrabarty - 2022 - Multilevel Monte Carlo and its Applications in Fin.pdf","","monte carlo","Quantitative Finance - Computational Finance","","","","","","","","","","","","","","","","","","","arXiv:2209.14549","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MEA963SP","preprint","2020","Beck, Christian; Jentzen, Arnulf; Kruse, Thomas","Nonlinear Monte Carlo methods with polynomial runtime for high-dimensional iterated nested expectations","","","","","http://arxiv.org/abs/2009.13989","The approximative calculation of iterated nested expectations is a recurring challenging problem in applications. Nested expectations appear, for example, in the numerical approximation of solutions of backward stochastic diﬀerential equations (BSDEs), in the numerical approximation of solutions of semilinear parabolic partial diﬀerential equations (PDEs), in statistical physics, in optimal stopping problems such as the approximative pricing of American or Bermudan options, in risk measure estimation in mathematical ﬁnance, or in decisionmaking under uncertainty. Nested expectations which arise in the above named applications often consist of a large number of nestings. However, the computational eﬀort of standard nested Monte Carlo approximations for iterated nested expectations grows exponentially in the number of nestings and it remained an open question whether it is possible to approximately calculate multiply iterated high-dimensional nested expectations in polynomial time. In this article we tackle this problem by proposing and studying a new class of full-history recursive multilevel Picard (MLP) approximation schemes for iterated nested expectations. In particular, we prove under suitable assumptions that these MLP approximation schemes can approximately calculate multiply iterated nested expectations with a computational effort growing at most polynomially in the number of nestings K P N “ t1, 2, 3, . . .u, in the problem dimension d P N, and in the reciprocal 1{ε of the desired approximation accuracy ε P p0, 8q.","2020-09-29","2023-02-18 14:08:24","2023-03-18 19:58:26","2023-02-18 14:08:24","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2009.13989 [cs, math]","","C:\Users\isido\Zotero\storage\DERMR4VB\Beck e.a. - 2020 - Nonlinear Monte Carlo methods with polynomial runt.pdf","","monte carlo","Mathematics - Probability; Mathematics - Numerical Analysis; 65C05 (Primary) 65M75, 68Q25 (Secondary); Computer Science - Computational Complexity","","","","","","","","","","","","","","","","","","","arXiv:2009.13989","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G3A4N44J","preprint","2019","Jacquier, Antoine; Malone, Emma R.; Oumgari, Mugad","Stacked Monte Carlo for option pricing","","","","","http://arxiv.org/abs/1903.10795","We introduce a stacking version of the Monte Carlo algorithm in the context of option pricing. Introduced recently for aeronautic computations, this simple technique, in the spirit of current machine learning ideas, learns control variates by approximating Monte Carlo draws with some speciﬁed function. We describe the method from ﬁrst principles and suggest appropriate ﬁts, and show its eﬃciency to evaluate European and Asian Call options in constant and stochastic volatility models.","2019-03-26","2023-02-18 14:10:45","2023-03-18 19:58:20","2023-02-18 14:10:45","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1903.10795 [math, q-fin]","","C:\Users\isido\Zotero\storage\XMLJ4K7G\Jacquier e.a. - 2019 - Stacked Monte Carlo for option pricing.pdf","","monte carlo","Mathematics - Probability; Quantitative Finance - Computational Finance; 65C05, 91B28 65C50","","","","","","","","","","","","","","","","","","","arXiv:1903.10795","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KA66DW9Q","encyclopediaArticle","2022","","Malliavin calculus","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Malliavin_calculus&oldid=1115107254","In probability theory and related fields, Malliavin calculus is a set of mathematical techniques and ideas that extend the mathematical field of calculus of variations from  deterministic functions to stochastic processes. In particular, it allows the computation of derivatives of random variables. Malliavin calculus is also called the stochastic calculus of variations. P. Malliavin first initiated the calculus on infinite dimensional space. Then, the significant contributors such as S. Kusuoka, D. Stroock, Bismut, S. Watanabe, I. Shigekawa, and so on finally completed the foundations. Malliavin calculus is named after Paul Malliavin whose ideas led to a proof that Hörmander's condition implies the existence and smoothness of a density for the solution of a stochastic differential equation; Hörmander's original proof was based on the theory of  partial differential equations. The calculus has been applied to stochastic partial differential equations as well. The calculus allows integration by parts with random variables; this operation is used in mathematical finance to compute the sensitivities of financial derivatives. The calculus has applications in, for example, stochastic filtering.","2022-10-09","2023-02-20 11:46:29","2023-02-20 11:46:29","2023-02-20 11:46:29","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1115107254","","C:\Users\isido\Zotero\storage\SJFH7GTJ\Malliavin_calculus.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FH7EVQT9","preprint","2022","Pentland, Kamran; Tamborrino, Massimiliano; Sullivan, T. J.","Error bound analysis of the stochastic parareal algorithm","","","","","http://arxiv.org/abs/2211.05496","Stochastic parareal (SParareal) is a probabilistic variant of the popular parallel-intime algorithm known as parareal. Similarly to parareal, it combines ﬁne- and coarse-grained solutions to an ordinary diﬀerential equation (ODE) using a predictor-corrector (PC) scheme. The key diﬀerence is that carefully chosen random perturbations are added to the PC to try to accelerate the location of a stochastic solution to the ODE. In this paper, we derive superlinear and linear mean-square error bounds for SParareal applied to nonlinear systems of ODEs using diﬀerent types of perturbations. We illustrate these bounds numerically on a linear system of ODEs and a scalar nonlinear ODE, showing a good match between theory and numerics.","2022-11-10","2023-02-25 20:00:14","2023-03-18 19:57:47","2023-02-25 20:00:14","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2211.05496 [cs, math, stat]","","C:\Users\isido\Zotero\storage\STV8JTHP\Pentland e.a. - 2022 - Error bound analysis of the stochastic parareal al.pdf","","ODE","Mathematics - Numerical Analysis; Statistics - Computation; 65L70, 65Y05, 65C99","","","","","","","","","","","","","","","","","","","arXiv:2211.05496","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7XALDZ5Y","preprint","2022","Carrel, Benjamin; Gander, Martin J.; Vandereycken, Bart","Low-rank Parareal: a low-rank parallel-in-time integrator","","","","","http://arxiv.org/abs/2203.08455","In this work, the Parareal algorithm is applied to evolution problems that admit good low-rank approximations and for which the dynamical low-rank approximation (DLRA) can be used as time stepper. Many discrete integrators for DLRA have recently been proposed, based on splitting the projected vector ﬁeld or by applying projected Runge–Kutta methods. The cost and accuracy of these methods are mostly governed by the rank chosen for the approximation. These properties are used in a new method, called low-rank Parareal, in order to obtain a time-parallel DLRA solver for evolution problems. The algorithm is analyzed on aﬃne linear problems and the results are illustrated numerically.","2022-09-13","2023-02-25 20:03:50","2023-03-18 19:57:35","2023-02-25 20:03:50","","","","","","","Low-rank Parareal","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2203.08455 [cs, math]","","C:\Users\isido\Zotero\storage\L5268KDM\Carrel e.a. - 2022 - Low-rank Parareal a low-rank parallel-in-time int.pdf","","ODE","Mathematics - Numerical Analysis; 65L05, 65L20, 65L70, 68W10, 65F45, 65F55","","","","","","","","","","","","","","","","","","","arXiv:2203.08455","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S8V3RHIR","journalArticle","2008","Gander, M.; Petcu, M.","Analysis of a Krylov subspace enhanced parareal algorithm for linear problems","ESAIM: Proceedings","","1270-900X","10.1051/proc:082508","http://www.esaim-proc.org/10.1051/proc:082508","The parareal algorithm is a numerical method to integrate evolution problems on parallel computers. The performance of the algorithm is well understood for diﬀusive problems, and it can have spectacular performance when applied to certain non-linear problems. Its convergence properties are however less favorable for hyperbolic problems. We present and analyze in this paper a variant of the parareal algorithm, recently proposed in the PITA framework for systems of second order ordinary diﬀerential equations.","2008","2023-02-25 20:07:34","2023-03-18 19:57:26","2023-02-25 20:07:33","114-129","","","25","","ESAIM: Proc.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\Q9UAI328\Gander en Petcu - 2008 - Analysis of a Krylov subspace enhanced parareal al.pdf","","ODE","","Cancès, E.; Faure, S.; Graille, B.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDXUPPVJ","preprint","2023","Gander, M. J.; Lunet, T.; Ruprecht, D.; Speck, R.","A unified analysis framework for iterative parallel-in-time algorithms","","","","","http://arxiv.org/abs/2203.16069","Parallel-in-time integration has been the focus of intensive research eﬀorts over the past two decades due to the advent of massively parallel computer architectures and the scaling limits of purely spatial parallelization. Various iterative parallel-in-time (PinT) algorithms have been proposed, like Parareal, PFASST, MGRIT, and Space-Time Multi-Grid (STMG). These methods have been described using diﬀerent notations, and the convergence estimates that are available are diﬃcult to compare. We describe Parareal, PFASST, MGRIT and STMG for the Dahlquist model problem using a common notation and give precise convergence estimates using generating functions. This allows us, for the ﬁrst time, to directly compare their convergence. We prove that all four methods eventually converge super-linearly, and also compare them numerically. The generating function framework provides further opportunities to explore and analyze existing and new methods.","2023-02-08","2023-02-25 20:11:45","2023-03-18 19:57:22","2023-02-25 20:11:45","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2203.16069 [cs, math]","","C:\Users\isido\Zotero\storage\ARYQ6U3W\2203.16069.pdf","","ODE","Mathematics - Numerical Analysis; Computer Science - Computational Engineering, Finance, and Science","","","","","","","","","","","","","","","","","","","arXiv:2203.16069","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSZRFWNB","preprint","2020","Maday, Y.; Mula, O.","An Adaptive Parareal Algorithm","","","","","http://arxiv.org/abs/1909.08333","In this paper, we consider the problem of accelerating the numerical simulation of time dependent problems by time domain decomposition. The available algorithms enabling such decompositions present severe eﬃciency limitations and are an obstacle for the solution of large scale and high dimensional problems. Our main contribution is the improvement of the parallel eﬃciency of the parareal in time method. The parareal method is based on combining predictions made by a numerically inexpensive solver (with coarse physics and/or coarse resolution) with corrections coming from an expensive solver (with highﬁdelity physics and high resolution). At convergence, the algorithm provides a solution that has the ﬁne solver’s high-ﬁdelity physics and high resolution. In the classical version, the ﬁne solver has a ﬁxed high accuracy which is the major obstacle to achieve a competitive parallel eﬃciency. In this paper, we develop an adaptive variant that overcomes this obstacle by dynamically increasing the accuracy of the ﬁne solver across the parareal iterations. We theoretically show that the parallel eﬃciency becomes very competitive in the ideal case where the cost of the coarse solver is small, thus proving that the only remaining factors impeding full scalability become the cost of the coarse solver and communication time. The developed theory has also the merit of setting a general framework to understand the success of several extensions of parareal based on iteratively improving the quality of the ﬁne solver and re-using information from previous parareal steps. We illustrate the actual performance of the method in stiﬀ ODEs, which are a challenging family of problems since the only mechanism for adaptivity is time and eﬃciency is aﬀected by the cost of the coarse solver.","2020-03-26","2023-02-25 20:14:10","2023-03-18 19:56:49","2023-02-25 20:14:10","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1909.08333 [cs, math]","","C:\Users\isido\Zotero\storage\3JZWT34D\Maday en Mula - 2020 - An Adaptive Parareal Algorithm.pdf","","ODE","Mathematics - Numerical Analysis; 65M12, 65N55, 65Y05, 65Y20","","","","","","","","","","","","","","","","","","","arXiv:1909.08333","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHSY4AN9","encyclopediaArticle","2023","","Monte Carlo integration","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Monte_Carlo_integration&oldid=1135560956","In mathematics, Monte Carlo integration is a technique for numerical integration using random numbers. It is a particular Monte Carlo method that numerically computes a definite integral. While other algorithms usually evaluate the integrand at a regular grid, Monte Carlo randomly chooses points at which the integrand is evaluated. This method is particularly useful for higher-dimensional integrals.There are different methods to perform a Monte Carlo integration, such as uniform sampling, stratified sampling, importance sampling, sequential Monte Carlo (also known as a particle filter), and mean-field particle methods.","2023-01-25","2023-03-01 17:30:09","2023-03-18 19:56:43","2023-03-01 17:30:09","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1135560956","","C:\Users\isido\Zotero\storage\GELHMB8Z\Monte_Carlo_integration.html","","monte carlo; integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJNXRK4T","journalArticle","2021","Lepage, G. Peter","Adaptive Multidimensional Integration: VEGAS Enhanced","Journal of Computational Physics","","00219991","10.1016/j.jcp.2021.110386","http://arxiv.org/abs/2009.05112","We describe a new algorithm, VEGAS+, for adaptive multidimensional Monte Carlo integration. The new algorithm adds a second adaptive strategy, adaptive stratiﬁed sampling, to the adaptive importance sampling that is the basis for its widely used predecessor VEGAS. Both VEGAS and VEGAS+ are effective for integrands with large peaks, but VEGAS+ can be much more effective for integrands with multiple peaks or other signiﬁcant structures aligned with diagonals of the integration volume. We give examples where VEGAS+ is 2–19× more accurate than VEGAS. We also show how to combine VEGAS+ with other integrators, such as the widely available MISER algorithm, to make new hybrid integrators. For a different kind of hybrid, we show how to use integrand samples, generated using MCMC or other methods, to optimize VEGAS+ before integrating. We give an example where preconditioned VEGAS+ is more than 100× as efﬁcient as VEGAS+ without preconditioning. Finally, we give examples where VEGAS+ is more than 10× as efﬁcient as MCMC for Bayesian integrals with D = 3 and 21 parameters. We explain why VEGAS+ will often outperform MCMC for small and moderate sized problems.","2021-08","2023-03-01 17:53:35","2023-03-18 19:56:31","2023-03-01 17:53:35","110386","","","439","","Journal of Computational Physics","Adaptive Multidimensional Integration","","","","","","","en","","","","","arXiv.org","","arXiv:2009.05112 [hep-ph, physics:physics]","","C:\Users\isido\Zotero\storage\HQJAQY43\Lepage - 2021 - Adaptive Multidimensional Integration VEGAS Enhan.pdf","","monte carlo; integration","Physics - Computational Physics; High Energy Physics - Phenomenology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZKWA9A36","journalArticle","2021","Mousavi, Ali; Monsefi, Reza; Elvira, Víctor","Hamiltonian Adaptive Importance Sampling","IEEE Signal Processing Letters","","1070-9908, 1558-2361","10.1109/LSP.2021.3068616","http://arxiv.org/abs/2209.13716","Importance sampling (IS) is a powerful Monte Carlo (MC) methodology for approximating integrals, for instance in the context of Bayesian inference. In IS, the samples are simulated from the so-called proposal distribution, and the choice of this proposal is key for achieving a high performance. In adaptive IS (AIS) methods, a set of proposals is iteratively improved. AIS is a relevant and timely methodology although many limitations remain yet to be overcome, e.g., the curse of dimensionality in high-dimensional and multi-modal problems. Moreover, the Hamiltonian Monte Carlo (HMC) algorithm has become increasingly popular in machine learning and statistics. HMC has several appealing features such as its exploratory behavior, especially in high-dimensional targets, when other methods suffer. In this paper, we introduce the novel Hamiltonian adaptive importance sampling (HAIS) method. HAIS implements a two-step adaptive process with parallel HMC chains that cooperate at each iteration. The proposed HAIS efﬁciently adapts a population of proposals, extracting the advantages of HMC. HAIS can be understood as a particular instance of the generic layered AIS family with an additional resampling step. HAIS achieves a signiﬁcant performance improvement in high-dimensional problems w.r.t. state-of-the-art algorithms. We discuss the statistical properties of HAIS and show its high performance in two challenging examples.","2021","2023-03-01 18:11:46","2023-03-18 19:56:20","2023-03-01 18:11:46","713-717","","","28","","IEEE Signal Process. Lett.","","","","","","","","en","","","","","arXiv.org","","arXiv:2209.13716 [cs, stat]","","C:\Users\isido\Zotero\storage\CKVBTMH7\Mousavi e.a. - 2021 - Hamiltonian Adaptive Importance Sampling.pdf","","monte carlo","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MV9IBLKD","journalArticle","2020","Carrazza, Stefano; Cruz-Martinez, Juan M.","VegasFlow: accelerating Monte Carlo simulation across multiple hardware platforms","Computer Physics Communications","","00104655","10.1016/j.cpc.2020.107376","http://arxiv.org/abs/2002.12921","We present VegasFlow , a new software for fast evaluation of high dimensional integrals based on Monte Carlo integration techniques designed for platforms with hardware accelerators. The growing complexity of calculations and simulations in many areas of science have been accompanied by advances in the computational tools which have helped their developments. VegasFlow enables developers to delegate all complicated aspects of hardware or platform implementation to the library so they can focus on the problem at hand. This software is inspired on the Vegas algorithm, ubiquitous in the particle physics community as the driver of cross section integration, and based on Google’s powerful TensorFlow library. We benchmark the performance of this library on many diﬀerent consumer and professional grade GPUs and CPUs.","2020-09","2023-03-01 18:42:17","2023-03-18 19:56:01","2023-03-01 18:42:17","107376","","","254","","Computer Physics Communications","VegasFlow","","","","","","","en","","","","","arXiv.org","","arXiv:2002.12921 [hep-ex, physics:hep-ph, physics:physics, stat]","","C:\Users\isido\Zotero\storage\DVF3BGFQ\Carrazza en Cruz-Martinez - 2020 - VegasFlow accelerating Monte Carlo simulation acr.pdf","","monte carlo","Statistics - Machine Learning; Physics - Computational Physics; High Energy Physics - Phenomenology; High Energy Physics - Experiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CF2EK23Q","preprint","2017","Bendavid, Joshua","Efficient Monte Carlo Integration Using Boosted Decision Trees and Generative Deep Neural Networks","","","","","http://arxiv.org/abs/1707.00028","New machine learning based algorithms have been developed and tested for Monte Carlo integration based on generative Boosted Decision Trees and Deep Neural Networks. Both of these algorithms exhibit substantial improvements compared to existing algorithms for non-factorizable integrands in terms of the achievable integration precision for a given number of target function evaluations. Large scale Monte Carlo generation of complex collider physics processes with improved eﬃciency can be achieved by implementing these algorithms into commonly used matrix element Monte Carlo generators once their robustness is demonstrated and performance validated for the relevant classes of matrix elements.","2017-06-30","2023-03-01 19:30:24","2023-03-18 19:55:53","2023-03-01 19:30:24","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1707.00028 [hep-ph, physics:physics]","","C:\Users\isido\Zotero\storage\VAWIJ2CM\Bendavid - 2017 - Efficient Monte Carlo Integration Using Boosted De.pdf","","monte carlo; integration; machine learning","Physics - Computational Physics; High Energy Physics - Phenomenology","","","","","","","","","","","","","","","","","","","arXiv:1707.00028","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BBQTH2T","journalArticle","","Huang, Yipeng; Guo, Ning; Seok, Mingoo; Tsividis, Yannis; Sethumadhavan, Simha","Evaluation of an Analog Accelerator for Linear Algebra","","","","","","Due to the end of supply voltage scaling and the increasing percentage of dark silicon in modern integrated circuits, researchers are looking for new scalable ways to get useful computation from existing silicon technology. In this paper we present a reconﬁgurable analog accelerator for solving systems of linear equations. Commonly perceived downsides of analog computing, such as low precision and accuracy, limited problem sizes, and difﬁculty in programming are all compensated for using methods we discuss. Based on a prototyped analog accelerator chip we compare the performance and energy consumption of the analog solver against an efﬁcient digital algorithm running on a CPU, and ﬁnd that the analog accelerator approach may be an order of magnitude faster and provide one third energy savings, depending on the accelerator design. Due to the speed and efﬁciency of linear algebra algorithms running on digital computers, an analog accelerator that matches digital performance needs a large silicon footprint. Finally, we conclude that problem classes outside of systems of linear equations may hold more promise for analog acceleration.","","2023-03-01 19:33:00","2023-03-18 19:48:15","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\TF7SI6TR\Huang e.a. - Evaluation of an Analog Accelerator for Linear Alg.pdf","","analog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72HKM9L7","encyclopediaArticle","2023","","Analog computer","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Analog_computer&oldid=1140592830","An analog computer or analogue computer is a type of computer that uses the continuous variation aspect of physical phenomena such as electrical, mechanical, or hydraulic quantities (analog signals) to model the problem being solved. In contrast, digital computers represent varying quantities symbolically and by discrete values of both time and amplitude (digital signals). Analog computers can have a very wide range of complexity. Slide rules and nomograms are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Complex mechanisms for process control and protective relays used analog computation to perform control and protective functions. Analog computers were widely used in scientific and industrial applications even after the advent of digital computers, because at the time they were typically much faster, but they started to become obsolete as early as the 1950s and 1960s, although they remained in use in some specific applications, such as aircraft flight simulators, the flight computer in aircraft, and for teaching control systems in universities. Perhaps the most relatable example of analog computers are mechanical watches where the continuous and periodic rotation of interlinked gears drives the seconds, minutes and hours needles in the clock. More complex applications, such as aircraft flight simulators and synthetic-aperture radar, remained the domain of analog computing (and hybrid computing) well into the 1980s, since digital computers were insufficient for the task.","2023-02-20","2023-03-01 20:03:49","2023-03-18 19:48:04","2023-03-01 20:03:49","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1140592830","","C:\Users\isido\Zotero\storage\78SJPMU4\Analog_computer.html","","analog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MUF8X5CR","journalArticle","","Guo, Ning","Investigation of Energy-Efficient Hybrid Analog/Digital Approximate Computation in Continuous Time","","","","","","This work investigates energy-efficient approximate computation for solving differential equations. It extends the analog computing techniques to a new paradigm: continuous-time hybrid computation, where both analog and digital circuits operate in continuous time. In this approach, the time intervals in the digital signals contain important information. Unlike conventional synchronous digital circuits, continuous-time digital signals offer the benefits of adaptive power dissipation and no quantization noise. Two prototype chips have been fabricated in 65 nm CMOS technology and tested successfully. The first chip is capable of solving nonlinear differential equations up to 4th order, and the second chip scales up to 16th order based on the first chip. Nonlinear functions are generated by a programmable, clockless, continuous-time 8-bit hybrid architecture (ADC+SRAM+DAC). Digitally-assisted calibration is used in all analog/mixed-signal blocks. Compared to the prior art [1], our chips makes possible arbitrary nonlinearities and achieves 16× lower power dissipation, thanks to technology scaling and extensive use of class-AB analog blocks Typically, the unit achieves a computational accuracy of about 0.5% to 5% RMS, solution times from a fraction of 1 μs to several hundred μs, and total computational energy from a fraction of 1 nJ to hundreds of nJ, depending on equation details. Very significant advantages are observed in computational speed and energy (over two orders of magnitude and over one order of magnitude, respectively) compared to those obtained with a modern MSP430 microcontroller for the same RMS error.","","2023-03-01 20:15:03","2023-08-01 13:56:51","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\DZW3H37R\Guo - Investigation of Energy-Efficient Hybrid AnalogDi.pdf","","ODE; analog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4FTH329","conferencePaper","2018","Huang, Yipeng; Guo, Ning; Sethumadhavan, Simha; Seok, Mingoo; Tsividis, Yannis","A Case Study in Analog Co-Processing for Solving Stochastic Differential Equations","2018 IEEE 23rd International Conference on Digital Signal Processing (DSP)","978-1-5386-6811-5","","10.1109/ICDSP.2018.8631831","https://ieeexplore.ieee.org/document/8631831/","Stochastic differential equations (SDEs) are an important class of mathematical models for areas such as physics and ﬁnance. Usually the model outputs are in the form of statistics of the dependent variables, generated from many solutions of the SDE using different samples of the random variables. Challenges in using existing conventional digital computer architectures for solving SDEs include: rapidly generating the random input variables for the SDE solutions, and having to use numerical integration to solve the differential equations. Recent work by our group has explored using hybrid analog-digital computing to solve differential equations. In the hybrid computing model, we solve differential equations by encoding variables as continuous values, which evolve in continuous time. In this paper we review the prior work, and study using the architecture, in conjunction with analog noise, to solve a canonical SDE, the Black-Scholes SDE.","2018-11","2023-03-01 20:16:01","2023-03-18 19:31:02","2023-03-01 20:16:01","1-5","","","","","","","","","","","IEEE","Shanghai, China","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\DVZPDWCW\Huang e.a. - 2018 - A Case Study in Analog Co-Processing for Solving S.pdf","","analog","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE 23rd International Conference on Digital Signal Processing (DSP)","","","","","","","","","","","","","","",""
"EF36SFGB","conferencePaper","2017","Huang, Yipeng; Guo, Ning; Seok, Mingoo; Tsividis, Yannis; Mandli, Kyle; Sethumadhavan, Simha","Hybrid analog-digital solution of nonlinear partial differential equations","Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture","978-1-4503-4952-9","","10.1145/3123939.3124550","https://dl.acm.org/doi/10.1145/3123939.3124550","We tackle the important problem class of solving nonlinear partial di↵erential equations. While nonlinear PDEs are typically solved in high-performance supercomputers, they are increasingly used in graphics and embedded systems, where e ciency is important.","2017-10-14","2023-03-01 20:17:38","2023-03-18 19:04:50","2023-03-01 20:17:38","665-678","","","","","","","","","","","ACM","Cambridge Massachusetts","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\WZ7SMKY8\Huang e.a. - 2017 - Hybrid analog-digital solution of nonlinear partia.pdf","","PDE; analog; Newton; nonlinear PDE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","MICRO-50: The 50th Annual IEEE/ACM International Symposium on Microarchitecture","","","","","","","","","","","","","","",""
"QM4XAKYD","journalArticle","2019","Georgiev, Iliyan; Misso, Zackary; Hachisuka, Toshiya; Nowrouzezahrai, Derek; Křivánek, Jaroslav; Jarosz, Wojciech","Integral formulations of volumetric transmittance","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3355089.3356559","https://dl.acm.org/doi/10.1145/3355089.3356559","Computing the light attenuation between two given points is an essential yet expensive task in volumetric light transport simulation. Existing unbiased transmittance estimators are all based on ""null-scattering"" random walks enabled by augmenting the media with fictitious matter. This formulation prevents the use of traditional Monte Carlo estimator variance analysis, thus the efficiency of such methods is understood from a mostly empirical perspective. In this paper, we present several novel integral formulations of volumetric transmittance in which existing estimators arise as direct Monte Carlo estimators. Breaking from physical intuition, we show that the null-scattering concept is not strictly required for unbiased transmittance estimation, but is a form of control variates for effectively reducing variance. Our formulations bring new insight into the problem and the efficiency of existing estimators. They also provide a framework for devising new types of transmittance estimators with distinct and complementary performance tradeoffs, as well as a clear recipe for applying sample stratification.","2019-12-31","2023-03-02 20:25:03","2023-03-18 16:07:44","2023-03-02 20:25:03","1-17","","6","38","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\J48ZZ86P\3355089.pdf","","monte carlo; rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLKQLSFS","preprint","2022","Goda, Takashi; Kazashi, Yoshihito; Suzuki, Yuya","Randomizing the trapezoidal rule gives the optimal RMSE rate in Gaussian Sobolev spaces","","","","","http://arxiv.org/abs/2212.11476","Randomized quadratures for integrating functions in Sobolev spaces of order α ≥ 1, where the integrability condition is with respect to the Gaussian measure, are considered. In this function space, the optimal rate for the worst-case root-mean-squared error (RMSE) is established. Here, optimality is for a general class of quadratures, in which adaptive non-linear algorithms with a possibly varying number of function evaluations are also allowed. The optimal rate is given by showing matching bounds. First, a lower bound on the worst-case RMSE of O(n−α−1/2) is proven, where n denotes an upper bound on the expected number of function evaluations. It turns out that a suitably randomized trapezoidal rule attains this rate, up to a logarithmic factor. A practical error estimator for this trapezoidal rule is also presented. Numerical results support our theory.","2022-12-21","2023-03-06 09:27:13","2023-03-18 16:07:11","2023-03-06 09:27:13","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2212.11476 [cs, math]","","C:\Users\isido\Zotero\storage\E7GZXZDN\Goda e.a. - 2022 - Randomizing the trapezoidal rule gives the optimal.pdf","","integration; randomized trapezodial","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2212.11476","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AM7SI2XZ","preprint","2022","Mitchell, William; Natkin, Abbie; Robertson, Paige; Sullivan, Marika; Yu, Xuechen; Zhu, Chenxin","Decomposition and conformal mapping techniques for the quadrature of nearly singular integrals","","","","","http://arxiv.org/abs/2210.09954","Gauss-Legendre quadrature and the trapezoidal rule are powerful tools for numerical integration of analytic functions. For nearly singular problems, however, these standard methods become unacceptably slow. We discuss and generalize some existing methods for improving on these schemes when the location of the nearby singularity is known. We conclude with an application to some nearly singular surface integrals of viscous flow.","2022-10-18","2023-03-06 09:32:15","2023-03-18 16:06:14","2023-03-06 09:32:15","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2210.09954 [cs, math]","","C:\Users\isido\Zotero\storage\I4A6MUMA\2210.09954.pdf","","integration","Mathematics - Numerical Analysis; 65D32, 30C20, 76D07","","","","","","","","","","","","","","","","","","","arXiv:2210.09954","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWMQCLIT","preprint","2022","Izzo, Federico; Runborg, Olof; Tsai, Richard","Convergence of a class of high order corrected trapezoidal rules","","","","","http://arxiv.org/abs/2208.08216","We present convergence theory for corrected quadrature rules on uniform Cartesian grids for functions with a point singularity. We begin by deriving an error estimate for the punctured trapezoidal rule, and then derive error expansions. We deﬁne the corrected trapezoidal rules, based on the punctured trapezoidal rule, where the weights for the nodes close to the singularity are judiciously corrected based on these expansions. Then we deﬁne the composite corrected trapezoidal rules for a larger family of functions using series expansions around the point singularity and applying corrected trapezoidal rules appropriately. We prove that we can achieve high order accuracy by using a suﬃcient number of correction nodes around the point singularity and of expansion terms.","2022-08-27","2023-03-06 09:38:52","2023-03-18 16:05:58","2023-03-06 09:38:52","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2208.08216 [cs, math]","","C:\Users\isido\Zotero\storage\7BMQ6MUX\2208.08216.pdf","","integration","Mathematics - Numerical Analysis; 65D30, 65D32","","","","","","","","","","","","","","","","","","","arXiv:2208.08216","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVT896JW","journalArticle","2022","Song, Chongmin; Eisenträger, Sascha","High-order implicit time integration scheme based on Pad\'e expansions","Computer Methods in Applied Mechanics and Engineering","","00457825","10.1016/j.cma.2021.114436","http://arxiv.org/abs/2103.12282","A single-step high-order implicit time integration scheme for the solution of transient and wave propagation problems is presented. It is constructed from the Pad´e expansions of the matrix exponential solution of a system of ﬁrst-order ordinary diﬀerential equations formulated in the state-space. A computationally eﬃcient scheme is developed exploiting the techniques of polynomial factorization and partial fractions of rational functions, and by decoupling the solution for the displacement and velocity vectors. An important feature of the novel algorithm is that no direct inversion of the mass matrix is required. From the diagonal Pad´e expansion of order M a time-stepping scheme of order 2M is developed. Here, each elevation of the accuracy by two orders results in an additional system of real or complex sparse equations to be solved. These systems are comparable in complexity to the standard Newmark method, i.e., the eﬀective system matrix is a linear combination of the static stiﬀness, damping, and mass matrices. It is shown that the second-order scheme is equivalent to Newmark’s constant average acceleration method, often also referred to as trapezoidal rule. The proposed time integrator has been implemented in MATLAB using the built-in direct linear equation solvers. In this article, numerical examples featuring nearly one million degrees of freedom are presented. High-accuracy and eﬃciency in comparison with common second-order time integration schemes are observed. The MATLAB-implementation is available from the authors upon request or from the GitHub repository (to be added).","2022-02","2023-03-06 09:42:24","2023-03-18 15:59:09","2023-03-06 09:42:24","114436","","","390","","Computer Methods in Applied Mechanics and Engineering","","","","","","","","en","","","","","arXiv.org","","arXiv:2103.12282 [cs, math]","","C:\Users\isido\Zotero\storage\NTJ24PYR\2103.12282.pdf","","ODE","Mathematics - Numerical Analysis; 65M22; G.1.3; G.1.8; J.2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YA4LBIR","journalArticle","2017","Kruse, Raphael; Wu, Yue","Error analysis of randomized Runge-Kutta methods for differential equations with time-irregular coefficients","Computational Methods in Applied Mathematics","","1609-9389, 1609-4840","10.1515/cmam-2016-0048","http://arxiv.org/abs/1701.03444","This paper contains an error analysis of two randomized explicit Runge-Kutta schemes for ordinary diﬀerential equations (ODEs) with timeirregular coeﬃcient functions. In particular, the methods are applicable to ODEs of Carath´eodory type, whose coeﬃcient functions are only integrable with respect to the time variable but are not assumed to be continuous. A further ﬁeld of application are ODEs with coeﬃcient functions that contain weak singularities with respect to the time variable.","2017-07-01","2023-03-06 10:03:32","2023-03-18 15:58:26","2023-03-06 10:03:32","479-498","","3","17","","","","","","","","","","en","","","","","arXiv.org","","arXiv:1701.03444 [math]","","C:\Users\isido\Zotero\storage\WF8T4VEL\1701.03444.pdf","","ODE; randomized trapezodial","Mathematics - Numerical Analysis; 65C05, 65L05, 65L06, 65L20","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K96C2LFK","preprint","2020","Wu, Yue","A randomised trapezoidal quadrature","","","","","http://arxiv.org/abs/2011.15086","A randomised trapezoidal quadrature rule is proposed for continuous functions which enjoys less regularity than commonly required. Indeed, we consider functions in some fractional Sobolev space. Various error bounds for this randomised rule are established while an error bound for classical trapezoidal quadrature is obtained for comparison. The randomised trapezoidal quadrature rule is shown to improve the order of convergence by half.","2020-12-02","2023-03-06 10:07:59","2023-03-18 15:25:17","2023-03-06 10:07:59","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2011.15086 [cs, math]","","C:\Users\isido\Zotero\storage\ZZ4A2GLQ\Wu - 2020 - A randomised trapezoidal quadrature.pdf","","integration; randomized trapezodial","Mathematics - Probability; Mathematics - Numerical Analysis; 65C05, 65D30","","","","","","","","","","","","","","","","","","","arXiv:2011.15086","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q24CAJ5X","preprint","2019","Grant, Cameron; Talvila, Erik","Elementary numerical methods for double integrals","","","","","http://arxiv.org/abs/1905.05805","Approximations to the integral $\int_a^b\int_c^d f(x,y)\,dy\,dx$ are obtained under the assumption that the partial derivatives of the integrand are in an $L^p$ space, for some $1\leq p\leq\infty$. We assume ${\lVert f_{xy}\rVert}_p$ is bounded (integration over $[a,b]\times[c,d]$), assume ${\lVert f_x(\cdot,c)\rVert}_p$ and ${\lVert f_x(\cdot,d)\rVert}_p$ are bounded (integration over $[a,b]$), and assume ${\lVert f_y(a,\cdot)\rVert}_p$ and ${\lVert f_y(b,\cdot)\rVert}_p$ are bounded (integration over $[c,d]$). The methods are elementary, using only integration by parts and H\""older's inequality. Versions of the trapezoidal rule, composite trapezoidal rule, midpoint rule and composite midpoint rule are given, with error estimates in terms of the above norms.","2019-05-14","2023-03-06 10:13:45","2023-03-18 15:02:57","2023-03-06 10:13:45","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1905.05805 [math]","","C:\Users\isido\Zotero\storage\C2T9FPFP\Grant en Talvila - 2019 - Elementary numerical methods for double integrals.pdf","","integration","Mathematics - Numerical Analysis; Primary 41A55, 65D30. Secondary 26D15","","","","","","","","","","","","","","","","","","","arXiv:1905.05805","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TXGACHGR","preprint","2018","Brune, Carl R.","Derivative Corrections to the Trapezoidal Rule","","","","","http://arxiv.org/abs/1808.04743","Extensions to the trapezoidal rule using derivative information are studied for periodic integrands and integrals along the entire real line. Integrands which are analytic within a half plane or within a strip containing the path of integration are considered. Derivative-free error bounds are obtained. Alternative approaches to including derivative information are discussed.","2018-08-14","2023-03-06 10:17:12","2023-03-18 15:01:46","2023-03-06 10:17:12","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1808.04743 [math]","","C:\Users\isido\Zotero\storage\ADTJQB7R\Brune - 2018 - Derivative Corrections to the Trapezoidal Rule.pdf","","integration","Mathematics - Numerical Analysis; 65D32","","","","","","","","","","","","","","","","","","","arXiv:1808.04743","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2KTSR8W","preprint","2012","Talvila, Erik; Wiersma, Matthew","Simple derivation of basic quadrature formulas","","","","","http://arxiv.org/abs/1202.0249","Simple proofs of the midpoint, trapezoidal and Simpson’s rules are proved for numerical integration on a compact interval. The integrand is assumed to be twice continuously diﬀerentiable for the midpoint and trapezoidal rules, and to be four times continuously diﬀerentiable for Simpson’s rule. Errors are estimated in terms of the uniform norm of second or fourth derivatives of the integrand. The proof uses only integration by parts, applied to the second or fourth derivative of the integrand, multiplied by an appropriate polynomial or piecewise polynomial function. A corrected trapezoidal rule that includes the ﬁrst derivative of the integrand at the endpoints of the integration interval is also proved in this manner, the coeﬃcient in the error estimate being smaller than for the midpoint and trapezoidal rules. The proofs are suitable for presentation in a calculus or elementary numerical analysis class. Several student projects are suggested.","2012-02-01","2023-03-06 11:42:52","2023-03-18 15:01:03","2023-03-06 11:42:52","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1202.0249 [math]","","C:\Users\isido\Zotero\storage\XSLY6YKE\Talvila en Wiersma - 2012 - Simple derivation of basic quadrature formulas.pdf","","integration","Mathematics - Numerical Analysis; 26D15, 65D30, 26A42, 41A55, 65D32; Mathematics - Classical Analysis and ODEs","","","","","","","","","","","","","","","","","","","arXiv:1202.0249","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AW26Z694","journalArticle","2019","Khan, Md. Mamun-Ur-Rashid","Analytical Solution of Van Der Pol’s Differential Equation Using Homotopy Perturbation Method","Journal of Applied Mathematics and Physics","","2327-4352, 2327-4379","10.4236/jamp.2019.71001","http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jamp.2019.71001","In this research work, Homotopy perturbation method (HPM) is applied to find the approximate solution of the Van der Pol Differential equation (VDPDE), which is a well-known nonlinear ODE. Firstly, the approximate solution of Van Der Pol equation is developed using Dirichlet boundary conditions. Then a comparison between the present results and previously published results is presented and a good agreement is observed. Finally, HPM method is applied to find the approximate solution of VDPDE with Robin and Neumann boundary conditions.","2019","2023-03-07 13:05:03","2023-03-18 14:59:59","2023-03-07 13:05:03","1-12","","01","07","","JAMP","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\S442NHWI\Khan - 2019 - Analytical Solution of Van Der Pol’s Differential .pdf","","ODE; Van Der Pol ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8QGLSEV","journalArticle","2013","Soomro, Abdul Sattar; Tularam, Gurudeo Anand; Shaikh, Muhammad Mujtaba","A Comparison of Numerical Methods for Solving the Unforced Van Der Pol’s Equation","","","","","","Due to the advancements in the field of computational mathematics, numerical methods are most widely being utilized to solve the equations arising in the fields of applied medical sciences, engineering and technology. In this paper, the numerical solutions of an important equation of applied dynamics: namely, the Unforced Van der Pol’s Equation (UFVDP) are obtained by reducing it to a system of two first order differential equations. The objective of this work is to investigate the efficiency of improved Heun’s (IH) method against the classical Runge-Kutta (RK4) and Mid-point (MP) methods for UFVDP equation. For analysis of accuracy, the Poincare-Lindstedt method has been used as a comparison criterion and respective error bounds are obtained. The results show that the popular RK4 method retains its better accuracy than other methods used for comparison.","2013","2023-03-07 13:38:13","2023-03-18 14:59:53","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\G8ZFGQ6S\Soomro e.a. - 2013 - A Comparison of Numerical Methods for Solving the .pdf","","ODE; Van Der Pol ODE; perturbation techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G6DWZHQ3","journalArticle","2019","Kritzer, Peter; Kuo, Frances Y.; Nuyens, Dirk; Ullrich, Mario","Lattice rules with random $n$ achieve nearly the optimal $\mathcal{O}(n^{-\alpha-1/2})$ error independently of the dimension","Journal of Approximation Theory","","00219045","10.1016/j.jat.2018.09.011","http://arxiv.org/abs/1706.04502","We analyze a new random algorithm for numerical integration of $d$-variate functions over $[0,1]^d$ from a weighted Sobolev space with dominating mixed smoothness $\alpha\ge 0$ and product weights $1\ge\gamma_1\ge\gamma_2\ge\cdots>0$, where the functions are continuous and periodic when $\alpha>1/2$. The algorithm is based on rank-$1$ lattice rules with a random number of points~$n$. For the case $\alpha>1/2$, we prove that the algorithm achieves almost the optimal order of convergence of $\mathcal{O}(n^{-\alpha-1/2})$, where the implied constant is independent of the dimension~$d$ if the weights satisfy $\sum_{j=1}^\infty \gamma_j^{1/\alpha}<\infty$. The same rate of convergence holds for the more general case $\alpha>0$ by adding a random shift to the lattice rule with random $n$. This shows, in particular, that the exponent of strong tractability in the randomized setting equals $1/(\alpha+1/2)$, if the weights decay fast enough. We obtain a lower bound to indicate that our results are essentially optimal. This paper is a significant advancement over previous related works with respect to the potential for implementation and the independence of error bounds on the problem dimension. Other known algorithms which achieve the optimal error bounds, such as those based on Frolov's method, are very difficult to implement especially in high dimensions. Here we adapt a lesser-known randomization technique introduced by Bakhvalov in 1961. This algorithm is based on rank-$1$ lattice rules which are very easy to implement given the integer generating vectors. A simple probabilistic approach can be used to obtain suitable generating vectors.","2019-04","2023-03-14 19:17:22","2023-03-18 14:59:41","2023-03-14 19:17:22","96-113","","","240","","Journal of Approximation Theory","","","","","","","","en","","","","","arXiv.org","","arXiv:1706.04502 [math]","","C:\Users\isido\Zotero\storage\85WBUZK2\Kritzer e.a. - 2019 - Lattice rules with random $n$ achieve nearly the o.pdf","","integration; randomized trapezodial","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2YAVL8Y","preprint","2006","Kacewicz, Boleslaw","Almost Optimal Solution of Initial-Value Problems by Randomized and Quantum Algorithms","","","","","http://arxiv.org/abs/quant-ph/0510045","We establish essentially optimal bounds on the complexity of initial-value problems in the randomized and quantum settings. For this purpose we define a sequence of new algorithms whose error/cost properties improve from step to step. These algorithms yield new upper complexity bounds, which differ from known lower bounds by only an arbitrarily small positive parameter in the exponent, and a logarithmic factor. In both the randomized and quantum settings, initial-value problems turn out to be essentially as difficult as scalar integration.","2006-10-09","2023-03-18 14:51:38","2023-03-18 14:57:57","2023-03-18 14:51:38","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:quant-ph/0510045","","C:\Users\isido\Zotero\storage\5U78U57J\Kacewicz - 2006 - Almost Optimal Solution of Initial-Value Problems .pdf","","ODE; randomized trapezodial","Quantum Physics","","","","","","","","","","","","","","","","","","","arXiv:quant-ph/0510045","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8ZRQ62Y","journalArticle","1999","Coulibaly, Ibrahim; Lécot, Christian","A quasi-randomized Runge-Kutta method","Mathematics of Computation","","0025-5718","10.1090/S0025-5718-99-01056-X","http://www.ams.org/journal-getitem?pii=S0025-5718-99-01056-X","We analyze a quasi-Monte Carlo method to solve the initial-value problem for a system of diﬀerential equations y (t) = f (t, y(t)). The function f is smooth in y and we suppose that f and Dy1f are of bounded variation in t and that Dy2f is bounded in a neighborhood of the graph of the solution. The method is akin to the second order Heun method of the Runge-Kutta family. It uses a quasi-Monte Carlo estimate of integrals. The error bound involves the square of the step size as well as the discrepancy of the point set used for quasi-Monte Carlo approximation. Numerical experiments show that the quasi-randomized method outperforms a recently proposed randomized numerical method.","1999-04-01","2023-03-06 12:54:54","2023-03-18 14:57:39","2023-03-06 12:54:54","651-660","","226","68","","Math. Comp.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\LQ4QYKR2\Coulibaly en Lécot - 1999 - A quasi-randomized Runge-Kutta method.pdf","","ODE; randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65EP6SI2","webpage","","","Stiff Differential Equations","","","","","https://www.mathworks.com/company/newsletters/articles/stiff-differential-equations.html","Stiffness is a subtle, difficult, and important - concept in the numerical solution of ordinary differential equations.","","2023-03-07 10:18:54","2023-03-18 14:28:55","2023-03-07 10:18:54","","","","","","","","","","","","","","en","","","","","","","","","C:\Users\isido\Zotero\storage\674H6FG6\stiff-differential-equations.html","","ODE; stiff ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"286TPP28","encyclopediaArticle","2023","","Perturbation theory","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Perturbation_theory&oldid=1131120602","In mathematics and applied mathematics, perturbation theory comprises methods for finding an approximate solution to a problem, by starting from the exact solution of a related, simpler problem. A critical feature of the technique is a middle step that breaks the problem into ""solvable"" and ""perturbative"" parts.  In perturbation theory, the solution is expressed as a power series in a small parameter                         ε                 {\displaystyle \varepsilon }   . The first term is the known solution to the solvable problem.  Successive terms in the series at higher powers of                         ε                 {\displaystyle \varepsilon }    usually become smaller.  An approximate 'perturbation solution' is obtained by truncating the series, usually by keeping only the first two terms, the solution to the known problem and the 'first order' perturbation correction. Perturbation theory is used in a wide range of fields, and reaches its most sophisticated and advanced forms in quantum field theory. Perturbation theory (quantum mechanics) describes the use of this method in quantum mechanics. The field in general remains actively and heavily researched across multiple disciplines.","2023-01-02","2023-03-07 12:35:07","2023-03-18 14:28:41","2023-03-07 12:35:07","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1131120602","","C:\Users\isido\Zotero\storage\Y4XGJLUT\Perturbation_theory.html","","perturbation techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IMBUXMUA","journalArticle","","Tzitzouris, James A","Notes on Perturbation Techniques for ODEs","","","","","","","","2023-03-08 11:41:51","2023-03-18 14:25:12","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\DYKBRWX6\Tzitzouris - Notes on Perturbation Techniques for ODEs.pdf","","perturbation techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Y3CMITE","book","2015","Kuehn, Christian","Multiple Time Scale Dynamics","","978-3-319-12315-8 978-3-319-12316-5","","","https://link.springer.com/10.1007/978-3-319-12316-5","This book aims to provide an introduction to dynamical systems with multiple time scales. As in any overview book, several topics are covered only quite briefly. My aim was to focus on topics that seem to be less available in introductory form. However, I try to give a global view of the subject by covering a broad spectrum of ideas and tools. The detailed bibliography aims to direct the reader to further topics. To explain it with a simple metaphor: using this book should make you more familiar with a country’s map, culture, and main attractions rather than imparting details of every street in just one city. Both things are useful at times. The term “multiple time scale dynamics” is rather modern. The subject and many of its core ideas are much older. For example, “singular perturbation theory” or “multiscale systems” encompass a larger variety of topics than what I present here. On the one hand, no serious multidimensional spatial problems are considered in this book. Furthermore, there are many singularly perturbed problems that have very little to do with dynamical systems. On the other hand, ordinary differential equations (ODEs) with multiple time scales already contain motivation, technique, and intuition for more complicated scenarios. Classical singular perturbation theory for multiple time scale systems provides many asymptotic techniques centered on series expansions, matching, and averaging. These methods are still indispensable today, and this book gives an overview of them. However, the details are not covered, since many excellent introductory texts are available. The last two decades have brought major additional progress with a particular focus on geometric ideas as well as powerful numerical algorithms. A major goal of this book was to merge several viewpoints with a wide variety of different techniques into a unified framework. Another reason for the broad choice of topics was to make it easier for students and researchers new to the field to get a much quicker overview. Again, I would like to warn the reader that this book is obviously not a mathematical monograph aiming at a complete treatment of the entire field of multiple time scales. Some readers, particularly students, may wonder how a book of over 700 pages can be only an “introduction,” but let me point out that most chapters, and even many five-page sections, in this book in fact deserve their own mathematical monograph of 300 pages or more. A few such books have vi PREFACE been written, while many exist only in a distant, happier future. I encourage my colleagues working in the field—you know who you are—to begin work on such projects and fill in the missing mathematical details that I decided to leave out in order to make the subject much more accessible to beginners. Despite the simplifications, there seem to be several advantages of the style of presentation. The great diversity of the subject, ranging from mathematical theory in dynamics, analysis, geometry, topology, stochastics, and numerics to virtually all fields in science and engineering applications, easily becomes visible. The unity and interconnections between different approaches to multiple time scale problems can be identified much more readily. Also, scientists with particular applications in mind should find it easier to spot many potential tools right away, while a “purer” mathematician can use this text as a source book of open mathematical problems. The target audience of the book is senior undergraduates, graduate students, as well as researchers interested in using the theory of multiple time scale dynamics in nonlinear science, either from a theoretical or a mathematical modeling perspective. Section 1.1provides a more detailed guide to the book. Now I have the pleasure of thanking several colleagues, collaborators, and institutions that have helped to get this book started, keep it on track, and eventually push it over the finish line. First and foremost, I would like to thank my thesis adviser, John Guckenheimer, for introducing me to the field during my time as a graduate student. Undoubtedly, he shaped my view of the field, and without his support and encouragement, I would never have attempted to undertake a book project on multiple time scale systems. Important influences on this book during my postdoctoral years have come from my colleagues Thilo Gross, Peter Szmolyan, Nils Berglund, and Barbara Gentz. Thilo helped me to form bridges from multiscale dynamics to such seemingly distant areas as ecology, networks, systems biology, and statistical physics. I would like to thank Peter for sharing his tremendous insights into all aspects of geometric multiscale dynamics. Nils and Barbara have been constant sources of inspiration on everything stochastic. Although it is clear that I am responsible for all potential errors that may remain within this version, I would like to thank several colleagues who responded with valuable feedback—alerting me to anything from tiny typos to blatant blunders—in various draft versions of this book: Nils Berglund, Alan Champneys, Hayato Chiba, Mike Cortez, Peter De Maesschalck, John Guckenheimer, Pavel Gurevich, Annalisa Iuorio, Mike Jeffrey, Hans Kaper, Daniel Karrasch, Chris Jones, Ilona Kosiuk, Steven Lade, Gabriel Lord, Anatoly Neishtadt, Clare Perryman, Sofia Piltz, Nikola Popovic, Jens Rademacher, Martin Rasmussen, Martin Riedler, Stephen Schecter, Jan Sieber, Eric Siero, Peter Szmolyan, Frits Veerman, Martin Wechselberger, and Antonios Zagaris. Furthermore, I would like to thank the production staff at Springer for the handling of my manuscript. In particular, Achi Dosanjh has been extremely important and tremendously helpful in leading the entire editorial process. Regarding the formatting of the book, I would also like to thank Yuri Kuznetsov PREFACE vii who shared his LATEX book formatting preamble with me, from which I took some inspiration for the format of this book. Several anonymous referees also provided very valuable feedback, which helped to improve the book. During the writing of this book I have also benefited from the generous hospitality and financial support of various institutions, including Cornell University, the Max Planck Institute for Physics of Complex Systems, and the Vienna University of Technology. Furthermore, I would like to thank the Austrian Academy of Sciences for support via the “Austrian Programme for Advanced Research and Technology” and the European Commission for support via a “Marie Curie International Reintegration Grant.” The final push of this project has been supported through the program “Oberwolfach Leibniz Fellows” by the Mathematisches Forschungsinstitut Oberwolfach. Although it is obvious for an overview book on a topic, let me stress that I do not make any claims to novelty of its content. I have tried to summarize and condense the extensive literature on multiple time scale dynamics into a more accessible expository format. However, I can certainly say that during the writing of this book, several very natural new ideas arose. I hope that the research-oriented reader will have a similar experience and that this book will provide a starting point for new ideas in multiscale dynamics.","2015","2023-03-08 14:04:36","2023-08-01 13:48:59","2023-03-08 14:04:36","","","","191","","","","Applied Mathematical Sciences","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-3-319-12316-5","","C:\Users\isido\Zotero\storage\KEKJNI5S\Kuehn - 2015 - Multiple Time Scale Dynamics.pdf","","perturbation techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SED9FB9T","document","","","intro perturbation theory","","","","","","First, let me say hello and welcome to the subject of perturbation methods. For those who may be unfamiliar with the topic, the title can be confusing. The first time I became aware of this was during a family reunion when someone asked what I did as a mathematician. This is not an easy question to answer, but I started by describing how a certain segment of the applied mathematics community was interested in problems that arise from physical problems. Examples such as water waves, sound propagation, and the aerodynamics of airplanes were discussed. The difficulty of solving such problems was also described in exaggerated detail. Next came the part about how one generally ends up using a computer to actually find the solution. At this point I editorialized on the limitations of computer solutions and why it is important to derive, if at all possible, accurate approximations of the solution. This lead naturally to the mentioning of asymptotics and perturbation methods. These terms ended the conversation because I was unprepared for their reactions. They were not sure exactly what asymptotics meant, but they were quite perplexed about perturbation methods. I tried, unsuccessfully, to explain what it means, but it was not until sometime later that I realized the difficulty. For them, as in Webster's Collegiate Dictionary, the first two meanings for the word perturb are ""to disturb greatly in mind (disquiet); to throw into confusion (disorder)."" Although a cynic might suggest this is indeed appropriate for the subject, the intent is exactly the opposite. (For a related comment, see Exercise 3.4.1(d).) In a nutshell, this book serves as an introduction into how to systematically construct an approximation of the solution of a problem that i viii Preface otherwise intractable. The methods all rely on there being a parameter in the problem that is relatively small. Such a situation is relatively common in applications, and this is one of the reasons that perturbation methods are a cornerstone of applied mathematics. One of the other cornerstones is scientific computing, and it is interesting that the two subjects have grown up together. However, this is not unexpected given their respective capabilities. When using a computer, one is capable of solving problems that are nonlinear, inhomogeneous, and multidimensional. Moreover, it is possible to achieve very high accuracy. The drawbacks are that computer solutions do not provide much insight into the physics of the problem (particularly for those who do not have access to the appropriate software or computer), and there is always the question as to whether or not the computed solution is correct. On the other hand, perturbation methods are also capable of dealing with nonlinear, inhomogeneous, and multidimensional problems (although not to the same extent as computer-generated solutions). The principal objective when using perturbation methods, at least as far as the author is concerned, is to provide a reasonably accurate expression for the solution. By doing this one is able to derive an understanding of the physics of the problem. Also, one can use the result, in conjunction with the original problem, to obtain more efficient numerical procedures for computing the solution. The methods covered in the text vary widely in their applicability. The first chapter introduces the fundamental ideas underlying asymptotic approximations. This includes their use in constructing approximate solutions of transcendental equations as well as differential equations. In the second chapter, matched asymptotic expansions are used to analyze problems with layers. Chapter 3 describes a method for dealing with problems with more than one time scale. In Chapter 4, the WKB method for analyzing linear singular perturbation problems is developed, while in Chapter 5 a method for dealing with materials containing disparate spatial scales (e.g., microscopic versus macroscopic) is discussed. The last chapter examines the topics of multiple solutions and stability. The mathematical prerequisites for this text include a basic background in differential equations and advanced calculus. In terms of difficulty, the chapters are written so that the first sections are either elementary or intermediate, while the later sections are somewhat more advanced. Also, the ideas developed in each chapter are applied to a spectrum of problems, including ordinary differential equations, partial differential equations, and difference equations. Scattered through the exercises are applications to integral equations, integra-differential equations, differential-difference equations, and delay equations. What will not be found is an in-depth discussion of the theory underlying the methods. This aspect of the subject is important, and references to the more theoretical work in the area are given in each chapter Preface ix The exercises in each section vary in their complexity. In addition to the more standard textbook problems, an attempt has been made to include problems from the research literature. The latter are intended to provide a window into the wide range of areas that use perturbation methods. Solutions to some of the exercises are available from the author's home page located at http://www.math.rpi.edu/""'holmes. Also located there is an errata list. Those who may want to make a contribution to one of these files, or have suggestions about the text, can reach the author at holmes@rpi.edu. I would like to express my gratitude to the many students who took my course in perturbation methods at Rensselaer. They helped me immeasurably in understanding the subject and provided much needed encouragement to write this book. It is a pleasure to acknowledge the suggestions of Jon Bell, Ash Kapila, and Bob O'Malley, who read early versions of the manuscript. I would also like to thank Julian Cole, who first introduced me to perturbation methods and is still, to this day, showing me what the subject is about.","","2023-03-08 17:07:46","2023-08-01 13:47:31","","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\A7D8KXBJ\[Texts in Applied Mathematics №20] Mark H. Holmes (auth.) - Introduction to Perturbation Methods (1995, Springer) [10.1007_978-1-4612-5347-1] - libgen.li.pdf","","perturbation techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQKMS4BA","webpage","2022","Wijgerden, Jeroen van","Tail recursion for branching problems","","","","","https://jeroenvanwijgerden.me/post/recursion-1/","Recently one of my clients asked me for help in learning about graphs. As graphs are a particular favorite topic of mine I took on this challenge with zeal and alacrity. In our ensuing sessions we touched upon some interesting topics regarding recursion, which inspired me to write this article. I assume you, dear reader, are already somewhat familiar with recursion. Nevertheless, I begin this article with a brief recap of a classic recursive solution: calculating a factorial. Then I introduce the what and why of tail recursion and how to modify regular recursion to tail recursion. The meat of this article is a discussion of how to use regular recursion and tail recursion to solve branching problems. The particular branching problem I use as an example is finding paths in a tree. I discuss not one but two different approaches to finding paths in trees. The first is more flexible, the second is more performant.","2022-02-16","2023-03-15 10:54:40","2023-08-01 13:46:26","2023-03-15 10:54:40","","","","","","","","","","","","","","en","","","","","","","Section: post","","C:\Users\isido\Zotero\storage\4BTFZQHH\recursion-1.html","","tail recursion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CB6RZ9HA","preprint","2013","Christopoulos, Demetris T.","Polynomial regression using trapezoidal rule for computing Legendre coefficients","","","","","http://arxiv.org/abs/1311.7525","We are presenting a method for computing the Fourier coeﬃcients of a given polynomial regression by using the trapezoidal rule for numerical integration. As function basis we use the orthogonal Legendre polynomials. The results are accurate and stable compared to Forsythe’s method.","2013-11-29","2023-03-06 11:42:06","2023-03-06 11:42:07","2023-03-06 11:42:06","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1311.7525 [math, stat]","","C:\Users\isido\Zotero\storage\MNCK7RST\Christopoulos - 2013 - Polynomial regression using trapezoidal rule for c.pdf","","","Mathematics - Numerical Analysis; Statistics - Computation; Primary 62J05, Secondary 65D99","","","","","","","","","","","","","","","","","","","arXiv:1311.7525","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGIU4CSX","encyclopediaArticle","2022","","Hardware acceleration","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Hardware_acceleration&oldid=1098931508","Hardware acceleration is the use of computer hardware designed to perform specific functions more efficiently when compared to software running on a general-purpose central processing unit (CPU). Any transformation of data that can be calculated in software running on a generic CPU can also be calculated in custom-made hardware, or in some mix of both. To perform computing tasks more quickly (or better in some other way), generally one can invest time and money in improving the software, improving the hardware, or both. There are various approaches with advantages and disadvantages in terms of decreased latency, increased throughput and reduced energy consumption. Typical advantages of focusing on software may include more rapid development, lower non-recurring engineering costs, heightened portability, and ease of updating features or patching bugs, at the cost of overhead to compute general operations. Advantages of focusing on hardware may include speedup, reduced power consumption, lower latency, increased parallelism and bandwidth, and better utilization of area and functional components available on an integrated circuit; at the cost of lower ability to update designs once etched onto silicon and higher costs of functional verification, and times to market. In the hierarchy of digital computing systems ranging from general-purpose processors to fully customized hardware, there is a tradeoff between flexibility and efficiency, with efficiency increasing by orders of magnitude when any given application is implemented higher up that hierarchy. This hierarchy includes general-purpose processors such as CPUs, more specialized processors such as GPUs, fixed-function implemented on field-programmable gate arrays (FPGAs), and fixed-function implemented on application-specific integrated circuits (ASICs).Hardware acceleration is advantageous for performance, and practical when the functions are fixed so updates are not as needed as in software solutions. With the advent of reprogrammable logic devices such as FPGAs, the restriction of hardware acceleration to fully fixed algorithms has eased since 2010, allowing hardware acceleration to be applied to problem domains requiring modification to algorithms and processing control flow. The disadvantage however, is that in many open source projects, it requires proprietary libraries that not all vendors are keen to distribute or expose, making it difficult to integrate in such projects.","2022-07-18","2023-03-01 19:25:27","2023-03-01 19:25:27","2023-03-01 19:25:27","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1098931508","","C:\Users\isido\Zotero\storage\DYFFG8BP\Hardware_acceleration.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBW63VKY","webpage","","","parallelODEs.pdf","","","","","https://www.cs.usask.ca/~spiteri/M314/notes/parallelODEs.pdf","","","2023-03-18 20:28:55","2023-03-18 20:29:04","2023-01-25 10:18:45","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\NW56ESQ7\parallelODEs.pdf","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7JCGRS9","journalArticle","2017","Ullrich, Mario","A Monte Carlo method for integration of multivariate smooth functions","SIAM Journal on Numerical Analysis","","0036-1429, 1095-7170","10.1137/16M1075557","http://arxiv.org/abs/1604.06008","We study a Monte Carlo algorithm that is based on a speciﬁc (randomly shifted and dilated) lattice point set. The main result of this paper is that the mean squared error for a given compactly supported, square-integrable function is bounded by n−1/2 times the L2-norm of the Fourier transform outside a region around the origin, where n is the expected number of function evaluations. As corollaries we obtain the optimal order of convergence for functions from the Sobolev spaces Hps with isotropic, anisotropic or mixed smoothness with given compact support for all values of the parameters. If the region of integration is the unit cube, we obtain the same optimal orders for functions without boundary conditions. This proves, in particular, that the optimal order of convergence in the latter case is n−s−1/2 for p ≥ 2, which is, in contrast to the case of deterministic algorithms, independent of the dimension. This shows that Monte Carlo algorithms can improve the order by more than n−1/2 for a whole class of natural function spaces. Note that a similar result (for a diﬀerent class) was obtained by Heinrich et al. [13].","2017-01","2023-05-25 16:15:41","2023-08-03 19:19:23","2023-05-25 16:15:41","1188-1200","","3","55","","SIAM J. Numer. Anal.","","","","","","","","en","","","","","arXiv.org","","arXiv:1604.06008 [math]","","C:\Users\isido\Zotero\storage\WBZMRYM7\Ullrich - 2017 - A Monte Carlo method for integration of multivaria.pdf","","integration; monte carlo","65D30, 65C05, 68Q25, 46E35, 42B10; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V9YCFEND","journalArticle","2018","Daluiso, Roberto","Second Order Sensitivities in Linear or Constant Time","SSRN Electronic Journal","","1556-5068","10.2139/ssrn.3201559","https://www.ssrn.com/abstract=3201559","We analyse and compare methods to compute the full set of second order sensitivities of a Monte Carlo price in a time which is at most O(N · T ) where N is the number of inputs and T is the time required to compute the price. The new ones include the ﬁrst algorithm which achieves a complexity O(T ) and has acceptable (in fact very low) statistical uncertainties at least in one relevant test case.","2018","2023-05-24 16:49:50","2023-05-24 16:49:52","2023-05-24 16:49:50","","","","","","SSRN Journal","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\T5E6FRLG\Daluiso - 2018 - Second Order Sensitivities in Linear or Constant T.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRW7G2PA","preprint","2018","Elliott, Conal","The simple essence of automatic differentiation","","","","","http://arxiv.org/abs/1804.00746","Automatic diﬀerentiation (AD) in reverse mode (RAD) is a central component of deep learning and other uses of large-scale optimization. Commonly used RAD algorithms such as backpropagation, however, are complex and stateful, hindering deep understanding, improvement, and parallel execution. This paper develops a simple, generalized AD algorithm calculated from a simple, natural speciﬁcation. The general algorithm is then specialized by varying the representation of derivatives. In particular, applying well-known constructions to a naive representation yields two RAD algorithms that are far simpler than previously known. In contrast to commonly used RAD implementations, the algorithms deﬁned here involve no graphs, tapes, variables, partial derivatives, or mutation. They are inherently parallel-friendly, correct by construction, and usable directly from an existing programming language with no need for new data types or programming style, thanks to use of an AD-agnostic compiler plugin.","2018-10-02","2023-05-23 13:26:37","2023-05-23 13:26:38","2023-05-23 13:26:37","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1804.00746 [cs]","","C:\Users\isido\Zotero\storage\XCWM9PGQ\1804.00746.pdf","","","Computer Science - Programming Languages","","","","","","","","","","","","","","","","","","","arXiv:1804.00746","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCQC24AA","webpage","2023","Ph.D, Jacob Marks","How I Turned My Company’s Docs into a Searchable Database with OpenAI","Medium","","","","https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736","For the past six months, I’ve been working at series A startup Voxel51, a and creator of the open source computer vision toolkit FiftyOne. As a machine learning engineer and developer evangelist, my job is to listen to our open source community and bring them what they need — new features, integrations, tutorials, workshops, you name it. A few weeks ago, we added native support for vector search engines and text similarity queries to FiftyOne, so that users can find the most relevant images in their (often massive — containing millions or tens of millions of samples) datasets, via simple natural language queries. This put us in a curious position: it was now possible for people using open source FiftyOne to readily search datasets with natural language queries, but using our documentation still required traditional keyword search. We have a lot of documentation, which has its pros and cons. As a user myself, I sometimes find that given the sheer quantity of documentation, finding precisely what I’m looking for requires more time than I’d like.","2023-04-27","2023-05-23 10:20:07","2023-08-01 13:31:04","2023-05-23 10:20:07","","","","","","","","","","","","","","en","","","","","","","","","C:\Users\isido\Zotero\storage\CPBYHIF6\how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U82ZZXN2","preprint","2014","Mirza, Mehdi; Osindero, Simon","Conditional Generative Adversarial Nets","","","","","http://arxiv.org/abs/1411.1784","Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.","2014-11-06","2023-05-23 09:56:33","2023-08-03 19:19:42","2023-05-23 09:56:33","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1411.1784 [cs, stat]","","C:\Users\isido\Zotero\storage\C933QUW2\Mirza en Osindero - 2014 - Conditional Generative Adversarial Nets.pdf","","machine learning; neural networks","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1411.1784","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PGY9QT3V","preprint","2016","Radford, Alec; Metz, Luke; Chintala, Soumith","Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks","","","","","http://arxiv.org/abs/1511.06434","In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.","2016-01-07","2023-05-23 09:39:01","2023-08-03 19:19:50","2023-05-23 09:39:01","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1511.06434 [cs]","","C:\Users\isido\Zotero\storage\8NCTCL8G\Radford e.a. - 2016 - Unsupervised Representation Learning with Deep Con.pdf","","machine learning; neural networks","Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1511.06434","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3TXQFB2","preprint","2023","Yang, Ling; Zhang, Zhilong; Song, Yang; Hong, Shenda; Xu, Runsheng; Zhao, Yue; Zhang, Wentao; Cui, Bin; Yang, Ming-Hsuan","Diffusion Models: A Comprehensive Survey of Methods and Applications","","","","","http://arxiv.org/abs/2209.00796","Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language generation, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.","2023-03-23","2023-05-23 09:29:13","2023-08-03 19:19:59","2023-05-23 09:29:13","","","","","","","Diffusion Models","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2209.00796 [cs]","","C:\Users\isido\Zotero\storage\8VW927IA\Yang e.a. - 2023 - Diffusion Models A Comprehensive Survey of Method.pdf","","machine learning; neural networks","Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2209.00796","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTMPSBW8","preprint","2017","Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N.; Kaiser, Lukasz; Polosukhin, Illia","Attention Is All You Need","","","","","http://arxiv.org/abs/1706.03762","The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.","2017-12-05","2023-05-23 09:20:21","2023-08-03 19:20:08","2023-05-23 09:20:21","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1706.03762 [cs]","","C:\Users\isido\Zotero\storage\I5AYFTK6\1706.03762.pdf","","machine learning; neural networks","Computer Science - Computation and Language; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1706.03762","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WW8TX9DE","journalArticle","2023","Pu, Kai-Fang; Li, Hanlin; Lu, Hong-Liang; Pang, Long-Gang","Solving Schrodinger equations using physically constrained neural network","Chinese Physics C","","1674-1137, 2058-6132","10.1088/1674-1137/acc518","http://arxiv.org/abs/2303.03934","Deep neural network (DNN) and auto differentiation have been widely used in computational physics to solve variational problems. When DNN is used to represent the wave function to solve quantum many-body problems using variational optimization, various physical constraints have to be injected into the neural network by construction, to increase the data and learning efficiency. We build the unitary constraint to the variational wave function using a monotonic neural network to represent the Cumulative Distribution Function (CDF) $F(x) = \int_{-\infty}^{x} \psi^*\psi dx'$. Using this constrained neural network to represent the variational wave function, we solve Schrodinger equations using auto-differentiation and stochastic gradient descent (SGD), by minimizing the violation of the trial wave function $\psi(x)$ to the Schrodinger equation. For several classical problems in quantum mechanics, we obtain their ground state wave function and energy with very low errors. The method developed in the present paper may pave a new way in solving nuclear many body problems in the future.","2023-05-01","2023-05-22 19:11:09","2023-08-03 19:20:17","2023-05-22 19:11:09","054104","","5","47","","Chinese Phys. C","","","","","","","","en","","","","","arXiv.org","","arXiv:2303.03934 [nucl-th]","","C:\Users\isido\Zotero\storage\WD3BPTM7\Pu e.a. - 2023 - Solving Schrodinger equations using physically con.pdf","","neural networks; PDE","Nuclear Theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z6V5DD3D","preprint","2021","Yang, Keyu; Chen, Lu; Zeng, Zhihao; Gao, Yunjun","FastSGD: A Fast Compressed SGD Framework for Distributed Machine Learning","","","","","http://arxiv.org/abs/2112.04291","With the rapid increase of big data, distributed Machine Learning (ML) has been widely applied in training large-scale models. Stochastic Gradient Descent (SGD) is arguably the workhorse algorithm of ML. Distributed ML models trained by SGD involve large amounts of gradient communication, which limits the scalability of distributed ML. Thus, it is important to compress the gradients for reducing communication. In this paper, we propose FastSGD, a Fast compressed SGD framework for distributed ML. To achieve a high compression ratio at a low cost, FastSGD represents the gradients as key-value pairs, and compresses both the gradient keys and values in linear time complexity. For the gradient value compression, FastSGD ﬁrst uses a reciprocal mapper to transform original values into reciprocal values, and then, it utilizes a logarithm quantization to further reduce reciprocal values to small integers. Finally, FastSGD ﬁlters reduced gradient integers by a given threshold. For the gradient key compression, FastSGD provides an adaptive ﬁne-grained delta encoding method to store gradient keys with fewer bits. Extensive experiments on practical ML models and datasets demonstrate that FastSGD achieves the compression ratio up to 4 orders of magnitude, and accelerates the convergence time up to 8×, compared with state-of-the-art methods.","2021-12-08","2023-05-22 19:05:26","2023-08-03 19:20:35","2023-05-22 19:05:26","","","","","","","FastSGD","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2112.04291 [cs]","","C:\Users\isido\Zotero\storage\S8Q4SDYG\2112.04291.pdf","","gradient descent; optimization","Computer Science - Distributed, Parallel, and Cluster Computing; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2112.04291","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DFGUWP52","preprint","2023","Ghaffari, Alireza; Tahaei, Marzieh S.; Tayaranian, Mohammadreza; Asgharian, Masoud; Nia, Vahid Partovi","Is Integer Arithmetic Enough for Deep Learning Training?","","","","","http://arxiv.org/abs/2207.08822","The ever-increasing computational complexity of deep learning models makes their training and deployment difﬁcult on various cloud and edge platforms. Replacing ﬂoating-point arithmetic with low-bit integer arithmetic is a promising approach to save energy, memory footprint, and latency of deep learning models. As such, quantization has attracted the attention of researchers in recent years. However, using integer numbers to form a fully functional integer training pipeline including forward pass, back-propagation, and stochastic gradient descent is not studied in detail. Our empirical and mathematical results reveal that integer arithmetic seems to be enough to train deep learning models. Unlike recent proposals, instead of quantization, we directly switch the number representation of computations. Our novel training method forms a fully integer training pipeline that does not change the trajectory of the loss and accuracy compared to ﬂoating-point, nor does it need any special hyper-parameter tuning, distribution adjustment, or gradient clipping. Our experimental results show that our proposed method is effective in a wide variety of tasks such as classiﬁcation (including vision transformers), object detection, and semantic segmentation.","2023-01-04","2023-05-22 19:01:46","2023-08-03 19:20:49","2023-05-22 19:01:46","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2207.08822 [cs]","","C:\Users\isido\Zotero\storage\3P85UYGA\2207.08822.pdf","","gradient descent; machine learning; optimization","Computer Science - Computational Complexity; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2207.08822","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRJ7W6YJ","preprint","2023","Yan, Guangfeng; Li, Tan; Wu, Kui; Song, Linqi","Killing Two Birds with One Stone: Quantization Achieves Privacy in Distributed Learning","","","","","http://arxiv.org/abs/2304.13545","Communication efﬁciency and privacy protection are two critical issues in distributed machine learning. Existing methods tackle these two issues separately and may have a high implementation complexity that constrains their application in a resource-limited environment. We propose a comprehensive quantization-based solution that could simultaneously achieve communication efﬁciency and privacy protection, providing new insights into the correlated nature of communication and privacy. Speciﬁcally, we demonstrate the effectiveness of our proposed solutions in the distributed stochastic gradient descent (SGD) framework by adding binomial noise to the uniformly quantized gradients to reach the desired differential privacy level but with a minor sacriﬁce in communication efﬁciency. We theoretically capture the new trade-offs between communication, privacy, and learning performance.","2023-04-26","2023-05-22 18:53:39","2023-08-03 19:21:03","2023-05-22 18:53:39","","","","","","","Killing Two Birds with One Stone","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2304.13545 [cs]","","C:\Users\isido\Zotero\storage\AXSWITAR\Yan e.a. - 2023 - Killing Two Birds with One Stone Quantization Ach.pdf","","gradient descent; machine learning; optimization","Computer Science - Artificial Intelligence; Computer Science - Cryptography and Security; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2304.13545","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8EWKD5U","preprint","2022","Goda, Takashi; Kazashi, Yoshihito; Suzuki, Yuya","Randomizing the trapezoidal rule gives the optimal RMSE rate in Gaussian Sobolev spaces","","","","","http://arxiv.org/abs/2212.11476","Randomized quadratures for integrating functions in Sobolev spaces of order α ≥ 1, where the integrability condition is with respect to the Gaussian measure, are considered. In this function space, the optimal rate for the worst-case root-mean-squared error (RMSE) is established. Here, optimality is for a general class of quadratures, in which adaptive non-linear algorithms with a possibly varying number of function evaluations are also allowed. The optimal rate is given by showing matching bounds. First, a lower bound on the worst-case RMSE of O(n−α−1/2) is proven, where n denotes an upper bound on the expected number of function evaluations. It turns out that a suitably randomized trapezoidal rule attains this rate, up to a logarithmic factor. A practical error estimator for this trapezoidal rule is also presented. Numerical results support our theory.","2022-12-21","2023-05-22 18:37:49","2023-08-03 19:21:16","2023-05-22 18:37:49","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2212.11476 [cs, math]","","C:\Users\isido\Zotero\storage\6Z96NCM6\Goda e.a. - 2022 - Randomizing the trapezoidal rule gives the optimal.pdf","","integration; randomized trapezodial","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2212.11476","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CT7WBFB2","preprint","2018","Lin, Hongzhou; Mairal, Julien; Harchaoui, Zaid","Catalyst Acceleration for First-order Convex Optimization: from Theory to Practice","","","","","http://arxiv.org/abs/1712.05654","We introduce a generic scheme for accelerating gradient-based optimization methods in the sense of Nesterov. The approach, called Catalyst, builds upon the inexact accelerated proximal point algorithm for minimizing a convex objective function, and consists of approximately solving a sequence of well-chosen auxiliary problems, leading to faster convergence. One of the keys to achieve acceleration in theory and in practice is to solve these sub-problems with appropriate accuracy by using the right stopping criterion and the right warm-start strategy. We give practical guidelines to use Catalyst and present a comprehensive analysis of its global complexity. We show that Catalyst applies to a large class of algorithms, including gradient descent, block coordinate descent, incremental algorithms such as SAG, SAGA, SDCA, SVRG, MISO/Finito, and their proximal variants. For all of these methods, we establish faster rates using the Catalyst acceleration, for strongly convex and non-strongly convex objectives. We conclude with extensive experiments showing that acceleration is useful in practice, especially for ill-conditioned problems.","2018-06-19","2023-05-22 10:43:39","2023-08-03 19:21:28","2023-05-22 10:43:39","","","","","","","Catalyst Acceleration for First-order Convex Optimization","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1712.05654 [math, stat]","","C:\Users\isido\Zotero\storage\PPKCAMMC\1712.05654.pdf","","machine learning; optimization","Mathematics - Optimization and Control; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1712.05654","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NE73XC8U","journalArticle","2002","Stampfer, Erwin; Stadlober, Ernst","METHODS FOR ESTIMATING PRINCIPAL POINTS","Communications in Statistics - Simulation and Computation","","0361-0918, 1532-4141","10.1081/SAC-120003338","http://www.tandfonline.com/doi/abs/10.1081/SAC-120003338","Principal points of a distribution have been introduced by Flury (1) who tackled the problem of optimal grouping in multivariate data. In essence, principal points are the theoretical counterparts of cluster means obtained by a $k$-means clustering algorithm. There has been considerable effort to find efficient estimation procedures for principal points. It is well known that under certain conditions the $k$-means estimator is a consistent and asymptotically normal estimator of the population principal points. In this paper some material on principal points is reviewed and new algorithms for the estimation of principal points in univariate distributions (univariate principal points) are proposed. Additionally, the Bootstrap approach is applied to assess the variability of the suggested estimators.","2002-05-23","2023-05-17 16:28:25","2023-08-01 13:32:41","2023-05-17 16:28:25","261-277","","2","31","","Communications in Statistics - Simulation and Computation","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\7XXCGFY2\Stampfer en Stadlober - 2002 - METHODS FOR ESTIMATING PRINCIPAL POINTS.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PY59DVS","preprint","2018","Jankowiak, Martin; Obermeyer, Fritz","Pathwise Derivatives Beyond the Reparameterization Trick","","","","","http://arxiv.org/abs/1806.01851","We observe that gradients computed via the reparameterization trick are in direct correspondence with solutions of the transport equation in the formalism of optimal transport. We use this perspective to compute (approximate) pathwise gradients for probability distributions not directly amenable to the reparameterization trick: Gamma, Beta, and Dirichlet. We further observe that when the reparameterization trick is applied to the Choleskyfactorized multivariate Normal distribution, the resulting gradients are suboptimal in the sense of optimal transport. We derive the optimal gradients and show that they have reduced variance in a Gaussian Process regression task. We demonstrate with a variety of synthetic experiments and stochastic variational inference tasks that our pathwise gradients are competitive with other methods.","2018-07-05","2023-05-11 09:15:59","2023-08-03 19:21:37","2023-05-11 09:15:58","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1806.01851 [cs, stat]","","C:\Users\isido\Zotero\storage\E9PELC7L\Jankowiak en Obermeyer - 2018 - Pathwise Derivatives Beyond the Reparameterization.pdf","","machine learning","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1806.01851","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3KNYP4T","journalArticle","","Xie, Yantong; Zhou, Zhennan","Frozen Gaussian Sampling: A Mesh-free Monte Carlo Method For Approximating Semiclassical Schr¨odinger Equations","","","","","","In this paper, we develop a Monte Carlo algorithm named the Frozen Gaussian Sampling (FGS) to solve the semiclassical Schr¨odinger equation based on the frozen Gaussian approximation. Due to the highly oscillatory structure of the wave function, traditional mesh-based algorithms suﬀer from ”the curse of dimensionality”, which gives rise to more severe computational burden when the semiclassical parameter ε is small. The Frozen Gaussian sampling outperforms the existing algorithms in that it is mesh-free in computing the physical observables and is suitable for high dimensional problems. In this work, we provide detailed procedures to implement the FGS for both Gaussian and WKB initial data cases, where the sampling strategies on the phase space balance the need of variance reduction and sampling convenience. Moreover, we rigorously prove that, to reach a certain accuracy, the number of samples needed for the FGS is independent of the scaling parameter ε. Furthermore, the complexity of the FGS algorithm is of a sublinear scaling with respect to the microscopic degrees of freedom and, in particular, is insensitive to the dimension number. The performance of the FGS is validated through several typical numerical experiments, including simulating scattering by the barrier potential, formation of the caustics and computing the high-dimensional physical observables without mesh.","","2023-05-10 16:37:26","2023-08-03 19:21:42","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\DR2NE79L\Xie en Zhou - Frozen Gaussian Sampling A Mesh-free Monte Carlo .pdf","","monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDCHQVJK","book","2003","Øksendal, Bernt","Stochastic Differential Equations","","978-3-540-04758-2 978-3-642-14394-6","","","http://link.springer.com/10.1007/978-3-642-14394-6","These notes are based on a postgraduate course I gave on stochastic differential equations at Edinburgh University in the spring 1982. No previous knowledge about the subject was assumed, but the presentation is based on some background in measure theory. There are several reasons why one should learn more about stochastic differential equations: They have a wide range of applications outside mathematics, there are many fruitful connections to other mathematical disciplines and the subject has a rapidly developing life of its own as a fascinating research field with many interesting unanswered questions. Unfortunately most of the literature about stochastic differential equations seems to place so much emphasis on rigor and completenessthatitscares many nonexperts away. These notes are an attempt to approach the subject from the nonexpert point of view: Not knowing anything (except rumours, maybe) about a subject to start with, what would I like to know first of all? My answer would be: 1) In what situations does the subject arise? 2) What are its essential features? 3) What are the applications and the connections to other fields? I would not be so interested in the proof of the most general case, but rather in an easier proof of a special case, which may give just as much of the basic idea in the argument. And I would be willing to believe some basic results without proof (at first stage, anyway) in order to have time for some more basic applications. These notes reflect this point of view. Such an approach enables us to reach the highlights of the theory quicker and easier. Thus it is hoped that these notes may contribute to fill a gap in the existing literature. The course is meant to be an appetizer. If it succeeds in awaking further interest, the reader will have a large selection of excellent literature available for the study of the whole story. Some of this literature is listed at the back. xxvi xxviii In the introduction we state 6 problems where stochastic differential equations play an essential role in the solution. In Chapter II we introduce the basic mathematical notions needed for the mathematical model of some of these problems, leading to the concept of Ito integrals in Chapter III. In Chapter IV we develop the stochastic calculus (the Ito formula) and in Chapter V we use this to solve some stochastic differential equations, including the first two problems in the introduction. In Chapter VI we present a solution of the linear filtering problem (of which problem 3 is an example), using the stochastic calculus. Problem 4 is the Dirichlet problem. Although this is purely deterministic we outline in Chapters VII and VIII how the introduction of an associated Ito diffusion (i.e. solution of a stochastic differential equation) leads to a simple, intuitive and useful stochastic solution, which is the cornerstone of stochastic potential theory. Problem 5 is an optimal stopping problem. In Chapter IX we represent the state of a game at time t by an Ito diffusion and solve the corresponding optimal stopping problem. The solution involves potential theoretic notions, such as the generalized harmonic extension provided by the solution of the Dirichlet problem in Chapter VIII. Problem 6 is a stochastic version of F.P. Ramsey’s classical control problem from 1928. In Chapter X we formulate the general stochastic control problem in terms of stochastic differential equations, and we apply the results of Chapters VII and VIII to show that the problem can be reduced to solving the (deterministic) Hamilton-Jacobi-Bellman equation. As an illustration we solve a problem about optimal portfolio selection. After the course was first given in Edinburgh in 1982, revised and expanded versions were presented at Agder College, Kristiansand and University of Oslo. Every time about half of the audience have come from the applied section, the others being so-called “pure” mathematicians. This fruitful combination has created a broad variety of valuable comments, for which I am very grateful. I particularly wish to express my gratitude to K.K. Aase, L. Csink and A.M. Davie for many useful discussions. I wish to thank the Science and Engineering Research Council, U.K. and Norges Almenvitenskapelige Forskningsra  ̊d (NAVF), Norway for their financial support. And I am greatly indebted to Ingrid Skram, Agder College and Inger Prestbakken, University of Oslo for their excellent typing – and their patience with the innumerable changes in the manuscript during these two years.","2003","2023-05-08 11:23:45","2023-08-01 13:36:21","2023-05-08 11:23:45","","","","","","","","Universitext","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-3-642-14394-6","","C:\Users\isido\Zotero\storage\GCS3EXST\Øksendal - 2003 - Stochastic Differential Equations.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RHMY7FI","preprint","2023","Løvbak, Emil; Blondeel, Frédéric; Lee, Adam; Vanroye, Lander; Van Barel, Andreas; Samaey, Giovanni","Reversible random number generation for adjoint Monte Carlo simulation of the heat equation","","","","","http://arxiv.org/abs/2302.02778","In PDE-constrained optimization, one aims to ﬁnd design parameters that minimize some objective, subject to the satisfaction of a partial diﬀerential equation. A major challenges is computing gradients of the objective to the design parameters, as applying the chain rule requires computing the Jacobian of the design parameters to the PDE’s state. The adjoint method avoids this Jacobian by computing partial derivatives of a Lagrangian. Evaluating these derivatives requires the solution of a second PDE with the adjoint diﬀerential operator to the constraint, resulting in a backwards-in-time simulation.","2023-02-06","2023-05-08 06:51:05","2023-08-03 19:21:58","2023-05-08 06:51:05","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2302.02778 [cs, math]","","C:\Users\isido\Zotero\storage\I2IIHESY\Løvbak e.a. - 2023 - Reversible random number generation for adjoint Mo.pdf","","monte carlo; PDE","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2302.02778","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TX6AHPUR","forumPost","2017","Fauskanger, Thomas","What is the advantages of Wasserstein metric compared to Kullback-Leibler divergence?","Cross Validated","","","","https://stats.stackexchange.com/q/295617","","2017-08-02","2023-05-07 07:22:55","2023-05-07 07:23:07","2023-05-07 07:22:54","","","","","","","","","","","","","","","","Forum post","","","","","","","C:\Users\isido\Zotero\storage\NW2RJDMV\what-is-the-advantages-of-wasserstein-metric-compared-to-kullback-leibler-diverg.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3P8WBQIS","journalArticle","","Johnson, Rie; Zhang, Tong","Accelerating Stochastic Gradient Descent using Predictive Variance Reduction","","","","","","Stochastic gradient descent is popular for large scale optimization but has slow convergence asymptotically due to the inherent variance. To remedy this problem, we introduce an explicit variance reduction method for stochastic gradient descent which we call stochastic variance reduced gradient (SVRG). For smooth and strongly convex functions, we prove that this method enjoys the same fast convergence rate as those of stochastic dual coordinate ascent (SDCA) and Stochastic Average Gradient (SAG). However, our analysis is signiﬁcantly simpler and more intuitive. Moreover, unlike SDCA or SAG, our method does not require the storage of gradients, and thus is more easily applicable to complex problems such as some structured prediction problems and neural network learning.","","2023-05-03 10:20:33","2023-08-03 19:22:15","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\NTPY2NIB\Johnson en Zhang - Accelerating Stochastic Gradient Descent using Pre.pdf","","gradient descent; optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2U9QZ5U9","journalArticle","2009","Jentzen, A.; Neuenkirch, A.","A random Euler scheme for Carathéodory differential equations","Journal of Computational and Applied Mathematics","","03770427","10.1016/j.cam.2008.05.060","https://linkinghub.elsevier.com/retrieve/pii/S0377042708002136","We study a random Euler scheme for the approximation of Carathéodory differential equations and give a precise error analysis. In particular, we show that under weak assumptions, this approximation scheme obtains the same rate of convergence as the classical Monte–Carlo method for integration problems.","2009-02","2023-03-06 12:43:19","2023-05-02 13:32:58","2023-03-06 12:43:19","346-359","","1","224","","Journal of Computational and Applied Mathematics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\LFZQS9Q7\Jentzen en Neuenkirch - 2009 - A random Euler scheme for Carathéodory differentia.pdf","","monte carlo; ODE; MC ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPMCLENJ","preprint","2023","Miller, Bailey; Sawhney, Rohan; Crane, Keenan; Gkioulekas, Ioannis","Boundary Value Caching for Walk on Spheres","","","","","http://arxiv.org/abs/2302.11825","Grid-free Monte Carlo methods such as \emph{walk on spheres} can be used to solve elliptic partial differential equations without mesh generation or global solves. However, such methods independently estimate the solution at every point, and hence do not take advantage of the high spatial regularity of solutions to elliptic problems. We propose a fast caching strategy which first estimates solution values and derivatives at randomly sampled points along the boundary of the domain (or a local region of interest). These cached values then provide cheap, output-sensitive evaluation of the solution (or its gradient) at interior points, via a boundary integral formulation. Unlike classic boundary integral methods, our caching scheme introduces zero statistical bias and does not require a dense global solve. Moreover we can handle imperfect geometry (e.g., with self-intersections) and detailed boundary/source terms without repairing or resampling the boundary representation. Overall, our scheme is similar in spirit to \emph{virtual point light} methods from photorealistic rendering: it suppresses the typical salt-and-pepper noise characteristic of independent Monte Carlo estimates, while still retaining the many advantages of Monte Carlo solvers: progressive evaluation, trivial parallelization, geometric robustness, \etc{}\ We validate our approach using test problems from visual and geometric computing.","2023-02-23","2023-05-02 08:09:18","2023-08-03 19:22:28","2023-05-02 08:09:18","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2302.11825 [cs]","","C:\Users\isido\Zotero\storage\LX3BMITM\Miller e.a. - 2023 - Boundary Value Caching for Walk on Spheres.pdf","","Boundary value problems; PDE; walk on spheres","Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:2302.11825","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3LPGHXU","preprint","2023","Sawhney, Rohan; Miller, Bailey; Gkioulekas, Ioannis; Crane, Keenan","Walk on Stars: A Grid-Free Monte Carlo Method for PDEs with Neumann Boundary Conditions","","","","","http://arxiv.org/abs/2302.11815","Grid-free Monte Carlo methods based on the \emph{walk on spheres (WoS)} algorithm solve fundamental partial differential equations (PDEs) like the Poisson equation without discretizing the problem domain, nor approximating functions in a finite basis. Such methods hence avoid aliasing in the solution, and evade the many challenges of mesh generation. Yet for problems with complex geometry, practical grid-free methods have been largely limited to basic Dirichlet boundary conditions. This paper introduces the \emph{walk on stars (WoSt)} method, which solves linear elliptic PDEs with arbitrary mixed Neumann and Dirichlet boundary conditions. The key insight is that one can efficiently simulate reflecting Brownian motion (which models Neumann conditions) by replacing the balls used by WoS with \emph{star-shaped} domains; we identify such domains by locating the closest visible point on the geometric silhouette. Overall, WoSt retains many attractive features of other grid-free Monte Carlo methods, such as progressive evaluation, trivial parallel implementation, and logarithmic scaling relative to geometric complexity.","2023-02-23","2023-05-01 17:04:56","2023-08-03 19:22:40","2023-05-01 17:04:56","","","","","","","Walk on Stars","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2302.11815 [cs]","","C:\Users\isido\Zotero\storage\36DKDXFD\2302.11815.pdf","","PDE; walk on spheres","Computer Science - Graphics","","","","","","","","","","","","","","","","","","","arXiv:2302.11815","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGS69Z62","journalArticle","2021","El Filali Ech-Chafiq, Zineb; Lelong, Jérôme; Reghai, Adil","Automatic control variates for option pricing using neural networks","Monte Carlo Methods and Applications","","1569-3961, 0929-9629","10.1515/mcma-2020-2081","https://www.degruyter.com/document/doi/10.1515/mcma-2020-2081/html","Many pricing problems boil down to the computation of a high dimensional integral, which is usually estimated using Monte Carlo. In fact, the accuracy of a Monte Carlo estimator with M simulations is given by √σ . Meaning that its convergence is immune to the dimension of the problem. However, M this convergence can be relatively slow depending on the variance σ of the function to be integrated. To resolve such a problem, one would perform some variance reduction techniques such as importance sampling, stratiﬁcation, or control variates. In this paper, we will study two approaches for improving the convergence of Monte Carlo using Neural Networks. The ﬁrst approach relies on the fact that many high dimensional ﬁnancial problems are of low effective dimensions[15]. We expose a method to reduce the dimension of such problems in order to keep only the necessary variables. The integration can then be done using fast numerical integration techniques such as Gaussian quadrature. The second approach consists in building an automatic control variate using neural networks. We learn the function to be integrated (which incorporates the diffusion model plus the payoff function) in order to build a network that is highly correlated to it. As the network that we use can be integrated exactly, we can use it as a control variate.","2021-06-01","2023-04-10 14:45:27","2023-08-03 19:23:13","2023-04-10 14:45:27","91-104","","2","27","","","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\XVFWLNCP\El Filali Ech-Chafiq e.a. - 2021 - Automatic control variates for option pricing usin.pdf","","control variates; neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UT6UQJK7","encyclopediaArticle","2023","","Kullback–Leibler divergence","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Kullback%E2%80%93Leibler_divergence&oldid=1145664968","In mathematical statistics, the  Kullback–Leibler divergence (also called relative entropy and I-divergence), denoted                                    D                        KL                             (         P         ∥         Q         )                 {\displaystyle D_{\text{KL}}(P\parallel Q)}   , is a type of statistical distance: a measure of how one probability distribution P is different from a second, reference probability distribution Q. A simple interpretation of the KL divergence of P from Q is the expected excess surprise from using Q as a model when the actual distribution is P. While it is a distance, it is not a metric, the most familiar type of distance: it is not symmetric in the two distributions (in contrast to variation of information), and does not satisfy the triangle inequality. Instead, in terms of information geometry, it is a type of divergence, a generalization of squared distance, and for certain classes of distributions (notably an exponential family), it satisfies a generalized Pythagorean theorem (which applies to squared distances).In the simple case, a relative entropy of 0 indicates that the two distributions in question have identical quantities of information. Relative entropy is a nonnegative function of two distributions or measures. It has diverse applications, both theoretical, such as characterizing the relative (Shannon) entropy in information systems, randomness in continuous time-series, and information gain when comparing statistical models of inference; and practical, such as applied statistics, fluid mechanics, neuroscience and bioinformatics.","2023-03-20","2023-04-10 09:17:31","2023-04-10 09:17:31","2023-04-10 09:17:31","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1145664968","","C:\Users\isido\Zotero\storage\65MFQLXQ\Kullback–Leibler_divergence.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYGAZWE4","preprint","2017","Geeraert, Sébastien; Lehalle, Charles-Albert; Pearlmutter, Barak; Pironneau, Olivier; Reghai, Adil","Mini-symposium on automatic differentiation and its applications in the financial industry","","","","","http://arxiv.org/abs/1703.02311","Automatic diﬀerentiation has been involved for long in applied mathematics as an alternative to ﬁnite diﬀerence to improve the accuracy of numerical computation of derivatives. Each time a numerical minimization is involved, automatic diﬀerentiation can be used. In between formal derivation and standard numerical schemes, this approach is based on software solutions applying mechanically the chain rule formula to obtain an exact value for the desired derivative. It has a cost in memory and cpu consumption.","2017-06-07","2023-04-10 08:05:34","2023-04-10 08:11:02","2023-04-10 08:05:34","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1703.02311 [cs, q-fin]","","C:\Users\isido\Zotero\storage\2CWLCKI6\Geeraert e.a. - 2017 - Mini-symposium on automatic differentiation and it.pdf","","MC forex course","Quantitative Finance - Computational Finance; Mathematics - Numerical Analysis; Computer Science - Computational Engineering, Finance, and Science","","","","","","","","","","","","","","","","","","","arXiv:1703.02311","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8U4MXXK5","journalArticle","2019","Alfonsi, Aurélien; Corbetta, Jacopo; Jourdain, Benjamin","SAMPLING OF ONE-DIMENSIONAL PROBABILITY MEASURES IN THE CONVEX ORDER AND COMPUTATION OF ROBUST OPTION PRICE BOUNDS","International Journal of Theoretical and Applied Finance","","0219-0249, 1793-6322","10.1142/S021902491950002X","https://www.worldscientific.com/doi/abs/10.1142/S021902491950002X","For [Formula: see text] and [Formula: see text] two probability measures on the real line such that [Formula: see text] is smaller than [Formula: see text] in the convex order, this property is in general not preserved at the level of the empirical measures [Formula: see text] and [Formula: see text], where [Formula: see text] (resp., [Formula: see text]) are independent and identically distributed according to [Formula: see text] (resp., [Formula: see text]). We investigate modifications of [Formula: see text] (resp., [Formula: see text]) smaller than [Formula: see text] (resp., greater than [Formula: see text]) in the convex order and weakly converging to [Formula: see text] (resp., [Formula: see text]) as [Formula: see text]. According to  Kertz & Rösler(1992) , the set of probability measures on the real line with a finite first order moment is a complete lattice for the increasing and the decreasing convex orders. For [Formula: see text] and [Formula: see text] in this set, this enables us to define a probability measure [Formula: see text] (resp., [Formula: see text]) greater than [Formula: see text] (resp., smaller than [Formula: see text]) in the convex order. We give efficient algorithms permitting to compute [Formula: see text] and [Formula: see text] (and therefore [Formula: see text] and [Formula: see text]) when [Formula: see text] and [Formula: see text] have finite supports. Last, we illustrate by numerical experiments the resulting sampling methods that preserve the convex order and their application to approximate martingale optimal transport problems and in particular to calculate robust option price bounds.","2019-05","2023-04-10 08:10:03","2023-04-10 08:10:57","2023-04-10 08:10:03","1950002","","03","22","","Int. J. Theor. Appl. Finan.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\Y8WBIPGT\Alfonsi e.a. - 2019 - SAMPLING OF ONE-DIMENSIONAL PROBABILITY MEASURES I.pdf","","MC forex course","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJ5DA757","journalArticle","2001","Avellaneda, Marco; Buff, Robert; Friedman, Craig; Grandechamp, Nicolas; Kruk, Lukasz; Newman, Joshua","WEIGHTED MONTE CARLO: A NEW TECHNIQUE FOR CALIBRATING ASSET-PRICING MODELS","","","","","","A general approach for calibrating Monte Carlo models to the market prices of benchmark securities is presented. Starting from a given model for market dynamics (price di usion, rate di usion, etc.), the algorithm corrects price-misspeci cations and  nitesample e ects in the simulation by assigning \probability weights"" to the simulated paths. The choice of weights is done by minimizing the Kullback{Leibler relative entropy distance of the posterior measure to the empirical measure. The resulting ensemble prices the given set of benchmark instruments exactly or in the sense of least-squares. We discuss pricing and hedging in the context of these weighted Monte Carlo models. A signi cant reduction of variance is demonstrated theoretically as well as numerically. Concrete applications to the calibration of stochastic volatility models and term-structure models with up to 40 benchmark instruments are presented. The construction of implied volatility surfaces and forward-rate curves and the pricing and hedging of exotic options are investigated through several examples.","2001","2023-04-10 08:10:05","2023-08-01 13:37:04","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\KQ733JQX\Avellaneda e.a. - 2001 - WEIGHTED MONTE CARLO A NEW TECHNIQUE FOR CALIBRAT.pdf","","MC forex course","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJ2Z7KIN","preprint","2019","Guo, Gaoyue; Obloj, Jan","Computational Methods for Martingale Optimal Transport problems","","","","","http://arxiv.org/abs/1710.07911","We establish numerical methods for solving the martingale optimal transport problem (MOT) - a version of the classical optimal transport with an additional martingale constraint on transport's dynamics. We prove that the MOT value can be approximated using linear programming (LP) problems which result from a discretisation of the marginal distributions combined with a suitable relaxation of the martingale constraint. Specialising to dimension one, we provide bounds on the convergence rate of the above scheme. We also show a stability result under only partial specification of the marginal distributions. Finally, we specialise to a particular discretisation scheme which preserves the convex ordering and does not require the martingale relaxation. We introduce an entropic regularisation for the corresponding LP problem and detail the corresponding iterative Bregman projection. We also rewrite its dual problem as a minimisation problem without constraint and solve it by computing the concave envelope of scattered data.","2019-04-05","2023-04-10 07:46:39","2023-04-10 07:47:27","2023-04-10 07:46:39","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1710.07911 [math, q-fin]","","C:\Users\isido\Zotero\storage\WT6MVWSJ\Guo en Obloj - 2019 - Computational Methods for Martingale Optimal Trans.pdf","","MC forex course","Mathematics - Probability; Quantitative Finance - Computational Finance; Mathematics - Optimization and Control","","","","","","","","","","","","","","","","","","","arXiv:1710.07911","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAZI25NX","encyclopediaArticle","2023","","Bregman method","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Bregman_method&oldid=1140527005","The Bregman method is an iterative algorithm to solve certain convex optimization problems involving regularization. The original version is due to Lev M. Bregman, who published it in 1967.The algorithm is a row-action method accessing constraint functions one by one and the method is particularly suited for large optimization problems where constraints can be efficiently enumerated. The algorithm works particularly well for regularizers such as the                                    ℓ                        1                                     {\displaystyle \ell _{1}}    norm, where it converges very quickly because of an error cancellation effect.","2023-02-20","2023-04-09 13:50:30","2023-04-09 13:51:04","2023-04-09 13:50:30","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1140527005","","C:\Users\isido\Zotero\storage\BXBQ74F4\Bregman_method.html","","MC forex course","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BUYS2YEE","journalArticle","","Belkotain, M; Reghai, A","Iterative Bregman Projection for Monte Carlo Enhancement","","","","","","","","2023-04-09 13:32:53","2023-04-09 13:33:23","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\MMDYLN8T\Belkotain en Reghai - Iterative Bregman Projection for Monte Carlo Enhan.pdf","","MC forex course","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZVGV9S4","journalArticle","","Belkotain, Mehdi; Reghai, Adil","Iterative Bregman Projection for Monte Carlo Enhancement","","","","","","Given a set of $N$ trajectories, $S_{t_1}, \ldots S_{t_n}$, $$ \left[\begin{array}{lll} S_{T_1}\left(\omega_1\right) & \ldots & S_{T_n}\left(\omega_1\right) \\ S_{T_1}\left(\omega_2\right) & \ldots & S_{T_n}\left(\omega_2\right) \\ \cdot & \ldots & \\ S_{T_1}\left(\omega_N\right) & \ldots & S_{T_n}\left(\omega_N\right) \end{array}\right] $$ sampled at $t_1, \ldots, t_n$, the empirical density is, $\mu=\frac{1}{N} \sum_{i=1}^N \delta_{S_{T_1}, \ldots, S_{T_n}}$. This distribution is used to price and hedge derivative products. This set of scenariosaccumulates many types of discretisation errors. These can be linked to data quality input, to calibration algorithms, discretisation in time, interpolation in space or even dependent on the sample’s size N. All these errors contribute in errors that are detrimental to the quality of the final result. The classical approach to mitigate these errors is to work separately on each step of the sequence before the generation of the trajectories. Most of the time this increases significantly the computation time and notably the size sample in order to improve convergence and the final result. In the context of dynamic markets, where real time management is essential for trading desks, Also, there are important needs for financial engineers to perform back tests and forward tests to design the appropriate financial products. For the risk department and with regard to important set of risk metrics such those requested by the FRTB (Fundamental review of the trading Desk) it becomes essential to obtain good convergence with a minimum computation budget, in this case very little set of trajectories. It is also essential to dispose of a methodology that is agnostic to the designed model which can be different from one bank to the other and even sometimes from one department to another. The contribution of this paper is to introduce a feedback loop on the Monte Carlo paths. We do not revise all steps of the pricing algorithms, we rather concentrate on the resulting set of trajectories and smoothly transport them into a new version of trajectories which is more appropriate to fit the target.The proposed method acts directly on the generated sample and proposes a way to modify them in a smooth way in order to fit the market tradeables and importantly meet the non arbitrage condition i.e.  the preservation of the martingale property. It is a re-sampling approach which ensures that the finite set of scenarios fits perfectly the pricing constraints. We achieve this through an application of the iterative Bregman Projection algorithm.","","2023-04-09 13:32:55","2023-08-01 13:40:22","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\WF3R3AZN\Belkotain en Reghai - Iterative Bregman Projection for Monte Carlo Enhan.pdf","","MC forex course","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JS622X4H","journalArticle","2021","South Russian State Polytechnic University (Novocherkassk Polytechnic Institute); Abas, Abas Wisam Mahdi","The calculation of the solution of multidimensional integral equations with methods Monte Carlo and quasi-Monte Carlo","T-Comm","","20728735, 20728743","10.36724/2072-8735-2021-15-10-55-63","http://media-publisher.ru/wp-content/uploads/8-10-2021.pdf","The article considers an approach based on the random cubature method for solving both single and multidimensional singular integral equations, Volterra and Fredholm equations of the 1st kind, for ill-posed problems in the theory of integral equations, etc. A variant of the quasi-Monte Carlo method is studied. The integral in an integral equation is approximated using the traditional Monte Carlo method for calculating integrals. Multidimensional interpolation is applied on an arbitrary set of points. Examples of applying the method to a one-dimensional integral equation with a smooth kernel using both random and low-dispersed pseudo-random nodes are considered. A multidimensional linear integral equation with a polynomial kernel and a multidimensional nonlinear problem – the Hammerstein integral equation – are solved using the Newton method. The existence of several solutions is shown. Multidimensional integral equations of the first kind and their solution using regularization are considered. The Monte Carlo and quasi-Monte Carlo methods have not been used to solve such problems in the studied literature. The Lavrentiev regularization method was used, as well as random and pseudo-random nodes obtained using the Halton sequence. The problem of eigenvalues is solved. It is established that one of the best methods considered is the Leverrier-Faddeev method. The results of solving the problem for a different number of quadrature nodes are presented in the table. An approach based on parametric regularization of the core, an interpolation-projection method, and averaged adaptive densities are studied. The considered methods can be successfully applied in solving spatial boundary value problems for areas of complex shape. These approaches allow us to expand the range of problems in the theory of integral equations solved by Monte Carlo and quasi-Monte Carlo methods, since there are no restrictions on the value of the norm of the integral operator. A series of examples demonstrating the effectiveness of the method under study is considered.","2021","2023-03-26 12:43:10","2023-08-03 19:23:38","2023-03-26 12:43:10","55-63","","10","15","","T-Comm","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\AI7SS2YK\South Russian State Polytechnic University (Novocherkassk Polytechnic Institute) en Abas - 2021 - The calculation of the solution of multidimensiona.pdf","","integration; monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JP6VW4GB","journalArticle","2012","ZhiMin, Hong; ZaiZai, Yan; JianRui, Chen","Monte Carlo Method for Solving the Fredholm Integral Equations of the Second Kind","Transport Theory and Statistical Physics","","0041-1450, 1532-2424","10.1080/00411450.2012.695317","http://www.tandfonline.com/doi/abs/10.1080/00411450.2012.695317","This article is concerned with a numerical algorithm for solving approximate solutions of Fredholm integral equations of the second kind with random sampling. We use Simpson’s rule for solving integral equations, which yields a linear system. The Monte Carlo method, based on the simulation of a finite discrete Markov chain, is employed to solve this linear system. To show the efficiency of the method, we use numerical examples. Results obtained by the present method indicate that the method is an effective alternate method. Keywords Monte Carlo algorithms; Markov chain; Simpson’s formula; Fredholm integral equation","2012-12","2023-03-26 12:40:33","2023-08-03 19:23:48","2023-03-26 12:40:33","513-528","","7","41","","Transport Theory and Statistical Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\HJ9CJZP4\ZhiMin e.a. - 2012 - Monte Carlo Method for Solving the Fredholm Integr.pdf","","integral equations; monte carlo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXBWXNGU","book","2012","Hackbusch, Wolfgang","Integral equations: theory and numerical treatment","","978-3-0348-9947-5","","","","Book on Integral equations: theory and numerical treatment","2012","2023-03-26 12:28:24","2023-08-01 13:42:38","","","380","","","","","Integral equations","International series of numerical mathematics","120","","","Birkhäuser","Basel","eng","","","","","K10plus ISBN","","","","C:\Users\isido\Zotero\storage\UBYLDU35\[International Series of Numerical Mathematics №120] Wolfgang Hackbusch (auth.) - Integral Equations_ Theory and Numerical Treatment (1995, Birkhäuser) [10.1007_978-3-0348-9215-5] - libgen.li.pdf","","integral equations","","","","","","","","","","","","","","","","","","","","","1. softcover ed.]; [Reprint of the orig. 1st ed. 1995","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9XFVFQK","book","2008","Poli︠a︡nin, A. D.; Manzhirov, A. V.","Handbook of integral equations","","978-1-58488-507-8","","","","Integral equations are encountered in various fields of science and numerous applications (in elasticity, plasticity, heat and mass transfer, oscillation theory, fluid dynamics, filtration theory, electrostatics, electrodynamics, biomechanics, game theory, control, queuing theory, electrical engineering, economics, medicine, etc.). Exact (closed-form) solutions of integral equations play an important role in the proper understanding of qualitative features of many phenomena and processes in various areas of natural science. Lots of equations of physics, chemistry, and biology contain functions or parameters which are obtained from experiments and hence are not strictly fixed. Therefore, it is expedient to choose the structure of these functions so that it would be easier to analyze and solve the equation. As a possible selection criterion, one may adopt the requirement that the model integral equation admits a solution in a closed form. Exact solutions can be used to verify the consistency and estimate errors of various numerical, asymptotic, and approximate methods. More than 2,100 integral equations and their solutions are given in the first part of the book (Chapters 1–6). A lot of new exact solutions to linear and nonlinear equations are included. Special attention is paid to equations of general form, which depend on arbitrary functions. The other equations contain one or more free parameters (the book actually deals with families of integral xxx xxxii PREFACE equations); it is the reader’s option to fix these parameters. In total, the number of equations described in this handbook is an order of magnitude greater than in any other book currently available. The second part of the book (Chapters 7–14) presents exact, approximate analytical, and numerical methods for solving linear and nonlinear integral equations. Apart from the classical methods, some new methods are also described. When selecting the material, the authors have given a pronounced preference to practical aspects of the matter; that is, to methods that allow effectively “constructing” the solution. For the reader’s better understanding of the methods, each section is supplied with examples of specific equations. Some sections may be used by lecturers of colleges and universities as a basis for courses on integral equations and mathematical physics equations for graduate and postgraduate students. For the convenience of a wide audience with different mathematical backgrounds, the authors tried to do their best, wherever possible, to avoid special terminology. Therefore, some of the methods are outlined in a schematic and somewhat simplified manner, with necessary references made to books where these methods are considered in more detail. For some nonlinear equations, only solutions of the simplest form are given. The book does not cover two-, three-, and multidimensional integral equations. The handbook consists of chapters, sections, and subsections. Equations and formulas are numbered separately in each section. The equations within a section are arranged in increasing order of complexity. The extensive table of contents provides rapid access to the desired equations. For the reader’s convenience, the main material is followed by a number of supplements, where some properties of elementary and special functions are described, tables of indefinite and definite integrals are given, as well as tables of Laplace, Mellin, and other transforms, which are used in the book. The first and second parts of the book, just as many sections, were written so that they could be read independently from each other. This allows the reader to quickly get to the heart of the matter. We would like to express our deep gratitude to Rolf Sulanke and Alexei Zhurov for fruitful discussions and valuable remarks. We also appreciate the help of Vladimir Nazaikinskii and Alexander Shtern in translating the second part of this book, and are thankful to Inna Shingareva for her assistance in preparing the camera-ready copy of the book. The authors hope that the handbook will prove helpful for a wide audience of researchers, college and university teachers, engineers, and students in various fields of mathematics, mechanics, physics, chemistry, biology, economics, and engineering sciences.","2008","2023-03-26 12:07:56","2023-08-01 13:44:46","","","1108","","","","","","Handbooks of mathematical equations","","","","Chapman & Hall/CRC","Boca Raton","en","","","","","Library of Congress ISBN","QA431 .P65 2008","OCLC: ocn167516078","","C:\Users\isido\Zotero\storage\83JNUZ6J\Poli︠a︡nin en Manzhirov - 2008 - Handbook of integral equations.pdf","","integral equations","Handbooks, manuals, etc; Integral equations","","","","","","","","","","","","","","","","","","","","2nd ed","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ7PU6PM","webpage","","","Fredholm Integral Equations colorado","","","","","https://www.colorado.edu/amath/sites/default/files/attached-files/fredholm.pdf","","","2023-03-26 11:18:49","2023-03-26 11:19:23","2023-03-26 11:18:13","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\G9NULA4I\fredholm.pdf","","integral equations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D823325H","preprint","2001","Heinrich, S.; Novak, E.","Optimal Summation and Integration by Deterministic, Randomized, and Quantum Algorithms","","","","","http://arxiv.org/abs/quant-ph/0105114","We survey old and new results about optimal algorithms for summation of finite sequences and for integration of functions from Hoelder or Sobolev spaces. First we discuss optimal deterministic and randomized algorithms. Then we add a new aspect, which has not been covered before on conferences about (quasi-) Monte Carlo methods: quantum computation. We give a short introduction into this setting and present recent results of the authors on optimal quantum algorithms for summation and integration. We discuss comparisons between the three settings. The most interesting case for Monte Carlo and quantum integration is that of moderate smoothness k and large dimension d which, in fact, occurs in a number of important applied problems. In that case the deterministic exponent is negligible, so the n^{-1/2} Monte Carlo and the n^{-1} quantum speedup essentially constitute the entire convergence rate. We observe that -- there is an exponential speed-up of quantum algorithms over deterministic (classical) algorithms, if k/d tends to zero; -- there is a (roughly) quadratic speed-up of quantum algorithms over randomized classical algorithms, if k/d is small.","2001-05-23","2023-03-19 16:36:30","2023-03-19 16:37:15","2023-03-19 16:36:30","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:quant-ph/0105114","","C:\Users\isido\Zotero\storage\LK6RKYIX\Heinrich en Novak - 2001 - Optimal Summation and Integration by Deterministic.pdf","","integration; randomized trapezodial","Mathematics - Numerical Analysis; Quantum Physics","","","","","","","","","","","","","","","","","","","arXiv:quant-ph/0105114","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSKZBGG6","journalArticle","2011","Daun, Thomas","On the randomized solution of initial value problems","Journal of Complexity","","0885064X","10.1016/j.jco.2010.07.002","https://linkinghub.elsevier.com/retrieve/pii/S0885064X1000066X","We study the randomized solution of initial value problems for systems of ordinary differential equations $$ y^{\prime}(x)=f(x, y(x)), x \in[a, b], y(a)=y_0 \in \mathbb{R}^d . $$ Recently S. Heinrich and B. Milla presented an order optimal randomized algorithm solving this problem for $\gamma$-smooth input data (i.e. $\gamma=r+\rho$ : the $r$-th derivatives of $f$ satisfy a $\rho$-Hölder condition). This algorithm uses function values and values of derivatives of $f$. In this paper we present an order optimal randomized algorithm for the class of $\gamma$-smooth functions that uses only values of $f$. For this purpose we show how to obtain an order optimal randomized algorithm from an order (sub)optimal deterministic one.","2011-06","2023-03-06 14:05:17","2023-08-01 13:50:15","2023-03-06 14:05:17","300-311","","3-4","27","","Journal of Complexity","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\NCVQFBK5\Daun - 2011 - On the randomized solution of initial value proble.pdf","","monte carlo; ODE; randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Q7VSW3M","journalArticle","2014","Goćwin, Maciej","Randomized and quantum complexity of nonlinear two-point BVPs","Applied Mathematics and Computation","","00963003","10.1016/j.amc.2014.07.106","https://linkinghub.elsevier.com/retrieve/pii/S009630031401073X","We deal with the complexity of nonlinear BVPs with nonlinear two-point boundary conditions. We consider the randomized and quantum models of computation. We assume that the right-hand side function is r times differentiable with all derivatives bounded by a constant. We show that the e-complexity is roughly of order eÀ1=ðrþ1=2Þ in the randomized setting, and eÀ1=ðrþ1Þ in the quantum setting. We compare our results with known results in the deterministic setting. The speed-up of the randomized computations with respect to the deterministic computations is by 1=ðrð2r þ 1ÞÞ in the exponent of 1=e, and the speed-up of the quantum computations by 1=ðrðr þ 1ÞÞ in the exponent.","2014-10","2023-03-19 15:36:30","2023-03-19 15:37:31","2023-03-19 15:36:30","357-371","","","245","","Applied Mathematics and Computation","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\AVIKYTNP\Goćwin - 2014 - Randomized and quantum complexity of nonlinear two.pdf","","ODE; randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K25543D6","videoRecording","2022","Marcin Anforowicz","The ""Just One More"" Paradox","","","","","https://www.youtube.com/watch?v=_FuuYSM7yOo","Code I wrote for this video: https://github.com/manforowicz/Manim-... Great ergodicity economics blog post by Jason Collins: https://www.jasoncollins.blog/posts/e... Related article: Myers, J. K. (2021). Multiplicative Gains, Non-ergodic Utility, and the Just One More Paradox (with Supplemental Information). https://www.researchsquare.com/articl... Another nice video about the Kelly criterion:    • The Kelly Criterion","2022-09-25","2023-05-29 06:46:11","2023-05-29 06:46:16","2023-05-29 06:46:11","","","","","","","","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","9:12","","","","","","","","","","","","","","","","","","","","","","","","",""
"GBRHHG8Z","preprint","2013","Cuturi, Marco","Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances","","","","","http://arxiv.org/abs/1306.0895","Optimal transportation distances are a fundamental family of parameterized distances for histograms. Despite their appealing theoretical properties, excellent performance in retrieval tasks and intuitive formulation, their computation involves the resolution of a linear program whose cost is prohibitive whenever the histograms’ dimension exceeds a few hundreds. We propose in this work a new family of optimal transportation distances that look at transportation problems from a maximum-entropy perspective. We smooth the classical optimal transportation problem with an entropic regularization term, and show that the resulting optimum is also a distance which can be computed through Sinkhorn-Knopp’s matrix scaling algorithm at a speed that is several orders of magnitude faster than that of transportation solvers. We also report improved performance over classical optimal transportation distances on the MNIST benchmark problem.","2013-06-04","2023-05-29 07:51:25","2023-05-29 07:51:25","2023-05-29 07:51:25","","","","","","","Sinkhorn Distances","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1306.0895 [stat]","","C:\Users\isido\Zotero\storage\772CFQJN\Cuturi - 2013 - Sinkhorn Distances Lightspeed Computation of Opti.pdf","","","Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1306.0895","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QE259D7Q","journalArticle","2020","Hu, Zhicheng; Liu, Zhihui","Heat Conduction Simulation of 2D Moving Heat Source Problems Using a Moving Mesh Method","Advances in Mathematical Physics","","1687-9120, 1687-9139","10.1155/2020/6067854","https://www.hindawi.com/journals/amp/2020/6067854/","This paper focuses on efficiently numerical investigation of two-dimensional heat conduction problems of material subjected to multiple moving Gaussian point heat sources. All heat sources are imposed on the inside of material and assumed to move along some specified straight lines or curves with time-dependent velocities. A simple but efficient moving mesh method, which continuously adjusts the two-dimensional mesh dimension by dimension upon the one-dimensional moving mesh partial differential equation with an appropriate monitor function of the temperature field, has been developed. The physical model problem is then solved on this adaptive moving mesh. Numerical experiments are presented to exhibit the capability of the proposed moving mesh algorithm to efficiently and accurately simulate the moving heat source problems. The transient heat conduction phenomena due to various parameters of the moving heat sources, including the number of heat sources and the types of motion, are well simulated and investigated.","2020-02-11","2023-05-29 11:58:37","2023-08-03 19:19:06","2023-05-29 11:58:37","1-16","","","2020","","Advances in Mathematical Physics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\G7ZGFDCD\Hu en Liu - 2020 - Heat Conduction Simulation of 2D Moving Heat Sourc.pdf","","PDE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B97ZGWZI","videoRecording","2022","Mathemaniac","The weirdest paradox in statistics (and machine learning)","","","","","https://www.youtube.com/watch?v=cUqoHQDinCM","🌏 AD: Get Exclusive NordVPN deal here ➼ https://nordvpn.com/mathemaniac. It's risk-free with Nord's 30-day money-back guarantee! ✌ Second channel video:    • Why James-Stein e...   Stein's paradox is of fundamental importance in modern statistics, introducing concepts of shrinkage to further reduce the mean squared error, especially in higher dimensional statistics that is particularly relevant nowadays, in the world of machine learning, for example. However, this is usually ignored, because it is mostly seen as a toy problem. Precisely because it is such a simple problem that illustrates the problem of maximum likelihood estimation! This paradox is the subject of many blogposts (linked below), but not really here on YouTube, except in some lecture recordings, so I have to bring this up to YouTube. This is not to say that maximum likelihood estimator is not useful - in most situations, especially in lower dimensional statistics, it is still good, but to hold it to such a high place, as statisticians did before 1961? That is not a healthy attitude to this theory. One thing I did not say, but perhaps a lot of people will want me to, is that this is an emprical Bayes estimator, but again, more links below. Video chapters: 00:00 Introduction 04:38 Chapter 1: The ""best"" estimator 09:48 Chapter 2: Why shrinkage works 15:51 Chapter 3: Bias-variance tradeoff 18:45 Chapter 4: Applications Further reading: The “baseball paper”: https://efron.ckirby.su.domains//othe... Wikipedia: https://en.wikipedia.org/wiki/Stein%2... Dominating the (positive-part) James-Stein estimator: https://projecteuclid.org/journals/an... Wikipedia (Empirical Bayes): https://en.wikipedia.org/wiki/Empiric... Other writeups: http://www.ime.unicamp.br/~veronica/M... https://joe-antognini.github.io/machi... https://www.jchau.org/2021/01/29/demy... https://www.naftaliharris.com/blog/st... https://austinrochford.com/posts/2013... https://duphan.wordpress.com/2016/07/... http://www.statslab.cam.ac.uk/~rjs57/... (Philosophical implications) http://philsci-archive.pitt.edu/13303... Other than commenting on the video, you are very welcome to fill in a Google form linked below, which helps me make better videos by catering for your math levels: https://forms.gle/QJ29hocF9uQAyZyH6 If you want to know more interesting Mathematics, stay tuned for the next video! SUBSCRIBE and see you in the next video! If you are wondering how I made all these videos, even though it is stylistically similar to 3Blue1Brown, I don't use his animation engine Manim, but I will probably reveal how I did it in a potential subscriber milestone, so do subscribe! Social media: Facebook: https://www.facebook.com/mathemaniacyt Instagram: https://www.instagram.com/_mathemaniac_/ Twitter: https://twitter.com/mathemaniacyt Patreon: https://www.patreon.com/mathemaniac (support if you want to and can afford to!) Merch: https://mathemaniac.myspreadshop.co.uk Ko-fi: https://ko-fi.com/mathemaniac [for one-time support] For my contact email, check my About page on a PC. See you next time!","2022-08-30","2023-06-05 09:26:37","2023-06-05 09:26:41","2023-06-05 09:26:37","","","","","","","","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","21:43","","","","","","","","","","","","","","","","","","","","","","","","",""
"6H6BV477","preprint","2023","Sugimoto, Ryusuke; Chen, Terry; Jiang, Yiti; Batty, Christopher; Hachisuka, Toshiya","A Practical Walk-on-Boundary Method for Boundary Value Problems","","","","10.1145/3592109","http://arxiv.org/abs/2305.04403","We introduce the walk-on-boundary (WoB) method for solving boundary value problems to computer graphics. WoB is a grid-free Monte Carlo solver for certain classes of second order partial differential equations. A similar Monte Carlo solver, the walk-on-spheres (WoS) method, has been recently popularized in computer graphics due to its advantages over traditional spatial discretization-based alternatives. We show that WoB’s intrinsic properties yield further advantages beyond those of WoS. Unlike WoS, WoB naturally supports various boundary conditions (Dirichlet, Neumann, Robin, and mixed) for both interior and exterior domains. WoB builds upon boundary integral formulations, and it is mathematically more similar to light transport simulation in rendering than the random walk formulation of WoS. This similarity between WoB and rendering allows us to implement WoB on top of Monte Carlo ray tracing, and to incorporate advanced rendering techniques (e.g., bidirectional estimators with multiple importance sampling, the virtual point lights method, and Markov chain Monte Carlo) into WoB. WoB does not suffer from the intrinsic bias of WoS near the boundary and can estimate solutions precisely on the boundary. Our numerical results highlight the advantages of WoB over WoS as an attractive alternative to solve boundary value problems based on Monte Carlo. CCS Concepts: • Mathematics of computing → Integral equations; Partial differential equations; • Computing methodologies → Ray tracing.","2023-05-19","2023-06-07 12:04:51","2023-08-03 19:18:58","2023-06-07 12:04:51","","","","","","","","","","","","","","en","","","","","arXiv.org","","arXiv:2305.04403 [cs, math]","","C:\Users\isido\Zotero\storage\7AGTX5CS\Sugimoto e.a. - 2023 - A Practical Walk-on-Boundary Method for Boundary V.pdf","","Boundary value problems; PDE; walk on spheres","Computer Science - Graphics; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHG2FICZ","journalArticle","","Mossberg, Linus","GPU-Accelerated Monte Carlo Geometry Processing for Gradient-Domain Methods","","","","","","This thesis extends the utility of the Monte Carlo approach to PDE-based methods presented in the paper Monte Carlo Geometry Processing. In particular, we implement this method on the GPU using CUDA, and investigate more viable methods of estimating the source integral when solving Poisson’s equation with intricate source terms. This is the case for a large group of gradient-domain methods in computer graphics, where source terms are represented by discrete volumetric data on regular grids. We develop unbiased source integral estimators like image-based importance sampling (IBIS) and biased estimators like source integral caching (SIC), and evaluate these against existing GPU-accelerated finite difference solvers for gradient-domain applications. By decoupling the source integration step from the WoS-algorithm, we find that the SIC method can improve performance by several orders of magnitude, making it competitive with existing finite difference solvers in many cases. We further investigate the viability of distance fields for accelerated distance queries, and find that these can provide significant performance improvements compared to BVHs without meaningfully affecting bias.","","2023-06-08 07:22:07","2023-08-03 19:18:46","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\M3CIZFYI\Mossberg - GPU-Accelerated Monte Carlo Geometry Processing fo.pdf","","Boundary value problems; monte carlo; PDE; walk on spheres","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ATUUSCKM","journalArticle","","Tibshirani, Ryan","Nonparametric Regression (and Classiﬁcation)","","","","","","","","2023-06-09 12:59:43","2023-06-09 12:59:43","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\GSH6DL6E\Tibshirani - Nonparametric Regression (and Classiﬁcation).pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GNQ2D6T5","videoRecording","2015","Ryan T","Lecture 11: Nonparametric Bayes","","","","","https://www.youtube.com/watch?v=l0HQXtqnBZY","Lecture Date: 02/18/15","2015-02-26","2023-06-09 13:00:23","2023-06-09 13:00:23","2023-06-09 13:00:23","","","","","","","Lecture 11","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","1:18:18","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KSSJRL8","journalArticle","","Tibshirani, Ryan","Sparsity, the Lasso, and Friends","","","","","","","","2023-06-09 13:22:06","2023-06-09 13:22:06","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\FMEX9G6K\Tibshirani - Sparsity, the Lasso, and Friends.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IMC2MPGC","bookSection","2012","Bottou, Léon","Stochastic Gradient Descent Tricks","Neural Networks: Tricks of the Trade","978-3-642-35288-1 978-3-642-35289-8","","","http://link.springer.com/10.1007/978-3-642-35289-8_25","Chapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a good learning algorithm when the training set is large, and provides useful recommendations.","2012","2023-06-09 14:11:09","2023-08-03 19:18:02","2023-06-09 14:11:09","421-436","","","7700","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-35289-8_25","","C:\Users\isido\Zotero\storage\38JMSAZM\Bottou - 2012 - Stochastic Gradient Descent Tricks.pdf","","gradient descent; optimization","","Montavon, Grégoire; Orr, Geneviève B.; Müller, Klaus-Robert","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZW7642E","journalArticle","","Tibshirani, Ryan","Numerical Linear Algebra Primer","","","","","","","","2023-06-09 14:20:48","2023-06-09 14:20:48","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\VZ7YFNWJ\Tibshirani - Numerical Linear Algebra Primer.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CEJW669D","preprint","2021","Gutman, David H.; Peña, Javier F.","Perturbed Fenchel duality and first-order methods","","","","","http://arxiv.org/abs/1812.10198","We show that the iterates generated by a generic ﬁrst-order meta-algorithm satisfy a canonical perturbed Fenchel duality inequality. The latter in turn readily yields a uniﬁed derivation of the best known convergence rates for various popular ﬁrst-order algorithms including the conditional gradient method as well as the main kinds of Bregman proximal methods: subgradient, gradient, fast gradient, and universal gradient methods.","2021-12-03","2023-06-09 14:45:53","2023-06-09 14:45:54","2023-06-09 14:45:53","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1812.10198 [math]","","C:\Users\isido\Zotero\storage\TDVYYRYS\Gutman en Peña - 2021 - Perturbed Fenchel duality and first-order methods.pdf","","","Mathematics - Optimization and Control","","","","","","","","","","","","","","","","","","","arXiv:1812.10198","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPG7863A","journalArticle","2009","Blanes, S.; Casas, F.; Oteo, J. A.; Ros, J.","The Magnus expansion and some of its applications","Physics Reports","","03701573","10.1016/j.physrep.2008.11.001","http://arxiv.org/abs/0810.5488","Approximate resolution of linear systems of diﬀerential equations with varying coeﬃcients is a recurrent problem shared by a number of scientiﬁc and engineering areas, ranging from Quantum Mechanics to Control Theory. When formulated in operator or matrix form, the Magnus expansion furnishes an elegant setting to built up approximate exponential representations of the solution of the system. It provides a power series expansion for the corresponding exponent and is sometimes referred to as Time-Dependent Exponential Perturbation Theory. Every Magnus approximant corresponds in Perturbation Theory to a partial re-summation of inﬁnite terms with the important additional property of preserving at any order certain symmetries of the exact solution.","2009-01","2023-06-12 11:19:37","2023-08-03 19:17:48","2023-06-12 11:19:37","151-238","","5-6","470","","Physics Reports","","","","","","","","en","","","","","arXiv.org","","arXiv:0810.5488 [math-ph]","","C:\Users\isido\Zotero\storage\352XINMQ\0810.5488.pdf","","ODE","Mathematical Physics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"28TH8SZ5","book","1988","Novak, Erich","Deterministic and stochastic error bounds in numerical analysis","","978-3-540-50368-2 978-0-387-50368-4","","","","In these notes we want to investigate different deterministic and stochastic error bounds of numerical analysis. For many computational problems (such as approximation, optimization, and quadrature) we have only partial information and consequently such problems can only be solved with uncertainty in the answer. The information-centered approach asks for optimal methods and optimal error bounds if only the type of information available is indicated. We begin with worst case error bounds for deterministic methods and consider relations between these error bounds and the n-widths of the class of problem elements (1.2). In 1.3 we give worst case error bounds for some special problems. We are mainly interested in the problems of approximation (App), optimization (Opt and Opt*), and quadrature or integration (Int). We consider different function classes, for both adaptive and nonadaptive methods. First of all, I explain the information-based approach by means of an example.","1988","2023-06-13 10:47:04","2023-08-03 19:17:43","","","113","","","","","","Lecture notes in mathematics","1349","","","Springer","Berlin Heidelberg","en","","","","","K10plus ISBN","","","","C:\Users\isido\Zotero\storage\CT75RT9T\Novak - 1988 - Deterministic and stochastic error bounds in numer.pdf; C:\Users\isido\Zotero\storage\3YULLQV7\Novak - Deterministic and Stochastic Error Bounds In Numer.pdf","","randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3MAD9IY","encyclopediaArticle","2023","","No free lunch theorem","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=No_free_lunch_theorem&oldid=1154448734","In mathematical folklore, the ""no free lunch"" (NFL) theorem (sometimes pluralized) of David Wolpert and William Macready appears in the 1997 ""No Free Lunch Theorems for Optimization"". Wolpert had previously derived no free lunch theorems for machine learning (statistical inference). The name alludes to the saying ""there ain't no such thing as a free lunch"", that is, there are no easy shortcuts to success. In 2005, Wolpert and Macready themselves indicated that the first theorem in their paper ""state[s] that any two optimization algorithms are equivalent when their performance is averaged across all possible problems"".The ""no free lunch"" (NFL) theorem is an easily stated and easily understood consequence of theorems Wolpert and Macready actually prove. It is weaker than the proven theorems, and thus does not encapsulate them. Various investigators have extended the work of Wolpert and Macready substantively. In terms of how the NFL theorem is used in the context of the research area, the no free lunch in search and optimization is a field that is dedicated for purposes of mathematically analyzing data for statistical identity, particularly search and optimization.While some scholars argue that NFL conveys important insight, others argue that NFL is of little relevance to machine learning research.","2023-05-12","2023-06-13 11:01:16","2023-08-03 19:17:37","2023-06-13 11:01:16","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1154448734","","C:\Users\isido\Zotero\storage\S7SXIJCH\No_free_lunch_theorem.html","","machine learning; optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7G2K4SLJ","encyclopediaArticle","2022","","Information-based complexity","Wikipedia","","","","https://en.wikipedia.org/w/index.php?title=Information-based_complexity&oldid=1116392336","Information-based complexity (IBC) studies optimal algorithms and computational complexity for the continuous problems that arise in physical science, economics, engineering, and mathematical finance. IBC has studied such continuous problems as path integration, partial differential equations, systems of ordinary differential equations, nonlinear equations, integral equations, fixed points, and very-high-dimensional integration. All these problems involve functions (typically multivariate) of a real or complex variable. Since one can never obtain a closed-form solution to the problems of interest one has to settle for a numerical solution. Since a function of a real or complex variable cannot be entered into a digital computer, the solution of continuous problems involves partial information. To give a simple illustration, in the numerical approximation of an integral, only samples of the integrand at a finite number of points are available. In the numerical solution of partial differential equations the functions specifying the boundary conditions and the coefficients of the differential operator can only be sampled. Furthermore, this partial information can be expensive to obtain. Finally the information is often contaminated by noise. The goal of information-based complexity is to create a theory of computational complexity and optimal algorithms for problems with partial, contaminated and priced information, and to apply the results to answering questions in various disciplines. Examples of such disciplines include physics, economics, mathematical finance, computer vision, control theory, geophysics, medical imaging, weather forecasting and climate prediction, and statistics. The theory is developed over abstract spaces, typically Hilbert or Banach spaces, while the applications are usually for multivariate problems. Since the information is partial and contaminated, only approximate solutions can be obtained. IBC studies computational complexity and optimal algorithms for approximate solutions in various settings. Since the worst case setting often leads to negative results such as unsolvability and intractability, settings with weaker assurances such as average, probabilistic and randomized are also studied. A fairly new area of IBC research is continuous quantum computing.","2022-10-16","2023-06-14 07:37:41","2023-08-03 19:17:20","2023-06-14 07:37:41","","","","","","","","","","","","","","en","Creative Commons Attribution-ShareAlike License","","","","Wikipedia","","Page Version ID: 1116392336","","C:\Users\isido\Zotero\storage\K3D6TU8D\Information-based_complexity.html","","randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AP6T8IT","preprint","2018","Robbe, Pieterjan; Nuyens, Dirk; Vandewalle, Stefan","Recycling Samples in the Multigrid Multilevel (Quasi-)Monte Carlo Method","","","","","http://arxiv.org/abs/1806.05619","The Multilevel Monte Carlo method is an eﬃcient variance reduction technique. It uses a sequence of coarse approximations to reduce the computational cost in uncertainty quantiﬁcation applications. The method is nowadays often considered to be the method of choice for solving PDEs with random coeﬃcients when many uncertainties are involved. When using Full Multigrid to solve the deterministic problem, coarse solutions obtained by the solver can be recycled as samples in the Multilevel Monte Carlo method, as was pointed out by Kumar, Oosterlee and Dwight [Int. J. Uncertain. Quantif., 7 (2017), pp. 57–81]. In this article, an alternative approach is considered, using Quasi-Monte Carlo points, to speed up convergence. Additionally, our method comes with an improved variance estimate which is also valid in case of the Monte Carlo based approach. The new method is illustrated on the example of an elliptic PDE with lognormal diﬀusion coeﬃcient. Numerical results for a variety of random ﬁelds with diﬀerent smoothness parameters in the Matérn covariance function show that sample recycling is more eﬃcient when the input random ﬁeld is nonsmooth.","2018-06-14","2023-06-14 08:26:10","2023-08-03 19:16:59","2023-06-14 08:26:10","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1806.05619 [math]","","C:\Users\isido\Zotero\storage\PWK6DY7M\Robbe e.a. - 2018 - Recycling Samples in the Multigrid Multilevel (Qua.pdf","","monte carlo; PDE","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1806.05619","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3435ZYKY","preprint","2017","Kuo, Frances Y.; Nuyens, Dirk","Application of quasi-Monte Carlo methods to PDEs with random coefficients -- an overview and tutorial","","","","","http://arxiv.org/abs/1710.10984","This article provides a high-level overview of some recent works on the application of quasi-Monte Carlo (QMC) methods to PDEs with random coeﬃcients. It is based on an indepth survey of a similar title by the same authors, with an accompanying software package which is also brieﬂy discussed here. Embedded in this article is a step-by-step tutorial of the required analysis for the setting known as the uniform case with ﬁrst order QMC rules. The aim of this article is to provide an easy entry point for QMC experts wanting to start research in this direction and for PDE analysts and practitioners wanting to tap into contemporary QMC theory and methods.","2017-10-26","2023-06-14 08:34:06","2023-08-03 19:16:46","2023-06-14 08:34:06","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1710.10984 [math]","","C:\Users\isido\Zotero\storage\CN5A6NQ6\Kuo en Nuyens - 2017 - Application of quasi-Monte Carlo methods to PDEs w.pdf","","monte carlo; PDE","65D32; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1710.10984","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUJDV556","preprint","2001","Heinrich, Stefan","From Monte Carlo to Quantum Computation","","","","","http://arxiv.org/abs/quant-ph/0112152","Quantum computing was so far mainly concerned with discrete problems. Recently, E. Novak and the author studied quantum algorithms for high dimensional integration and dealt with the question, which advantages quantum computing can bring over classical deterministic or randomized methods for this type of problem.","2001-12-23","2023-06-15 10:27:55","2023-08-03 19:16:08","2023-06-15 10:27:55","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:quant-ph/0112152","","C:\Users\isido\Zotero\storage\2BSDMTVF\Heinrich - 2001 - From Monte Carlo to Quantum Computation.pdf","","monte carlo; Quantum computing","Quantum Physics","","","","","","","","","","","","","","","","","","","arXiv:quant-ph/0112152","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UTMNWQF","preprint","2015","Lan, Guanghui; Zhou, Yi","An optimal randomized incremental gradient method","","","","","http://arxiv.org/abs/1507.02000","In this paper, we consider a class of finite-sum convex optimization problems whose objective function is given by the summation of $m$ ($\ge 1$) smooth components together with some other relatively simple terms. We first introduce a deterministic primal-dual gradient (PDG) method that can achieve the optimal black-box iteration complexity for solving these composite optimization problems using a primal-dual termination criterion. Our major contribution is to develop a randomized primal-dual gradient (RPDG) method, which needs to compute the gradient of only one randomly selected smooth component at each iteration, but can possibly achieve better complexity than PDG in terms of the total number of gradient evaluations. More specifically, we show that the total number of gradient evaluations performed by RPDG can be ${\cal O} (\sqrt{m})$ times smaller, both in expectation and with high probability, than those performed by deterministic optimal first-order methods under favorable situations. We also show that the complexity of the RPDG method is not improvable by developing a new lower complexity bound for a general class of randomized methods for solving large-scale finite-sum convex optimization problems. Moreover, through the development of PDG and RPDG, we introduce a novel game-theoretic interpretation for these optimal methods for convex optimization.","2015-10-18","2023-06-16 12:18:37","2023-08-03 19:15:52","2023-06-16 12:18:37","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1507.02000 [cs, math, stat]","","C:\Users\isido\Zotero\storage\YKXRE23K\Lan en Zhou - 2015 - An optimal randomized incremental gradient method.pdf","","gradient descent; optimization","Computer Science - Computational Complexity; Mathematics - Optimization and Control; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1507.02000","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSC4MMNZ","journalArticle","2022","Driggs, Derek; Ehrhardt, Matthias J.; Schönlieb, Carola-Bibiane","Accelerating variance-reduced stochastic gradient methods","Mathematical Programming","","0025-5610, 1436-4646","10.1007/s10107-020-01566-2","https://link.springer.com/10.1007/s10107-020-01566-2","Variance reduction is a crucial tool for improving the slow convergence of stochastic gradient descent. Only a few variance-reduced methods, however, have yet been shown to directly beneﬁt from Nesterov’s acceleration techniques to match the convergence rates of accelerated gradient methods. Such approaches rely on “negative momentum”, a technique for further variance reduction that is generally speciﬁc to the SVRG gradient estimator. In this work, we show for the ﬁrst time that negative momentum is unnecessary for acceleration and develop a universal acceleration framework that allows all popular variance-reduced methods to achieve accelerated convergence rates. The constants appearing in these rates, including their dependence on the number of functions n, scale with the mean-squared-error and bias of the gradient estimator. In a series of numerical experiments, we demonstrate that versions of SAGA, SVRG, SARAH, and SARGE using our framework signiﬁcantly outperform non-accelerated versions and compare favourably with algorithms using negative momentum.","2022-02","2023-06-16 12:28:36","2023-08-03 19:15:42","2023-06-16 12:28:36","671-715","","2","191","","Math. Program.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\HBSFVERS\Driggs e.a. - 2022 - Accelerating variance-reduced stochastic gradient .pdf","","gradient descent; optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78DJTG8P","journalArticle","2021","Kettunen, Markus; d'Eon, Eugene; Pantaleoni, Jacopo; Novak, Jan","An unbiased ray-marching transmittance estimator","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3450626.3459937","http://arxiv.org/abs/2102.10294","We present an in-depth analysis of the sources of variance in state-of-the-art unbiased volumetric transmittance estimators, and propose several new methods for improving their efficiency. These combine to produce a single estimator that is universally optimal relative to prior work, with up to several orders of magnitude lower variance at the same cost, and has zero variance for any ray with non-varying extinction. We first reduce the variance of truncated power-series estimators using a novel efficient application of U-statistics. We then greatly reduce the average expansion order of the power series and redistribute density evaluations to filter the optical depth estimates with an equidistant sampling comb. Combined with the use of an online control variate built from a sampled mean density estimate, the resulting estimator effectively performs ray marching most of the time while using rarely-sampled higher order terms to correct the bias.","2021-08-31","2023-06-18 08:56:46","2023-08-03 19:15:26","2023-06-18 08:56:46","1-20","","4","40","","ACM Trans. Graph.","","","","","","","","en","","","","","arXiv.org","","arXiv:2102.10294 [cs]","","C:\Users\isido\Zotero\storage\6276WE78\Kettunen e.a. - 2021 - An unbiased ray-marching transmittance estimator.pdf","","rendering","Computer Science - Graphics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QDME6GF7","journalArticle","2022","Nimier-David, Merlin; Müller, Thomas; Keller, Alexander; Jakob, Wenzel","Unbiased inverse volume rendering with differential trackers","ACM Transactions on Graphics","","0730-0301, 1557-7368","10.1145/3528223.3530073","https://dl.acm.org/doi/10.1145/3528223.3530073","Volumetric representations are popular in inverse rendering because they have a simple parameterization, are smoothly varying, and transparently handle topology changes. However, incorporating the full volumetric transport of light is costly and challenging, often leading practitioners to implement simplified models, such as purely emissive and absorbing volumes with ""baked"" lighting. One such challenge is the efficient estimation of the gradients of the volume's appearance with respect to its scattering and absorption parameters. We show that the straightforward approach---differentiating a volumetric free-flight sampler---can lead to biased and high-variance gradients, hindering optimization. Instead, we propose using a new sampling strategy:               differential ratio tracking               , which is unbiased, yields low-variance gradients, and runs in linear time. Differential ratio tracking combines ratio tracking and reservoir sampling to estimate gradients by sampling distances proportional to the unweighted transmittance rather than the usual extinction-weighted transmittance. In addition, we observe local minima when optimizing scattering parameters to reproduce dense volumes or surfaces. We show that these local minima can be overcome by bootstrapping the optimization from nonphysical emissive volumes that are easily optimized.","2022-07","2023-06-18 11:02:46","2023-08-03 19:15:21","2023-06-18 11:02:46","1-20","","4","41","","ACM Trans. Graph.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\4PYPVM7M\Nimier-David e.a. - 2022 - Unbiased inverse volume rendering with differentia.pdf","","inverse problem; rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P66IEAQN","preprint","2017","Kingma, Diederik P.; Ba, Jimmy","Adam: A Method for Stochastic Optimization","","","","","http://arxiv.org/abs/1412.6980","We introduce Adam, an algorithm for ﬁrst-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efﬁcient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the inﬁnity norm.","2017-01-29","2023-06-18 11:09:30","2023-08-03 19:15:13","2023-06-18 11:09:30","","","","","","","Adam","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1412.6980 [cs]","","C:\Users\isido\Zotero\storage\PZYRRCM2\Kingma en Ba - 2017 - Adam A Method for Stochastic Optimization.pdf","","gradient descent; machine learning; optimization","Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:1412.6980","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D86IEHBA","preprint","2021","Buvoli, Tommaso; Minion, Michael L.","IMEX Runge-Kutta Parareal for Non-Diffusive Equations","","","","","http://arxiv.org/abs/2011.01604","Parareal is a widely studied parallel-in-time method that can achieve meaningful speedup on certain problems. However, it is well known that the method typically performs poorly on non-diﬀusive equations. This paper analyzes linear stability and convergence for IMEX Runge-Kutta Parareal methods on non-diﬀusive equations. By combining standard linear stability analysis with a simple convergence analysis, we ﬁnd that certain Parareal conﬁgurations can achieve parallel speedup on non-diﬀusive equations. These stable conﬁgurations all posses low iteration counts, large block sizes, and a large number of processors. Numerical examples using the nonlinear Schro¨dinger equation demonstrate the analytical conclusions.","2021-07-31","2023-06-25 11:38:40","2023-08-03 19:14:58","2023-06-25 11:38:40","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2011.01604 [cs, math]","","C:\Users\isido\Zotero\storage\JJGX8M7T\Buvoli en Minion - 2021 - IMEX Runge-Kutta Parareal for Non-Diffusive Equati.pdf","","ODE; parareal","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2011.01604","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBHYGDMQ","preprint","2021","Buvoli, Tommaso; Minion, Michael L.","On the Stability of Exponential Integrators for Non-Diffusive Equations","","","","","http://arxiv.org/abs/2108.00185","Exponential integrators are a well-known class of time integration methods that have been the subject of many studies and developments in the past two decades. Surprisingly, there have been limited eﬀorts to analyze their stability and eﬃciency on non-diﬀusive equations to date. In this paper we apply linear stability analysis to showcase the poor stability properties of exponential integrators on non-diﬀusive problems. We then propose a simple repartitioning approach that stabilizes the integrators and enables the eﬃcient solution of stiﬀ, non-diﬀusive equations. To validate the eﬀectiveness of our approach, we perform several numerical experiments that compare partitioned exponential integrators to unmodiﬁed ones. We also compare repartitioning to the well-known approach of adding hyperviscosity to the equation right-hand-side. Overall, we ﬁnd that the repartitioning restores convergence at large timesteps and, unlike hyperviscosity, it does not require the use of high-order spatial derivatives.","2021-07-31","2023-06-25 11:39:56","2023-08-03 19:14:36","2023-06-25 11:39:56","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2108.00185 [cs, math]","","C:\Users\isido\Zotero\storage\ZTRRZAV8\Buvoli en Minion - 2021 - On the Stability of Exponential Integrators for No.pdf","","exponential integrators; ODE","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2108.00185","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PL5J5TAN","preprint","2023","Buvoli, Tommaso; Minion, Michael L.","Exponential Runge-Kutta Parareal for Non-Diffusive Equations","","","","","http://arxiv.org/abs/2301.03764","Parareal is a well-known parallel-in-time algorithm that combines a coarse and ﬁne propagator within a parallel iteration. It allows for large-scale parallelism that leads to signiﬁcantly reduced computational time compared to serial time-stepping methods. However, like many parallel-intime methods it can fail to achieve parallel speedup when applied to non-diﬀusive equations such as hyperbolic systems or dispersive nonlinear wave equations. This paper explores the use of exponential integrators within the Parareal iteration. Exponential integrators are particularly interesting candidates for Parareal because of their ability to resolve fast-moving waves, even at the large stepsizes used by coarse propagators. This work begins with an introduction to exponential Parareal integrators followed by several motivating numerical experiments involving the nonlinear Schrödinger equation. These experiments are then analyzed using linear analysis that approximates the stability and convergence properties of the exponential Parareal iteration on nonlinear problems. The paper concludes with two additional numerical experiments involving the dispersive Kadomtsev-Petviashvili equation and the hyperbolic Vlasov-Poisson equation. These experiments demonstrate that exponential Parareal methods can achieve signiﬁcant parallel speedup on diﬀerent types of non-diﬀusive equations.","2023-01-09","2023-06-25 11:42:20","2023-08-03 19:14:23","2023-06-25 11:42:20","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2301.03764 [cs, math]","","C:\Users\isido\Zotero\storage\EJTQSHKJ\Buvoli en Minion - 2023 - Exponential Runge-Kutta Parareal for Non-Diffusive.pdf","","exponential integrators; ODE; parareal","65L04, 65L05, 65L06, 65L07; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2301.03764","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3JLQZN3","preprint","2023","Gander, M. J.; Lunet, T.; Ruprecht, D.; Speck, R.","A unified analysis framework for iterative parallel-in-time algorithms","","","","","http://arxiv.org/abs/2203.16069","Parallel-in-time integration has been the focus of intensive research eﬀorts over the past two decades due to the advent of massively parallel computer architectures and the scaling limits of purely spatial parallelization. Various iterative parallel-in-time (PinT) algorithms have been proposed, like Parareal, PFASST, MGRIT, and Space-Time Multi-Grid (STMG). These methods have been described using diﬀerent notations, and the convergence estimates that are available are diﬃcult to compare. We describe Parareal, PFASST, MGRIT and STMG for the Dahlquist model problem using a common notation and give precise convergence estimates using generating functions. This allows us, for the ﬁrst time, to directly compare their convergence. We prove that all four methods eventually converge super-linearly, and also compare them numerically. The generating function framework provides further opportunities to explore and analyze existing and new methods.","2023-04-28","2023-06-25 11:43:17","2023-08-03 19:14:07","2023-06-25 11:43:17","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2203.16069 [cs, math]","","C:\Users\isido\Zotero\storage\GJFVIYAG\Gander e.a. - 2023 - A unified analysis framework for iterative paralle.pdf","","ODE; parareal","Computer Science - Computational Engineering, Finance, and Science; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2203.16069","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3P73L5V","journalArticle","2021","Zanger, Benjamin; Mendl, Christian B.; Schulz, Martin; Schreiber, Martin","Quantum Algorithms for Solving Ordinary Differential Equations via Classical Integration Methods","Quantum","","2521-327X","10.22331/q-2021-07-13-502","http://arxiv.org/abs/2012.09469","Identifying computational tasks suitable for (future) quantum computers is an active field of research. Here we explore utilizing quantum computers for the purpose of solving differential equations. We consider two approaches: (i) basis encoding and fixed-point arithmetic on a digital quantum computer, and (ii) representing and solving high-order Runge-Kutta methods as optimization problems on quantum annealers. As realizations applied to two-dimensional linear ordinary differential equations, we devise and simulate corresponding digital quantum circuits, and implement and run a 6$^{\mathrm{th}}$ order Gauss-Legendre collocation method on a D-Wave 2000Q system, showing good agreement with the reference solution. We find that the quantum annealing approach exhibits the largest potential for high-order implicit integration methods. As promising future scenario, the digital arithmetic method could be employed as an ""oracle"" within quantum search algorithms for inverse problems.","2021-07-13","2023-06-25 11:45:32","2023-08-03 19:13:42","2023-06-25 11:45:32","502","","","5","","Quantum","","","","","","","","en","","","","","arXiv.org","","arXiv:2012.09469 [quant-ph]","","C:\Users\isido\Zotero\storage\6LH65XLT\Zanger e.a. - 2021 - Quantum Algorithms for Solving Ordinary Differenti.pdf","","ODE; Quantum computing","Quantum Physics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TF8J32A5","preprint","2022","Huang, Zhongzhan; Liang, Senwei; Zhang, Hong; Yang, Haizhao; Lin, Liang","Accelerating Numerical Solvers for Large-Scale Simulation of Dynamical System via NeurVec","","","","","http://arxiv.org/abs/2208.03680","Ensemble-based large-scale simulation of dynamical systems is essential to a wide range of science and engineering problems. Conventional numerical solvers used in the simulation are significantly limited by the step size for time integration, which hampers efficiency and feasibility especially when high accuracy is desired. To overcome this limitation, we propose a data-driven corrector method that allows using large step sizes while compensating for the integration error for high accuracy. This corrector is represented in the form of a vector-valued function and is modeled by a neural network to regress the error in the phase space. Hence we name the corrector neural vector (NeurVec). We show that NeurVec can achieve the same accuracy as traditional solvers with much larger step sizes. We empirically demonstrate that NeurVec can accelerate a variety of numerical solvers significantly and overcome the stability restriction of these solvers. Our results on benchmark problems, ranging from high-dimensional problems to chaotic systems, suggest that NeurVec is capable of capturing the leading error term and maintaining the statistics of ensemble forecasts.","2022-08-07","2023-07-06 12:34:51","2023-08-03 19:12:08","2023-07-06 12:34:51","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2208.03680 [cs, math]","","C:\Users\isido\Zotero\storage\V8G6BSNX\Huang e.a. - 2022 - Accelerating Numerical Solvers for Large-Scale Sim.pdf","","neural networks; ODE","Computer Science - Artificial Intelligence; Computer Science - Computational Engineering, Finance, and Science; Computer Science - Machine Learning; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2208.03680","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5VSTZWV6","preprint","2023","Huang, Zhongzhan; Liang, Mingfu; Lin, Liang","On Robust Numerical Solver for ODE via Self-Attention Mechanism","","","","","http://arxiv.org/abs/2302.10184","With the development of deep learning techniques, AI-enhanced numerical solvers are expected to become a new paradigm for solving differential equations due to their versatility and effectiveness in alleviating the accuracy-speed trade-off in traditional numerical solvers. However, this paradigm still inevitably requires a large amount of high-quality data, whose acquisition is often very expensive in natural science and engineering problems. Therefore, in this paper, we explore training efﬁcient and robust AI-enhanced numerical solvers with a small data size by mitigating intrinsic noise disturbances. We ﬁrst analyze the ability of the self-attention mechanism to regulate noise in supervised learning and then propose a simple-yet-effective numerical solver, AttSolver, which introduces an additive self-attention mechanism to the numerical solution of differential equations based on the dynamical system perspective of the residual neural network. Our results on benchmarks, ranging from high-dimensional problems to chaotic systems, demonstrate the effectiveness of AttSolver in generally improving the performance of existing traditional numerical solvers without any elaborated model crafting. Finally, we analyze the convergence, generalization, and robustness of the proposed method experimentally and theoretically.","2023-02-04","2023-07-06 12:29:43","2023-08-03 19:12:22","2023-07-06 12:29:43","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2302.10184 [cs, math]","","C:\Users\isido\Zotero\storage\B6JQY5GS\Huang e.a. - 2023 - On Robust Numerical Solver for ODE via Self-Attent.pdf","","neural networks; ODE","Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2302.10184","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZHB8H5KI","preprint","2023","Finzi, Marc; Potapczynski, Andres; Choptuik, Matthew; Wilson, Andrew Gordon","A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks","","","","","http://arxiv.org/abs/2304.14994","Unlike conventional grid and mesh based methods for solving partial differential equations (PDEs), neural networks have the potential to break the curse of dimensionality, providing approximate solutions to problems where using classical solvers is difﬁcult or impossible. While global minimization of the PDE residual over the network parameters works well for boundary value problems, catastrophic forgetting impairs the applicability of this approach to initial value problems (IVPs). In an alternative local-in-time approach, the optimization problem can be converted into an ordinary differential equation (ODE) on the network parameters and the solution propagated forward in time; however, we demonstrate that current methods based on this approach suffer from two key issues. First, following the ODE produces an uncontrolled growth in the conditioning of the problem, ultimately leading to unacceptably large numerical errors. Second, as the ODE methods scale cubically with the number of model parameters, they are restricted to small neural networks, signiﬁcantly limiting their ability to represent intricate PDE initial conditions and solutions. Building on these insights, we develop Neural IVP, an ODE based IVP solver which prevents the network from getting ill-conditioned and runs in time linear in the number of parameters, enabling us to evolve the dynamics of challenging PDEs with neural networks.","2023-04-28","2023-07-06 12:20:45","2023-08-03 19:12:35","2023-07-06 12:20:45","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2304.14994 [cs, math, stat]","","C:\Users\isido\Zotero\storage\G6V5GEWN\2304.14994.pdf","","PDE","Computer Science - Machine Learning; Statistics - Machine Learning; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:2304.14994","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3XU6NQA5","journalArticle","","Johnson, Rie; Zhang, Tong","Accelerating Stochastic Gradient Descent using Predictive Variance Reduction","","","","","","Stochastic gradient descent is popular for large scale optimization but has slow convergence asymptotically due to the inherent variance. To remedy this problem, we introduce an explicit variance reduction method for stochastic gradient descent which we call stochastic variance reduced gradient (SVRG). For smooth and strongly convex functions, we prove that this method enjoys the same fast convergence rate as those of stochastic dual coordinate ascent (SDCA) and Stochastic Average Gradient (SAG). However, our analysis is signiﬁcantly simpler and more intuitive. Moreover, unlike SDCA or SAG, our method does not require the storage of gradients, and thus is more easily applicable to complex problems such as some structured prediction problems and neural network learning.","","2023-07-05 06:52:13","2023-08-03 19:12:59","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\V5D4E8K9\Johnson en Zhang - Accelerating Stochastic Gradient Descent using Pre.pdf","","gradient descent; optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BXR7I33","journalArticle","2020","Mukhopadhyay, Samrat","Stochastic Gradient Descent For Linear Systems With Sequential Matrix Entry Accumulation","Signal Processing","","","10.1016/j.sigpro.2020.107494","","Conventional stochastic iterative methods are often employed for solving linear systems of equations involving large matrix sizes using low memory footprint. However, their performances are often limited by the unavailability of all the matrix entries, which is often termed as the problem of missing data. Although Ma and Needell [1] have recently proposed a method, termed as mSGD, assuming a model for data missing that results in improved convergence, their result is also affected by constant large variance of the stochastic gradient. In this paper we propose a SGD type method termed as cumulative information SGD (CISGD) for solving a linear system with missing data with an additional provision to accumulate a very small number of matrix entries sequentially per iteration, termed as the sequential matrix entry accumulation (SEMEA) mechanism. CISGD uses the data collected by SEMEA mechanism along with the prior model for data missing mechanism of [1] to gradually reduce variance of the stochastic gradient. The convergence of the proposed CISGD is theoretically analyzed and some interesting implications of the result are investigated under a specific SEMEA mechanism. Finally, numerical experiments are performed along with simulations that corroborate the theoretical findings regarding the efficacy of the proposed CISGD method.","2020-06-01","2023-07-05 06:47:09","2023-08-03 19:13:13","","107494","","","171","","Signal Processing","","","","","","","","","","","","","ResearchGate","","","","","https://www.researchgate.net/publication/338760625_Stochastic_Gradient_Descent_For_Linear_Systems_With_Sequential_Matrix_Entry_Accumulation","gradient descent; linear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JETBS48M","preprint","2019","Ma, Anna; Needell, Deanna","Stochastic Gradient Descent for Linear Systems with Missing Data","","","","","http://arxiv.org/abs/1702.07098","Traditional methods for solving linear systems have quickly become impractical due to an increase in the size of available data. Utilizing massive amounts of data is further complicated when the data is incomplete or has missing entries. In this work, we address the obstacles presented when working with large data and incomplete data simultaneously. In particular, we propose to adapt the Stochastic Gradient Descent method to address missing data in linear systems. Our proposed algorithm, the Stochastic Gradient Descent for Missing Data method (mSGD), is introduced and theoretical convergence guarantees are provided. In addition, we include numerical experiments on simulated and real world data that demonstrate the usefulness of our method.","2019-01-07","2023-07-05 06:19:40","2023-08-03 19:13:23","2023-07-05 06:19:40","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:1702.07098 [math]","","C:\Users\isido\Zotero\storage\BE762FG6\1702.07098.pdf","","gradient descent; linear systems","Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","arXiv:1702.07098","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZKY8LKAD","videoRecording","2023","Shlomi Steinberg","Towards Practical Physical-Optics Rendering — Presentation","","","","","https://www.youtube.com/watch?v=4Z3ohq0ZszI","Physical light transport (PLT) algorithms can represent the wave nature of light globally in a scene, and are consistent with Maxwell’s theory of electromagnetism. As such, they are able to reproduce the wave-interference and diffraction effects of real physical optics. However, the recent works that have proposed PLT are too expensive to apply to real-world scenes with complex geometry and materials. To address this problem, we propose a novel framework for physical light transport based on several key ideas that actually makes PLT practical for complex scenes. First, we restrict the spatial coherence shape of light to an anisotropic Gaussian and justify this restriction with general arguments based on entropy. This restriction serves to simplify the rest of the derivations, without practical loss of generality. To describe partially-coherent light, we present new rendering primitives that generalize the radiometric radiance and irradiance, and are based on the well-known Stokes parameters. We are able to represent light of arbitrary spectral content and states of polarization, and with any coherence volume and anisotropy. We also present the wave BSDF to accurately render diffractions and wave-interference effects. Furthermore, we present an approach to importance sample this wave BSDF to facilitate bi-directional path tracing, which has been previously impossible. We show good agreement with state-of-the-art methods, but unlike them we are able to render complex scenes where all the materials are new, coherence-aware physical optics materials, and with performance approaching that of “classical” rendering methods.","2023-07-15","2023-07-15 09:52:53","2023-08-03 19:08:57","2023-07-15 09:52:53","","","","","","","","","","","","","","","","","","","YouTube","","","","","","rendering","","","","","","","","","","","","","","","","","","","","","","19:00","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5HVVJ63","journalArticle","","Steinberg, Shlomi; Ramamoorthi, Ravi; Bitterli, Benedikt; D’Eon, Eugene; Yan, Ling-Qi; Pharr, Matt","A Generalized Ray Formulation For Wave-Optics Rendering","","","","","","In this paper we present the generalized ray: an extension of the classical ray to wave optics. The generalized ray retains the defining characteristics of the ray-optical ray: locality and linearity. These properties allow the generalized ray to serve as a “point query” of light’s behaviour—the same purpose that the classical ray fulfils in rendering. By using such generalized rays, we enable the rendering of complex scenes, like the one shown, under rigorous wave-optical light transport. Materials admitting diffractive optical phenomena are visible: (a) a Bornite ore with a layer of copper oxide causing interference; (b) a Brazilian Rainbow Boa, whose scales are biological diffraction grated surfaces; and (c) a Chrysomelidae beetle, whose colour arises due to naturally-occurring multilayered interference reflectors in its elytron. Our formalism serves as a link between path tracing techniques and wave optics, and admits a highly general validity domain. Therefore, we are able to apply sophisticated sampling techniques, and achieve performance that surpasses the state-of-the-art by orders-of-magnitude. We indicate resolution and samples-per-pixel (spp) count in all figures rendered using our method. While these figures showcase converged (high spp) results, our implementation also allows interactive rendering of all these scenes at 1 spp. Frame times (at 1 spp) for interactive rendering are indicated. Implementation, as well as additional renderings and videos are available in our supplemental material.","","2023-07-15 09:33:11","2023-08-03 19:09:07","","","","","","","","","","","","","","","en","","","","","Zotero","","","","C:\Users\isido\Zotero\storage\CV99AWZL\Steinberg e.a. - A Generalized Ray Formulation For Wave-Optics Rend.pdf","","rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AAIUR5TG","preprint","2022","Beznea, Lucian; Cimpean, Iulian; Lupascu-Stamate, Oana; Popescu, Ionel; Zarnescu, Arghir","From Monte Carlo to neural networks approximations of boundary value problems","","","","","http://arxiv.org/abs/2209.01432","In this paper we study probabilistic and neural network approximations for solutions to Poisson equation subject to H¨older or C2 data in general bounded domains of Rd. We aim at two fundamental goals.","2022-09-03","2023-07-17 07:22:30","2023-08-03 19:08:49","2023-07-17 07:22:30","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2209.01432 [cs, math]","","C:\Users\isido\Zotero\storage\NUHRK4MF\Beznea e.a. - 2022 - From Monte Carlo to neural networks approximations.pdf","","Boundary value problems; neural networks","Computer Science - Artificial Intelligence; Computer Science - Machine Learning; Mathematics - Analysis of PDEs; Mathematics - Numerical Analysis; Mathematics - Probability","","","","","","","","","","","","","","","","","","","arXiv:2209.01432","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N46GEQUR","journalArticle","2017","Daun, Thomas; Heinrich, Stefan","Complexity of parametric initial value problems for systems of ODEs","Mathematics and Computers in Simulation","","03784754","10.1016/j.matcom.2015.04.008","https://linkinghub.elsevier.com/retrieve/pii/S0378475415000713","We study the approximate solution of initial value problems for parameter dependent ﬁnite or inﬁnite systems of scalar ordinary diﬀerential equations (ODEs). Both the deterministic and the randomized setting is considered, with input data from various smoothness classes. We study deterministic and Monte Carlo multilevel algorithms and derive convergence rates. Moreover, we prove their optimality by showing matching (in some limit cases up to logarithmic factors) lower bounds and settle this way the complexity. Comparisons between the deterministic and randomized setting are given, as well.","2017-05","2023-07-17 07:32:11","2023-08-03 19:08:03","2023-07-17 07:32:11","72-85","","","135","","Mathematics and Computers in Simulation","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\BJIUZ98W\Daun en Heinrich - 2017 - Complexity of parametric initial value problems fo.pdf","","ODE; randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAXDSJP6","journalArticle","2014","Goćwin, Maciej","Randomized and quantum complexity of nonlinear two-point BVPs","Applied Mathematics and Computation","","0096-3003","10.1016/j.amc.2014.07.106","https://www.sciencedirect.com/science/article/pii/S009630031401073X","We deal with the complexity of nonlinear BVPs with nonlinear two-point boundary conditions. We consider the randomized and quantum models of computation. We assume that the right-hand side function is r times differentiable with all derivatives bounded by a constant. We show that the ε-complexity is roughly of order ε-1/(r+1/2) in the randomized setting, and ε-1/(r+1) in the quantum setting. We compare our results with known results in the deterministic setting. The speed-up of the randomized computations with respect to the deterministic computations is by 1/(r(2r+1)) in the exponent of 1/ε, and the speed-up of the quantum computations by 1/(r(r+1)) in the exponent.","2014-10-15","2023-07-17 07:45:48","2023-08-03 19:08:15","2023-07-17 07:45:48","357-371","","","245","","Applied Mathematics and Computation","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\isido\Zotero\storage\CRRV662Q\S009630031401073X.html","","ODE; randomized trapezodial","Boundary value problems; Complexity; Optimal algorithms; Quantum computing; Randomized computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPPIFCN4","journalArticle","2010","Goćwin, Maciej; Szczęsny, Marek","On the complexity of a two-point boundary value problem in different settings","International Journal of Computer Mathematics","","0020-7160, 1029-0265","10.1080/00207160903401852","http://www.tandfonline.com/doi/abs/10.1080/00207160903401852","We study the complexity of a two-point boundary value problem. We concentrate on the linear problem of order k with separated boundary conditions. Right-hand side functions are assumed to be r times differentiable with all derivatives bounded by a constant. We consider three models of computation: deterministic with standard and linear information, randomized and quantum. In each setting, we construct an algorithm for solving the problem, which allows us to establish upper complexity bounds. In the deterministic setting, we show that the use of linear information gives us a speed-up of at least one order of magnitude compared with the standard information. For randomized algorithms, we show that the speed-up over standard deterministic algorithms is by 1/2 in the exponent. For quantum algorithms, we can achieve a speed-up by one order of magnitude. We also provide lower complexity bounds. They match upper bounds in the deterministic setting with the standard information, and almost match upper bounds in the randomized and quantum settings. In the deterministic setting with the linear information, a gap still remains between the upper and lower complexity bounds.","2010-12","2023-07-17 07:50:28","2023-08-03 19:07:36","2023-07-17 07:50:28","3370-3386","","15","87","","International Journal of Computer Mathematics","","","","","","","","en","","","","","Semantic Scholar","","","","","https://www.semanticscholar.org/paper/On-the-complexity-of-a-two-point-boundary-value-in-Go%C4%87win-Szczesny/383b09d521353ea4639246999ec63b788114f2c8","randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XNQXJK34","preprint","2022","Herman, Dylan; Googin, Cody; Liu, Xiaoyuan; Galda, Alexey; Safro, Ilya; Sun, Yue; Pistoia, Marco; Alexeev, Yuri","A Survey of Quantum Computing for Finance","","","","","http://arxiv.org/abs/2201.02773","Quantum computers are expected to surpass the computational capabilities of classical computers during this decade and have transformative impact on numerous industry sectors, particularly ﬁnance. In fact, ﬁnance is estimated to be the ﬁrst industry sector to beneﬁt from quantum computing, not only in the medium and long terms, but even in the short term. This survey paper presents a comprehensive summary of the state of the art of quantum computing for ﬁnancial applications, with particular emphasis on stochastic modeling, optimization, and machine learning, describing how these solutions, adapted to work on a quantum computer, can potentially help to solve ﬁnancial problems, such as derivative pricing, risk modeling, portfolio optimization, natural language processing, and fraud detection, more eﬃciently and accurately. We also discuss the feasibility of these algorithms on nearterm quantum computers with various hardware implementations and demonstrate how they relate to a wide range of use cases in ﬁnance. We hope this article will not only serve as a reference for academic researchers and industry practitioners but also inspire new ideas for future research.","2022-06-27","2023-07-20 14:49:17","2023-08-03 19:07:27","2023-07-20 14:49:17","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2201.02773 [quant-ph, q-fin]","","C:\Users\isido\Zotero\storage\JM9ZHVD5\2201.02773.pdf","","Quantum computing","Quantitative Finance - Computational Finance; Quantum Physics","","","","","","","","","","","","","","","","","","","arXiv:2201.02773","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTU6RLC9","preprint","2021","Pistoia, Marco; Ahmad, Syed Farhan; Ajagekar, Akshay; Buts, Alexander; Chakrabarti, Shouvanik; Herman, Dylan; Hu, Shaohan; Jena, Andrew; Minssen, Pierre; Niroula, Pradeep; Rattew, Arthur; Sun, Yue; Yalovetzky, Romina","Quantum Machine Learning for Finance","","","","","http://arxiv.org/abs/2109.04298","Quantum computers are expected to surpass the computational capabilities of classical computers during this decade, and achieve disruptive impact on numerous industry sectors, particularly ﬁnance. In fact, ﬁnance is estimated to be the ﬁrst industry sector to beneﬁt from Quantum Computing not only in the medium and long terms, but even in the short term. This review paper presents the state of the art of quantum algorithms for ﬁnancial applications, with particular focus to those use cases that can be solved via Machine Learning.","2021-09-09","2023-07-20 14:49:23","2023-08-03 19:07:15","2023-07-20 14:49:23","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2109.04298 [quant-ph]","","C:\Users\isido\Zotero\storage\RUN9KCYU\Pistoia e.a. - 2021 - Quantum Machine Learning for Finance.pdf","","machine learning; Quantum computing","Computer Science - Machine Learning; Quantum Physics","","","","","","","","","","","","","","","","","","","arXiv:2109.04298","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64CMKIKW","journalArticle","2019","Orús, Román; Mugel, Samuel; Lizaso, Enrique","Quantum computing for finance: Overview and prospects","Reviews in Physics","","24054283","10.1016/j.revip.2019.100028","https://linkinghub.elsevier.com/retrieve/pii/S2405428318300571","We discuss how quantum computation can be applied to financial problems, providing an overview of current approaches and potential prospects. We review quantum optimization algorithms, and expose how quantum annealers can be used to optimize portfolios, find arbitrage opportunities, and perform credit scoring. We also discuss deep-learning in finance, and suggestions to improve these methods through quantum machine learning. Finally, we consider quantum amplitude estimation, and how it can result in a quantum speed-up for Monte Carlo sampling. This has direct applications to many current financial methods, including pricing of derivatives and risk analysis. Perspectives are also discussed.","2019-11","2023-07-20 14:53:45","2023-08-03 19:07:00","2023-07-20 14:53:45","100028","","","4","","Reviews in Physics","Quantum computing for finance","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\7E3B7Z3C\Orús e.a. - 2019 - Quantum computing for finance Overview and prospe.pdf","","Quantum computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KXMV99M","videoRecording","2017","Ryan T","Lecture 01: Linear regression","","","","","https://www.youtube.com/watch?v=Z1cSby8ZzhA","Lecture Date: Jan 17, 2017. http://www.stat.cmu.edu/~ryantibs/sta...","2017-01-20","2023-07-22 13:46:17","2023-07-22 13:46:17","2023-07-22 13:46:17","","","","","","","Lecture 01","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","1:10:06","","","","","","","","","","","","","","","","","","","","","","","","",""
"KHW6LQLK","videoRecording","2021","Cynthia Rudin","PaCMAP: An algorithm for dimension reduction","","","","","https://www.youtube.com/watch?v=sD-uDZ8zXkc","This video describes the PaCMAP technique for dimension reduction, which is an alternative to t-SNE and UMAP. It was derived based on an understanding of what makes dimension algorithms work. Paper: Understanding How Dimension Reduction Tools Work: An Empirical Approach to Deciphering t-SNE, UMAP, TriMAP, and PaCMAP for Data Visualization https://arxiv.org/abs/2012.04456 Code: https://github.com/YingfanWang/PaCMAP","2021-08-30","2023-07-23 10:26:44","2023-07-23 10:26:44","2023-07-23 10:26:44","","","","","","","PaCMAP","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","14:49","","","","","","","","","","","","","","","","","","","","","","","","",""
"9IDMEA3N","preprint","2021","Wang, Yingfan; Huang, Haiyang; Rudin, Cynthia; Shaposhnik, Yaron","Understanding How Dimension Reduction Tools Work: An Empirical Approach to Deciphering t-SNE, UMAP, TriMAP, and PaCMAP for Data Visualization","","","","","http://arxiv.org/abs/2012.04456","Dimension reduction (DR) techniques such as t-SNE, UMAP, and TriMAP have demonstrated impressive visualization performance on many real world datasets. One tension that has always faced these methods is the trade-off between preservation of global structure and preservation of local structure: these methods can either handle one or the other, but not both. In this work, our main goal is to understand what aspects of DR methods are important for preserving both local and global structure: it is difficult to design a better method without a true understanding of the choices we make in our algorithms and their empirical impact on the lower-dimensional embeddings they produce. Towards the goal of local structure preservation, we provide several useful design principles for DR loss functions based on our new understanding of the mechanisms behind successful DR methods. Towards the goal of global structure preservation, our analysis illuminates that the choice of which components to preserve is important. We leverage these insights to design a new algorithm for DR, called Pairwise Controlled Manifold Approximation Projection (PaCMAP), which preserves both local and global structure. Our work provides several unexpected insights into what design choices both to make and avoid when constructing DR algorithms.","2021-08-24","2023-07-23 10:26:53","2023-08-03 19:06:49","2023-07-23 10:26:53","","","","","","","Understanding How Dimension Reduction Tools Work","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2012.04456 [cs, stat]","","C:\Users\isido\Zotero\storage\TW5ZFTXU\2012.04456.pdf","","machine learning","Computer Science - Machine Learning; Statistics - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2012.04456","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9KSZG368","videoRecording","2023","PyData","Leland McInnes - Data Mapping for Data Exploration | PyData Seattle 2023","","","","","https://www.youtube.com/watch?v=r8dWZX8IGw8","www.pydata.org As embeddings and and vector databases become ever more popular we need to develop new tools for exploratory data analysis. One such approach is interactive data maps -- using 2D map style representations of the data, combined with rich interactivity that can link back to the source data. We'll look at the open source tools available for building interactive data maps, and work through an example use case. PyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R.  PyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases. 00:00 Welcome! 00:10 Help us add time stamps or captions to this video! See the description for details. Want to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVi...","2023-06-20","2023-07-23 11:34:45","2023-07-23 11:34:45","2023-07-23 11:34:45","","","","","","","","","","","","","","","","","","","YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","38:15","","","","","","","","","","","","","","","","","","","","","","","","",""
"X6UB3DBA","webpage","","","Tutte Institute for Mathematics and Computing","GitHub","","","","https://github.com/TutteInstitute","Tutte Institute for Mathematics and Computing. Tutte Institute for Mathematics and Computing has 8 repositories available. Follow their code on GitHub.","","2023-07-23 11:48:17","2023-07-23 11:48:25","2023-07-23 11:48:17","","","","","","","","","","","","","","en","","","","","","","","","C:\Users\isido\Zotero\storage\XQFYKYGV\tutteinstitute.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8P3AXZTK","preprint","2022","Xin, Rui; Zhong, Chudi; Chen, Zhi; Takagi, Takuya; Seltzer, Margo; Rudin, Cynthia","Exploring the Whole Rashomon Set of Sparse Decision Trees","","","","","http://arxiv.org/abs/2209.08040","In any given machine learning problem, there might be many models that explain the data almost equally well. However, most learning algorithms return only one of these models, leaving practitioners with no practical way to explore alternative models that might have desirable properties beyond what could be expressed by a loss function. The Rashomon set is the set of these all almost-optimal models. Rashomon sets can be large in size and complicated in structure, particularly for highly nonlinear function classes that allow complex interaction terms, such as decision trees. We provide the ﬁrst technique for completely enumerating the Rashomon set for sparse decision trees; in fact, our work provides the ﬁrst complete enumeration of any Rashomon set for a non-trivial problem with a highly nonlinear discrete function class. This allows the user an unprecedented level of control over model choice among all models that are approximately equally good. We represent the Rashomon set in a specialized data structure that supports efﬁcient querying and sampling. We show three applications of the Rashomon set: 1) it can be used to study variable importance for the set of almost-optimal trees (as opposed to a single tree), 2) the Rashomon set for accuracy enables enumeration of the Rashomon sets for balanced accuracy and F1-score, and 3) the Rashomon set for a full dataset can be used to produce Rashomon sets constructed with only subsets of the data set. Thus, we are able to examine Rashomon sets across problems with a new lens, enabling users to choose models rather than be at the mercy of an algorithm that produces only a single model.","2022-10-25","2023-07-23 11:56:34","2023-07-23 11:56:34","2023-07-23 11:56:34","","","","","","","","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2209.08040 [cs]","","C:\Users\isido\Zotero\storage\D6ZQM9GH\Xin e.a. - 2022 - Exploring the Whole Rashomon Set of Sparse Decisio.pdf","","","Computer Science - Machine Learning; Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","arXiv:2209.08040","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5N5M8MW","conferencePaper","2022","Wang, Zijie J.; Zhong, Chudi; Xin, Rui; Takagi, Takuya; Chen, Zhi; Chau, Duen Horng; Rudin, Cynthia; Seltzer, Margo","TimberTrek: Exploring and Curating Sparse Decision Trees with Interactive Visualization","2022 IEEE Visualization and Visual Analytics (VIS)","","","10.1109/VIS54862.2022.00021","http://arxiv.org/abs/2209.09227","Given thousands of equally accurate machine learning (ML) models, how can users choose among them? A recent ML technique enables domain experts and data scientists to generate a complete Rashomon set for sparse decision trees--a huge set of almost-optimal interpretable ML models. To help ML practitioners identify models with desirable properties from this Rashomon set, we develop TimberTrek, the first interactive visualization system that summarizes thousands of sparse decision trees at scale. Two usage scenarios highlight how TimberTrek can empower users to easily explore, compare, and curate models that align with their domain knowledge and values. Our open-source tool runs directly in users' computational notebooks and web browsers, lowering the barrier to creating more responsible ML models. TimberTrek is available at the following public demo link: https://poloclub.github.io/timbertrek.","2022-10","2023-07-23 11:57:56","2023-07-23 11:57:57","2023-07-23 11:57:56","60-64","","","","","","TimberTrek","","","","","","","en","","","","","arXiv.org","","arXiv:2209.09227 [cs]","","C:\Users\isido\Zotero\storage\8A6FQSQ2\Wang e.a. - 2022 - TimberTrek Exploring and Curating Sparse Decision.pdf","","","Computer Science - Machine Learning; Computer Science - Artificial Intelligence; Computer Science - Human-Computer Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NE3GSXAN","videoRecording","2021","Cynthia Rudin","Nobel Conference - Rudin","","","","","https://www.youtube.com/watch?v=Eokq35hm3mM","Cynthia Rudin's lecture for the 2021 Nobel Conference, on the topic of interpretable machine learning.","2021-10-04","2023-07-23 12:38:27","2023-08-03 19:06:34","2023-07-23 12:38:27","","","","","","","","","","","","","","","","","","","YouTube","","","","","","machine learning","","","","","","","","","","","","","","","","","","","","","","37:24","","","","","","","","","","","","","","","","","","","","","","","","",""
"NP6BXKFA","preprint","2023","Bonev, Boris; Kurth, Thorsten; Hundt, Christian; Pathak, Jaideep; Baust, Maximilian; Kashinath, Karthik; Anandkumar, Anima","Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere","","","","","http://arxiv.org/abs/2306.03838","Fourier Neural Operators (FNOs) have proven to be an efficient and effective method for resolutionindependent operator learning in a broad variety of application areas across scientific machine learning. A key reason for their success is their ability to accurately model long-range dependencies in spatio-temporal data by learning global convolutions in a computationally efficient manner. To this end, FNOs rely on the discrete Fourier transform (DFT), however, DFTs cause visual and spectral artifacts as well as pronounced dissipation when learning operators in spherical coordinates since they incorrectly assume a flat geometry. To overcome this limitation, we generalize FNOs on the sphere, introducing Spherical FNOs (SFNOs) for learning operators on spherical geometries. We apply SFNOs to forecasting atmospheric dynamics, and demonstrate stable autoregressive rollouts for a year of simulated time (1,460 steps), while retaining physically plausible dynamics. The SFNO has important implications for machine learning-based simulation of climate dynamics that could eventually help accelerate our response to climate change.","2023-06-06","2023-07-25 18:14:05","2023-08-03 19:06:25","2023-07-25 18:14:05","","","","","","","Spherical Fourier Neural Operators","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2306.03838 [physics]","","C:\Users\isido\Zotero\storage\4GD8MR5N\Bonev e.a. - 2023 - Spherical Fourier Neural Operators Learning Stabl.pdf","","machine learning","Computer Science - Machine Learning; Mathematics - Numerical Analysis; Physics - Atmospheric and Oceanic Physics; Physics - Computational Physics","","","","","","","","","","","","","","","","","","","arXiv:2306.03838","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9U582DK7","preprint","2023","Kalinin, Kirill P.; Mourgias-Alexandris, George; Ballani, Hitesh; Berloff, Natalia G.; Clegg, James H.; Cletheroe, Daniel; Gkantsidis, Christos; Haller, Istvan; Lyutsarev, Vassily; Parmigiani, Francesca; Pickup, Lucinda; Rowstron, Antony","Analog Iterative Machine (AIM): using light to solve quadratic optimization problems with mixed variables","","","","","http://arxiv.org/abs/2304.12594","Solving optimization problems is challenging for existing digital computers and even for future quantum hardware. The practical importance of diverse problems, from healthcare to financial optimization, has driven the emergence of specialised hardware over the past decade. However, their support for problems with only binary variables severely restricts the scope of practical problems that can be efficiently embedded. We build analog iterative machine (AIM), the first instance of an opto-electronic solver that natively implements a wider class of quadratic unconstrained mixed optimization (QUMO) problems and supports all-to-all connectivity of both continuous and binary variables.Beyond synthetic 7-bit problems at small-scale, AIM solves the financial transaction settlement problem entirely in analog domain with higher accuracy than quantum hardware and at room temperature. With compute-in-memory operation and spatial-division multiplexed representation of variables, the design of AIM paves the path to chip-scale architecture with 100 times speed-up per unit-power over the latest GPUs for solving problems with 10,000 variables. The robustness of the AIM algorithm at such scale is further demonstrated by comparing it with commercial production solvers across multiple benchmarks, where for several problems we report new best solutions. By combining the superior QUMO abstraction, sophisticated gradient descent methods inspired by machine learning, and commodity hardware, AIM introduces a novel platform with a step change in expressiveness, performance, and scalability, for optimization in the post-Moores law era.","2023-06-20","2023-07-27 18:27:48","2023-08-03 19:06:12","2023-07-27 18:27:48","","","","","","","Analog Iterative Machine (AIM)","","","","","arXiv","","en","","","","","arXiv.org","","arXiv:2304.12594 [physics]","","C:\Users\isido\Zotero\storage\LIAP6PZ5\Kalinin e.a. - 2023 - Analog Iterative Machine (AIM) using light to sol.pdf","","analog","Computer Science - Emerging Technologies; Mathematics - Optimization and Control; Physics - Applied Physics","","","","","","","","","","","","","","","","","","","arXiv:2304.12594","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VYG5E5Y7","book","2022","Foucart, Simon","Mathematical Pictures at a Data Science Exhibition","","978-1-00-900393-3 978-1-316-51888-5 978-1-00-900185-4","","","https://www.cambridge.org/core/product/identifier/9781009003933/type/book","This text provides deep and comprehensive coverage of the mathematical background for data science, including machine learning, optimal recovery, compressed sensing, optimization, and neural networks. In the past few decades, heuristic methods adopted by big tech companies have complemented existing scientific disciplines to form the new field of Data Science. This text embarks the readers on an engaging itinerary through the theory supporting the field. Altogether, twenty-seven lecture-length chapters with exercises provide all the details necessary for a solid understanding of key topics in data science. While the book covers standard material on machine learning and optimization, it also includes distinctive presentations of topics such as reproducing kernel Hilbert spaces, spectral clustering, optimal recovery, compressed sensing, group testing, and applications of semidefinite programming. Students and data scientists with less mathematical background will appreciate the appendices that provide more background on some of the more abstract concepts.","2022-05-31","2023-07-29 11:52:05","2023-08-03 19:06:04","2023-07-29 11:52:05","","","","","","","","","","","","Cambridge University Press","","en","","","","","DOI.org (Crossref)","","DOI: 10.1017/9781009003933","","C:\Users\isido\Zotero\storage\IV37PZ8W\Foucart - 2022 - Mathematical Pictures at a Data Science Exhibition.pdf","","machine learning","","","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36T4NZIV","journalArticle","2023","Bakbouk, Ghada; Peers, Pieter","Mean Value Caching for Walk on Spheres","","","","10.2312/SR.20231120","https://diglib.eg.org/handle/10.2312/sr20231120","Walk on Spheres (WoS) is a grid-free Monte Carlo method for numerically estimating solutions for elliptical partial differential equations (PDE) such as the Laplace and Poisson PDEs. While WoS is efficient for computing a solution value at a single evaluation point, it becomes less efficient when the solution is required over a whole domain or a region of interest. WoS computes a solution for each evaluation point separately, possibly recomputing similar sub-walks multiple times over multiple evaluation points. In this paper, we introduce a novel filtering and caching strategy that leverages the volume mean value property (in contrast to the boundary mean value property that forms the core of WoS). In addition, to improve quality under sparse cache regimes, we describe a weighted mean as well as a non-uniform sampling method. Finally, we show that we can reduce the variance within the cache by recursively applying the volume mean value property on the cached elements.","2023","2023-08-01 08:39:05","2023-08-03 19:05:55","2023-08-01 08:39:05","10 pages","","","","","","","","","","","","","en","Creative Commons Attribution 4.0 International","","","","DOI.org (Datacite)","","Artwork Size: 10 pages Publisher: The Eurographics Association","","C:\Users\isido\Zotero\storage\VT2WT79A\Bakbouk en Peers - 2023 - Mean Value Caching for Walk on Spheres.pdf","","walk on spheres","CCS Concepts: Computing methodologies -&gt; Shape analysis; Computing methodologies; Shape analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3E7WWC9","videoRecording","2023","Computerphile","Quantum Computing in Reality (Pt3: Beyond the Hype) - Computerphile","","","","","https://www.youtube.com/watch?v=gH_rF9LLzFA","What's actually possible vs what's theoretically possible vs what's actually useful with quantum computing? Victor V. Albert of University of Maryland and NIST simplifies! Victor on Twitter: @victorvalbert  Entire Quantum playlist:    • Quantum Computing   https://www.facebook.com/computerphile  https://twitter.com/computer_phile    This video was filmed and edited by Sean Riley.    Computer Science at the University of Nottingham: https://bit.ly/nottscomputer    Computerphile is a sister project to Brady Haran's Numberphile. More at http://www.bradyharan.com","2023-07-06","2023-08-01 09:48:47","2023-08-03 19:05:48","2023-08-01 09:48:47","","","","","","","Quantum Computing in Reality (Pt3","","","","","","","","","","","","YouTube","","","","","","Quantum computing","","","","","","","","","","","","","","","","","","","","","","7:39","","","","","","","","","","","","","","","","","","","","","","","","",""
"8CAH26QQ","webpage","","","BSc_Mathematics_2017_Hollander_RM.pdf","","","","","https://fse.studenttheses.ub.rug.nl/14905/1/BSc_Mathematics_2017_Hollander_RM.pdf","For a homogeneous system of linear differential equations with a constant coefficient matrix, the fundamental matrix can be computed for example using the Jordan Canonical Form. However, when the coefficient matrix depends on a single variable t, this method does not always provide a correct solution. The fundamental matrix can be computed using a numerical method, for example the Picard iterative method, but using such method, one can lose important qualitative properties. Wilhelm Magnus provided a method to approximate the fundamental matrix, such that these qualitative properties are preserved. In this thesis, we will state Magnus’ theorem and it’s proof. We will compute the Magnus Expansion for some simple examples, and compare the solutions with the fundamental matrices obtained by applying Picard iteration.","","2023-08-01 13:24:32","2023-08-03 19:05:38","2023-06-12 11:16:15","","","","","","","","","","","","","","","","","","","","","","","C:\Users\isido\Zotero\storage\Y5W4DSKX\BSc_Mathematics_2017_Hollander_RM.pdf","","ODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVAQMSES","journalArticle","2021","Bochacik, Tomasz; Goćwin, Maciej; Morkisz, Paweł M.; Przybyłowicz, Paweł","Randomized Runge-Kutta method -- stability and convergence under inexact information","Journal of Complexity","","0885064X","10.1016/j.jco.2021.101554","http://arxiv.org/abs/2006.12131","We deal with optimal approximation of solutions of ODEs under local Lipschitz condition and inexact discrete information about the right-hand side functions. We show that the randomized two-stage Runge-Kutta scheme is the optimal method among all randomized algorithms based on standard noisy information. We perform numerical experiments that conﬁrm our theoretical ﬁndings. Moreover, for the optimal algorithm we rigorously investigate properties of regions of absolute stability.","2021-08","2023-08-02 13:46:47","2023-08-03 19:05:13","2023-08-02 13:46:47","101554","","","65","","Journal of Complexity","","","","","","","","en","","","","","arXiv.org","","arXiv:2006.12131 [cs, math]","","C:\Users\isido\Zotero\storage\NYK5DYWB\Bochacik e.a. - 2021 - Randomized Runge-Kutta method -- stability and con.pdf","","ODE; randomized trapezodial","65C05, 65C20, 65L05, 65L06, 65L20; Mathematics - Numerical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EIIDDXXM","journalArticle","2019","Eisenmann, Monika; Kovács, Mihály; Kruse, Raphael; Larsson, Stig","On a Randomized Backward Euler Method for Nonlinear Evolution Equations with Time-Irregular Coefficients","Foundations of Computational Mathematics","","1615-3375, 1615-3383","10.1007/s10208-018-09412-w","http://link.springer.com/10.1007/s10208-018-09412-w","In this paper, we introduce a randomized version of the backward Euler method that is applicable to stiff ordinary differential equations and nonlinear evolution equations with time-irregular coefﬁcients. In the ﬁnite-dimensional case, we consider Carathéodory-type functions satisfying a one-sided Lipschitz condition. After investigating the well-posedness and the stability properties of the randomized scheme, we prove the convergence to the exact solution with a rate of 0.5 in the root-mean-square norm assuming only that the coefﬁcient function is square integrable with respect to the temporal parameter. These results are then extended to the approximation of inﬁnitedimensional evolution equations under monotonicity and Lipschitz conditions. Here, we consider a combination of the randomized backward Euler scheme with a Galerkin ﬁnite element method. We obtain error estimates that correspond to the regularity of the exact solution. The practicability of the randomized scheme is also illustrated through several numerical experiments.","2019-12","2023-08-02 14:19:04","2023-08-03 19:04:59","2023-08-02 14:19:04","1387-1430","","6","19","","Found Comput Math","","","","","","","","en","","","","","DOI.org (Crossref)","","","","C:\Users\isido\Zotero\storage\NBPU49QC\Eisenmann e.a. - 2019 - On a Randomized Backward Euler Method for Nonlinea.pdf","","ODE; randomized trapezodial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""