{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093e6ad46e024a1e94ec47c6a5e5c268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'proximity'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "import torch\n",
    "\n",
    "zot_df = pd.read_csv('./data/zot_clean.csv')\n",
    "\n",
    "# Convert the date columns to datetime objects\n",
    "date_columns = [\"Date\", \"Date Added\", \"Date Modified\"]\n",
    "for col in date_columns:\n",
    "    zot_df[col] = pd.to_datetime(zot_df[col], errors='coerce')\n",
    "\n",
    "zot_df[\"Publication Year\"] = zot_df[\"Publication Year\"].astype(\"Int64\")\n",
    "zot_df[\"Hearts\"] = zot_df[\"Hearts\"].astype(\"Int64\")\n",
    "\n",
    "zot_df[\"Manual Tags\"] = zot_df[\"Manual Tags\"].fillna(\"\").str.split(\";\").apply(lambda tags: [tag.strip() for tag in tags])\n",
    "zot_df[\"Abstract Note\"] = zot_df[\"Abstract Note\"].fillna(\"\")\n",
    "\n",
    "#dropping rows without title or abstract\n",
    "zot_df = zot_df.dropna(subset=['Title'])\n",
    "\n",
    "\n",
    "# embedding model\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base')\n",
    "model = AutoAdapterModel.from_pretrained('allenai/specter2_base')\n",
    "\n",
    "#load the adapter(s) as per the required task, provide an identifier for the adapter in load_as argument and activate it\n",
    "model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\", set_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 924 entries, 0 to 923\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Item Type          924 non-null    object        \n",
      " 1   Publication Year   882 non-null    Int64         \n",
      " 2   Author             822 non-null    object        \n",
      " 3   Title              924 non-null    object        \n",
      " 4   Publication Title  343 non-null    object        \n",
      " 5   DOI                304 non-null    object        \n",
      " 6   Url                836 non-null    object        \n",
      " 7   Abstract Note      924 non-null    object        \n",
      " 8   Date               75 non-null     datetime64[ns]\n",
      " 9   Date Added         924 non-null    datetime64[ns]\n",
      " 10  Date Modified      924 non-null    datetime64[ns]\n",
      " 11  Volume             246 non-null    float64       \n",
      " 12  Publisher          408 non-null    object        \n",
      " 13  Language           723 non-null    object        \n",
      " 14  Library Catalog    840 non-null    object        \n",
      " 15  Manual Tags        924 non-null    object        \n",
      " 16  Hearts             403 non-null    Int64         \n",
      " 17  Common Tags        675 non-null    object        \n",
      "dtypes: Int64(2), datetime64[ns](3), float64(1), object(12)\n",
      "memory usage: 131.9+ KB\n"
     ]
    }
   ],
   "source": [
    "zot_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [22:13<00:00, 14.34s/it]\n"
     ]
    }
   ],
   "source": [
    "#23min hour for 930 items\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Assuming zot_df is your DataFrame\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base')\n",
    "model = AutoModel.from_pretrained('allenai/specter2_base')\n",
    "\n",
    "# Function to process a single batch\n",
    "def process_batch(batch):\n",
    "\t# Concatenate title and abstract with the tokenizer's separator token\n",
    "\ttext_batch = batch[\"Title\"] + tokenizer.sep_token + batch[\"Abstract Note\"]\n",
    "\ttext_batch = list(text_batch)\n",
    "\t\n",
    "\t# Tokenize the text batch\n",
    "\tinputs = tokenizer(text_batch, padding=True, truncation=True,\n",
    "\t\t\t\t\t   return_tensors=\"pt\", return_token_type_ids=False, max_length=512)\n",
    "\t\n",
    "\t# Perform inference without gradient calculation\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(**inputs)\n",
    "\t\n",
    "\t# Extract embeddings from the output\n",
    "\tembeddings = output.last_hidden_state[:, 0, :]\n",
    "\treturn embeddings\n",
    "\n",
    "# Process the DataFrame in chunks\n",
    "batch_size = 10  # Set batch size (adjust based on memory availability)\n",
    "amount_batches = 8\n",
    "amount_batches = len(zot_df) // batch_size + 1\n",
    "embeddings_list = []\n",
    "\n",
    "# Iterate over the DataFrame in chunks with progress bar\n",
    "for start in tqdm(range(0, batch_size*amount_batches, batch_size), total=amount_batches):\n",
    "\tend = min(start + batch_size, len(zot_df))\n",
    "\tbatch = zot_df.iloc[start:end]\n",
    "\tembeddings = process_batch(batch)\n",
    "\tembeddings_list.append(embeddings)\n",
    "\n",
    "# Concatenate all embeddings\n",
    "all_embeddings = torch.cat(embeddings_list, dim=0)\n",
    "\n",
    "all_embeddings = torch.cat(embeddings_list, dim=0)\n",
    "embeddings_df = pd.DataFrame(all_embeddings.numpy())\n",
    "embeddings_df.to_csv('data/zot_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
