{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program_files\\miniconda\\envs\\zoteromap\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\program_files\\miniconda\\envs\\zoteromap\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "d:\\program_files\\miniconda\\envs\\zoteromap\\Lib\\site-packages\\adapters\\loading.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'proximity'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "import torch\n",
    "\n",
    "zot_df = pd.read_csv('./data/zot_clean.csv')\n",
    "\n",
    "# Convert the date columns to datetime objects\n",
    "date_columns = [\"Date\", \"Date Added\", \"Date Modified\"]\n",
    "for col in date_columns:\n",
    "    zot_df[col] = pd.to_datetime(zot_df[col], errors='coerce')\n",
    "\n",
    "zot_df[\"Publication Year\"] = zot_df[\"Publication Year\"].astype(\"Int64\")\n",
    "zot_df[\"Hearts\"] = zot_df[\"Hearts\"].astype(\"Int64\")\n",
    "\n",
    "zot_df[\"Manual Tags\"] = zot_df[\"Manual Tags\"].fillna(\"\").str.split(\";\").apply(lambda tags: [tag.strip() for tag in tags])\n",
    "zot_df[\"Abstract Note\"] = zot_df[\"Abstract Note\"].fillna(\"\")\n",
    "\n",
    "#dropping rows without title or abstract\n",
    "zot_df = zot_df.dropna(subset=['Title'])\n",
    "\n",
    "\n",
    "# embedding model\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base')\n",
    "model = AutoAdapterModel.from_pretrained('allenai/specter2_base')\n",
    "\n",
    "#load the adapter(s) as per the required task, provide an identifier for the adapter in load_as argument and activate it\n",
    "model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\", set_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 719 entries, 0 to 718\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Item Type          719 non-null    object        \n",
      " 1   Publication Year   646 non-null    Int64         \n",
      " 2   Author             654 non-null    object        \n",
      " 3   Title              719 non-null    object        \n",
      " 4   Publication Title  279 non-null    object        \n",
      " 5   DOI                215 non-null    object        \n",
      " 6   Url                651 non-null    object        \n",
      " 7   Abstract Note      670 non-null    object        \n",
      " 8   Date               53 non-null     datetime64[ns]\n",
      " 9   Date Added         719 non-null    datetime64[ns]\n",
      " 10  Date Modified      719 non-null    datetime64[ns]\n",
      " 11  Volume             205 non-null    float64       \n",
      " 12  Publisher          325 non-null    object        \n",
      " 13  Language           584 non-null    object        \n",
      " 14  Library Catalog    671 non-null    object        \n",
      " 15  Notes              200 non-null    object        \n",
      " 16  Manual Tags        719 non-null    object        \n",
      " 17  Hearts             228 non-null    Int64         \n",
      "dtypes: Int64(2), datetime64[ns](3), float64(1), object(12)\n",
      "memory usage: 102.6+ KB\n"
     ]
    }
   ],
   "source": [
    "zot_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [54:43<00:00, 45.60s/it]\n"
     ]
    }
   ],
   "source": [
    "#1 hour for 720 items\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Assuming zot_df is your DataFrame\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base')\n",
    "model = AutoModel.from_pretrained('allenai/specter2_base')\n",
    "\n",
    "# Function to process a single batch\n",
    "def process_batch(batch):\n",
    "\t# Concatenate title and abstract with the tokenizer's separator token\n",
    "\ttext_batch = batch[\"Title\"] + tokenizer.sep_token + batch[\"Abstract Note\"]\n",
    "\ttext_batch = list(text_batch)\n",
    "\t\n",
    "\t# Tokenize the text batch\n",
    "\tinputs = tokenizer(text_batch, padding=True, truncation=True,\n",
    "\t\t\t\t\t   return_tensors=\"pt\", return_token_type_ids=False, max_length=512)\n",
    "\t\n",
    "\t# Perform inference without gradient calculation\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(**inputs)\n",
    "\t\n",
    "\t# Extract embeddings from the output\n",
    "\tembeddings = output.last_hidden_state[:, 0, :]\n",
    "\treturn embeddings\n",
    "\n",
    "# Process the DataFrame in chunks\n",
    "batch_size = 10  # Set batch size (adjust based on memory availability)\n",
    "amount_batches = 8\n",
    "amount_batches = len(zot_df) // batch_size + 1\n",
    "embeddings_list = []\n",
    "\n",
    "# Iterate over the DataFrame in chunks with progress bar\n",
    "for start in tqdm(range(0, batch_size*amount_batches, batch_size), total=amount_batches):\n",
    "\tend = min(start + batch_size, len(zot_df))\n",
    "\tbatch = zot_df.iloc[start:end]\n",
    "\tembeddings = process_batch(batch)\n",
    "\tembeddings_list.append(embeddings)\n",
    "\n",
    "# Concatenate all embeddings\n",
    "all_embeddings = torch.cat(embeddings_list, dim=0)\n",
    "\n",
    "all_embeddings = torch.cat(embeddings_list, dim=0)\n",
    "embeddings_df = pd.DataFrame(all_embeddings.numpy())\n",
    "embeddings_df.to_csv('data/zot_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoteromap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
